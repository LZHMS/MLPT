***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RMaPLe/vit_b16_c2_ep50_batch4.yaml
dataset_config_file: configs/datasets/dtd.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
num_fp: 4
opts: ['TRAINER.MAPLE.N_CTX', '2', 'DATASET.NUM_SHOTS', '16']
output_dir: output/dtd/RMaPLe/vit_b16_c2_ep50_batch4_16shots/nctx2_depth9/GCE_False/16shots_4noise/seed3
prompt_depth: 9
resume: 
root: data
seed: 3
source_domains: None
target_domains: None
trainer: RMaPLe
transforms: None
use_robustloss: False
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 4
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: DescribableTextures
  NUM_FP: 4
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  USE_ROBUSTLOSS: False
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.0035
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/dtd/RMaPLe/vit_b16_c2_ep50_batch4_16shots/nctx2_depth9/GCE_False/16shots_4noise/seed3
RESUME: 
SEED: 3
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MAPLE:
    CTX_INIT: a photo of a
    N_CTX: 2
    PREC: fp16
    PROMPT_DEPTH: 9
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RMaPLe
  RMAPLE:
    CTX_INIT: a photo of a
    N_CTX: 2
    PREC: fp16
    PROMPT_DEPTH: 9
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.11.0
Is debug build: False
CUDA used to build PyTorch: 11.3
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: Could not collect
GPU models and configuration: 
GPU 0: NVIDIA GeForce RTX 2080 Ti
GPU 1: NVIDIA GeForce RTX 2080 Ti

Nvidia driver version: 470.86
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.24.3
[pip3] torch==1.11.0
[pip3] torchvision==0.12.0
[conda] blas                      1.0                         mkl    defaults
[conda] cudatoolkit               11.3.1               h2bc3f7f_2    defaults
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2021.4.0           h06a4308_640    defaults
[conda] mkl-service               2.4.0            py38h7f8727e_0    defaults
[conda] mkl_fft                   1.3.1            py38hd3c417c_0    defaults
[conda] mkl_random                1.2.2            py38h51133e4_0    defaults
[conda] numpy                     1.24.3           py38h14f4228_0    defaults
[conda] numpy-base                1.24.3           py38h31eccc5_0    defaults
[conda] pytorch                   1.11.0          py3.8_cuda11.3_cudnn8.2.0_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.12.0               py38_cu113    https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch
        Pillow (9.4.0)

Loading trainer: RMaPLe
Loading dataset: DescribableTextures
Reading split from /home/zhli/projects/RMaPLe/data/dtd/split_zhou_DescribableTextures.json
Loading preprocessed noisy few-shot data from /home/zhli/projects/RMaPLe/data/dtd/split_noisy_fewshot/shot_16-numfp_4-seed_3.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------------------
Dataset    DescribableTextures
# classes  47
# train_x  752
# val      188
# test     1,692
---------  -------------------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
RMAPLE design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of RMAPLE context words (tokens): 2
Turning off gradients in both the image and the text encoder
Parameters to be updated: {'prompt_learner.compound_prompt_projections.0.weight', 'prompt_learner.compound_prompt_projections.5.weight', 'prompt_learner.compound_prompts_text.1', 'prompt_learner.compound_prompts_text.5', 'prompt_learner.compound_prompt_projections.4.bias', 'prompt_learner.compound_prompt_projections.0.bias', 'prompt_learner.compound_prompt_projections.6.bias', 'prompt_learner.compound_prompt_projections.4.weight', 'prompt_learner.compound_prompts_text.2', 'prompt_learner.compound_prompt_projections.7.weight', 'prompt_learner.compound_prompt_projections.1.bias', 'prompt_learner.compound_prompt_projections.5.bias', 'prompt_learner.proj.weight', 'prompt_learner.compound_prompts_text.3', 'prompt_learner.compound_prompts_text.7', 'prompt_learner.compound_prompts_text.6', 'prompt_learner.compound_prompts_text.0', 'prompt_learner.ctx', 'prompt_learner.compound_prompt_projections.1.weight', 'prompt_learner.compound_prompt_projections.2.weight', 'prompt_learner.compound_prompt_projections.2.bias', 'prompt_learner.proj.bias', 'prompt_learner.compound_prompt_projections.3.bias', 'prompt_learner.compound_prompt_projections.7.bias', 'prompt_learner.compound_prompt_projections.3.weight', 'prompt_learner.compound_prompts_text.4', 'prompt_learner.compound_prompt_projections.6.weight'}
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/dtd/RMaPLe/vit_b16_c2_ep50_batch4_16shots/nctx2_depth9/GCE_False/16shots_4noise/seed3/tensorboard)
epoch [1/50] batch [20/188] time 0.061 (0.092) data 0.000 (0.013) loss 3.8789 (3.7489) lr 1.0000e-05 eta 0:14:18
epoch [1/50] batch [40/188] time 0.061 (0.076) data 0.000 (0.007) loss 3.1016 (3.7265) lr 1.0000e-05 eta 0:11:54
epoch [1/50] batch [60/188] time 0.061 (0.071) data 0.000 (0.005) loss 3.8613 (3.7735) lr 1.0000e-05 eta 0:11:05
epoch [1/50] batch [80/188] time 0.061 (0.069) data 0.000 (0.003) loss 3.4199 (3.7877) lr 1.0000e-05 eta 0:10:40
epoch [1/50] batch [100/188] time 0.062 (0.067) data 0.000 (0.003) loss 3.7148 (3.7671) lr 1.0000e-05 eta 0:10:25
epoch [1/50] batch [120/188] time 0.061 (0.066) data 0.000 (0.002) loss 3.9629 (3.7642) lr 1.0000e-05 eta 0:10:14
epoch [1/50] batch [140/188] time 0.061 (0.066) data 0.000 (0.002) loss 3.6387 (3.7456) lr 1.0000e-05 eta 0:10:06
epoch [1/50] batch [160/188] time 0.061 (0.065) data 0.000 (0.002) loss 4.0156 (3.7545) lr 1.0000e-05 eta 0:10:00
epoch [1/50] batch [180/188] time 0.061 (0.065) data 0.000 (0.002) loss 3.5547 (3.7553) lr 1.0000e-05 eta 0:09:54
epoch [2/50] batch [20/188] time 0.061 (0.070) data 0.000 (0.009) loss 3.0840 (3.5570) lr 3.5000e-03 eta 0:10:45
epoch [2/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 3.4023 (3.5475) lr 3.5000e-03 eta 0:10:01
epoch [2/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 3.4395 (3.4791) lr 3.5000e-03 eta 0:09:46
epoch [2/50] batch [80/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.2617 (3.4543) lr 3.5000e-03 eta 0:09:38
epoch [2/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.4746 (3.4239) lr 3.5000e-03 eta 0:09:33
epoch [2/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.6875 (3.4365) lr 3.5000e-03 eta 0:09:29
epoch [2/50] batch [140/188] time 0.061 (0.062) data 0.000 (0.001) loss 3.3848 (3.4382) lr 3.5000e-03 eta 0:09:26
epoch [2/50] batch [160/188] time 0.061 (0.062) data 0.000 (0.001) loss 3.7969 (3.4307) lr 3.5000e-03 eta 0:09:23
epoch [2/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 3.1094 (3.4184) lr 3.5000e-03 eta 0:09:21
epoch [3/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 3.5508 (3.2221) lr 3.4965e-03 eta 0:10:36
epoch [3/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.6328 (3.1000) lr 3.4965e-03 eta 0:09:53
epoch [3/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 3.0762 (3.0984) lr 3.4965e-03 eta 0:09:37
epoch [3/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 4.4141 (3.1106) lr 3.4965e-03 eta 0:09:29
epoch [3/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.6230 (3.1333) lr 3.4965e-03 eta 0:09:24
epoch [3/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.4609 (3.1343) lr 3.4965e-03 eta 0:09:20
epoch [3/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.5195 (3.1101) lr 3.4965e-03 eta 0:09:16
epoch [3/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 3.1309 (3.1187) lr 3.4965e-03 eta 0:09:14
epoch [3/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.9531 (3.1106) lr 3.4965e-03 eta 0:09:11
epoch [4/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 1.9824 (3.1248) lr 3.4862e-03 eta 0:10:27
epoch [4/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.6348 (2.9824) lr 3.4862e-03 eta 0:09:42
epoch [4/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.0137 (2.9179) lr 3.4862e-03 eta 0:09:27
epoch [4/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 3.0527 (2.9414) lr 3.4862e-03 eta 0:09:18
epoch [4/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.1738 (2.9453) lr 3.4862e-03 eta 0:09:13
epoch [4/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 3.5918 (2.9227) lr 3.4862e-03 eta 0:09:09
epoch [4/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.5410 (2.9087) lr 3.4862e-03 eta 0:09:06
epoch [4/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 3.2246 (2.8944) lr 3.4862e-03 eta 0:09:03
epoch [4/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 3.4336 (2.8925) lr 3.4862e-03 eta 0:09:00
epoch [5/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 2.8574 (2.7231) lr 3.4690e-03 eta 0:10:10
epoch [5/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 3.5117 (2.5913) lr 3.4690e-03 eta 0:09:28
epoch [5/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 2.7500 (2.7001) lr 3.4690e-03 eta 0:09:13
epoch [5/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.1719 (2.7252) lr 3.4690e-03 eta 0:09:05
epoch [5/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.5605 (2.7037) lr 3.4690e-03 eta 0:09:00
epoch [5/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.6035 (2.6955) lr 3.4690e-03 eta 0:08:56
epoch [5/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 3.1914 (2.7126) lr 3.4690e-03 eta 0:08:53
epoch [5/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.7930 (2.7281) lr 3.4690e-03 eta 0:08:50
epoch [5/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.8779 (2.7131) lr 3.4690e-03 eta 0:08:48
epoch [6/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.010) loss 1.8379 (2.6038) lr 3.4450e-03 eta 0:09:59
epoch [6/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.1514 (2.6123) lr 3.4450e-03 eta 0:09:17
epoch [6/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.1211 (2.6605) lr 3.4450e-03 eta 0:09:02
epoch [6/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.4766 (2.6035) lr 3.4450e-03 eta 0:08:54
epoch [6/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.2227 (2.5917) lr 3.4450e-03 eta 0:08:49
epoch [6/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.5293 (2.5933) lr 3.4450e-03 eta 0:08:45
epoch [6/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.2246 (2.5628) lr 3.4450e-03 eta 0:08:41
epoch [6/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.4199 (2.5731) lr 3.4450e-03 eta 0:08:39
epoch [6/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.9375 (2.5839) lr 3.4450e-03 eta 0:08:37
epoch [7/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 2.4062 (2.4799) lr 3.4143e-03 eta 0:09:42
epoch [7/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.6504 (2.4359) lr 3.4143e-03 eta 0:09:03
epoch [7/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.9277 (2.4706) lr 3.4143e-03 eta 0:08:48
epoch [7/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 3.6602 (2.4650) lr 3.4143e-03 eta 0:08:41
epoch [7/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.9766 (2.4661) lr 3.4143e-03 eta 0:08:36
epoch [7/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.1465 (2.4582) lr 3.4143e-03 eta 0:08:32
epoch [7/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 3.1289 (2.4815) lr 3.4143e-03 eta 0:08:29
epoch [7/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 3.7324 (2.4986) lr 3.4143e-03 eta 0:08:27
epoch [7/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 3.3105 (2.5128) lr 3.4143e-03 eta 0:08:24
epoch [8/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 1.2422 (2.3675) lr 3.3771e-03 eta 0:09:34
epoch [8/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 3.0684 (2.4276) lr 3.3771e-03 eta 0:08:53
epoch [8/50] batch [60/188] time 0.062 (0.065) data 0.000 (0.003) loss 2.3594 (2.3662) lr 3.3771e-03 eta 0:08:39
epoch [8/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.9688 (2.3840) lr 3.3771e-03 eta 0:08:31
epoch [8/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.1660 (2.3742) lr 3.3771e-03 eta 0:08:26
epoch [8/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.2988 (2.4072) lr 3.3771e-03 eta 0:08:22
epoch [8/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.4971 (2.4329) lr 3.3771e-03 eta 0:08:19
epoch [8/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 3.6309 (2.4241) lr 3.3771e-03 eta 0:08:16
epoch [8/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.9453 (2.4367) lr 3.3771e-03 eta 0:08:13
epoch [9/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 3.1562 (2.4959) lr 3.3334e-03 eta 0:09:17
epoch [9/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 3.0605 (2.4613) lr 3.3334e-03 eta 0:08:39
epoch [9/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 2.4512 (2.4200) lr 3.3334e-03 eta 0:08:25
epoch [9/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 0.9580 (2.3618) lr 3.3334e-03 eta 0:08:17
epoch [9/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9434 (2.3782) lr 3.3334e-03 eta 0:08:13
epoch [9/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.3975 (2.3732) lr 3.3334e-03 eta 0:08:09
epoch [9/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.7900 (2.3682) lr 3.3334e-03 eta 0:08:06
epoch [9/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.7207 (2.3741) lr 3.3334e-03 eta 0:08:03
epoch [9/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 3.4629 (2.3760) lr 3.3334e-03 eta 0:08:01
epoch [10/50] batch [20/188] time 0.061 (0.070) data 0.000 (0.009) loss 1.7129 (2.1885) lr 3.2835e-03 eta 0:09:01
epoch [10/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 1.7920 (2.2004) lr 3.2835e-03 eta 0:08:25
epoch [10/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 2.8750 (2.1750) lr 3.2835e-03 eta 0:08:12
epoch [10/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 1.4893 (2.2380) lr 3.2835e-03 eta 0:08:05
epoch [10/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.1348 (2.2446) lr 3.2835e-03 eta 0:08:01
epoch [10/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.0508 (2.2300) lr 3.2835e-03 eta 0:07:57
epoch [10/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.5557 (2.2634) lr 3.2835e-03 eta 0:07:54
epoch [10/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.8799 (2.3008) lr 3.2835e-03 eta 0:07:52
epoch [10/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.5703 (2.3178) lr 3.2835e-03 eta 0:07:49
epoch [11/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.010) loss 1.5742 (2.2028) lr 3.2276e-03 eta 0:08:53
epoch [11/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 4.2734 (2.3171) lr 3.2276e-03 eta 0:08:15
epoch [11/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 3.1855 (2.3425) lr 3.2276e-03 eta 0:08:02
epoch [11/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.003) loss 2.0762 (2.2607) lr 3.2276e-03 eta 0:07:55
epoch [11/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9092 (2.2394) lr 3.2276e-03 eta 0:07:50
epoch [11/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.8145 (2.2722) lr 3.2276e-03 eta 0:07:46
epoch [11/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.6133 (2.2804) lr 3.2276e-03 eta 0:07:43
epoch [11/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.6250 (2.2850) lr 3.2276e-03 eta 0:07:40
epoch [11/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.7344 (2.2635) lr 3.2276e-03 eta 0:07:38
epoch [12/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.8965 (1.9155) lr 3.1658e-03 eta 0:08:37
epoch [12/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.8066 (2.0128) lr 3.1658e-03 eta 0:08:01
epoch [12/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 1.5068 (2.1685) lr 3.1658e-03 eta 0:07:49
epoch [12/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 3.2695 (2.1709) lr 3.1658e-03 eta 0:07:42
epoch [12/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9990 (2.1814) lr 3.1658e-03 eta 0:07:37
epoch [12/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9766 (2.1978) lr 3.1658e-03 eta 0:07:34
epoch [12/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.8242 (2.1587) lr 3.1658e-03 eta 0:07:31
epoch [12/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.7480 (2.2049) lr 3.1658e-03 eta 0:07:28
epoch [12/50] batch [180/188] time 0.062 (0.062) data 0.000 (0.001) loss 2.4961 (2.2132) lr 3.1658e-03 eta 0:07:26
epoch [13/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 4.7109 (2.3784) lr 3.0984e-03 eta 0:08:28
epoch [13/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.8242 (2.2832) lr 3.0984e-03 eta 0:07:51
epoch [13/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.1855 (2.1063) lr 3.0984e-03 eta 0:07:38
epoch [13/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.0547 (2.1585) lr 3.0984e-03 eta 0:07:31
epoch [13/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.7822 (2.1591) lr 3.0984e-03 eta 0:07:26
epoch [13/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9141 (2.1801) lr 3.0984e-03 eta 0:07:22
epoch [13/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.5000 (2.1869) lr 3.0984e-03 eta 0:07:19
epoch [13/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.6758 (2.2057) lr 3.0984e-03 eta 0:07:17
epoch [13/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.7812 (2.2024) lr 3.0984e-03 eta 0:07:15
epoch [14/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.010) loss 1.0732 (2.3258) lr 3.0257e-03 eta 0:08:12
epoch [14/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 3.0117 (2.3107) lr 3.0257e-03 eta 0:07:37
epoch [14/50] batch [60/188] time 0.062 (0.065) data 0.000 (0.003) loss 1.7021 (2.3569) lr 3.0257e-03 eta 0:07:25
epoch [14/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 3.2539 (2.3486) lr 3.0257e-03 eta 0:07:18
epoch [14/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.9277 (2.3013) lr 3.0257e-03 eta 0:07:14
epoch [14/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.1836 (2.2506) lr 3.0257e-03 eta 0:07:10
epoch [14/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 3.3223 (2.2090) lr 3.0257e-03 eta 0:07:07
epoch [14/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.9048 (2.1843) lr 3.0257e-03 eta 0:07:05
epoch [14/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.9131 (2.1695) lr 3.0257e-03 eta 0:07:03
epoch [15/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.010) loss 2.0195 (1.9387) lr 2.9480e-03 eta 0:07:59
epoch [15/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.4922 (2.0144) lr 2.9480e-03 eta 0:07:25
epoch [15/50] batch [60/188] time 0.062 (0.065) data 0.000 (0.003) loss 2.4707 (2.0162) lr 2.9480e-03 eta 0:07:13
epoch [15/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.3203 (2.0049) lr 2.9480e-03 eta 0:07:07
epoch [15/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.2559 (1.9889) lr 2.9480e-03 eta 0:07:02
epoch [15/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.7393 (2.0446) lr 2.9480e-03 eta 0:06:59
epoch [15/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.9238 (2.0628) lr 2.9480e-03 eta 0:06:56
epoch [15/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.9111 (2.0768) lr 2.9480e-03 eta 0:06:53
epoch [15/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.1787 (2.0858) lr 2.9480e-03 eta 0:06:51
epoch [16/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 1.4102 (2.1002) lr 2.8655e-03 eta 0:07:43
epoch [16/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.8105 (2.1097) lr 2.8655e-03 eta 0:07:11
epoch [16/50] batch [60/188] time 0.062 (0.065) data 0.000 (0.003) loss 2.1855 (2.2216) lr 2.8655e-03 eta 0:07:00
epoch [16/50] batch [80/188] time 0.063 (0.064) data 0.000 (0.002) loss 3.0469 (2.1999) lr 2.8655e-03 eta 0:06:54
epoch [16/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.6387 (2.2234) lr 2.8655e-03 eta 0:06:50
epoch [16/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.7798 (2.2094) lr 2.8655e-03 eta 0:06:46
epoch [16/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.5879 (2.1490) lr 2.8655e-03 eta 0:06:44
epoch [16/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.6162 (2.1240) lr 2.8655e-03 eta 0:06:41
epoch [16/50] batch [180/188] time 0.062 (0.062) data 0.000 (0.001) loss 1.2607 (2.0889) lr 2.8655e-03 eta 0:06:39
epoch [17/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 1.4189 (1.8798) lr 2.7786e-03 eta 0:07:30
epoch [17/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.2246 (1.9218) lr 2.7786e-03 eta 0:06:59
epoch [17/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 2.1016 (1.9297) lr 2.7786e-03 eta 0:06:48
epoch [17/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 3.3613 (1.9710) lr 2.7786e-03 eta 0:06:42
epoch [17/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.9463 (2.0270) lr 2.7786e-03 eta 0:06:37
epoch [17/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9424 (2.0574) lr 2.7786e-03 eta 0:06:34
epoch [17/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.2383 (2.0472) lr 2.7786e-03 eta 0:06:32
epoch [17/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.0801 (2.0739) lr 2.7786e-03 eta 0:06:29
epoch [17/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 0.9282 (2.0685) lr 2.7786e-03 eta 0:06:27
epoch [18/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 1.2129 (2.1021) lr 2.6877e-03 eta 0:07:19
epoch [18/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.2500 (2.0873) lr 2.6877e-03 eta 0:06:48
epoch [18/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 1.2314 (2.1031) lr 2.6877e-03 eta 0:06:37
epoch [18/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 3.5820 (2.1551) lr 2.6877e-03 eta 0:06:30
epoch [18/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9883 (2.1556) lr 2.6877e-03 eta 0:06:26
epoch [18/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.4805 (2.0856) lr 2.6877e-03 eta 0:06:23
epoch [18/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.3789 (2.0887) lr 2.6877e-03 eta 0:06:20
epoch [18/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.0898 (2.0642) lr 2.6877e-03 eta 0:06:18
epoch [18/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.3281 (2.0290) lr 2.6877e-03 eta 0:06:16
epoch [19/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.8857 (2.2122) lr 2.5931e-03 eta 0:07:04
epoch [19/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.8789 (2.1253) lr 2.5931e-03 eta 0:06:35
epoch [19/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 3.6465 (2.1491) lr 2.5931e-03 eta 0:06:24
epoch [19/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 1.5146 (2.1244) lr 2.5931e-03 eta 0:06:18
epoch [19/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.2529 (2.0610) lr 2.5931e-03 eta 0:06:14
epoch [19/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.9678 (2.0031) lr 2.5931e-03 eta 0:06:11
epoch [19/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.2715 (2.0638) lr 2.5931e-03 eta 0:06:08
epoch [19/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.2129 (2.0476) lr 2.5931e-03 eta 0:06:06
epoch [19/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.1631 (2.0110) lr 2.5931e-03 eta 0:06:04
epoch [20/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 1.1758 (1.7871) lr 2.4951e-03 eta 0:06:53
epoch [20/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 1.7793 (1.8074) lr 2.4951e-03 eta 0:06:23
epoch [20/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.2090 (1.8248) lr 2.4951e-03 eta 0:06:12
epoch [20/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.003) loss 2.8613 (1.8396) lr 2.4951e-03 eta 0:06:06
epoch [20/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.7891 (1.8803) lr 2.4951e-03 eta 0:06:02
epoch [20/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.0840 (1.9105) lr 2.4951e-03 eta 0:05:59
epoch [20/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.5547 (1.9242) lr 2.4951e-03 eta 0:05:57
epoch [20/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.3887 (1.9733) lr 2.4951e-03 eta 0:05:54
epoch [20/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.0869 (1.9887) lr 2.4951e-03 eta 0:05:52
epoch [21/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 3.3047 (1.9721) lr 2.3942e-03 eta 0:06:36
epoch [21/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.4180 (1.8135) lr 2.3942e-03 eta 0:06:09
epoch [21/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 0.8340 (1.8878) lr 2.3942e-03 eta 0:05:59
epoch [21/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 1.2178 (1.9862) lr 2.3942e-03 eta 0:05:54
epoch [21/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.6328 (1.9706) lr 2.3942e-03 eta 0:05:50
epoch [21/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.6309 (1.9577) lr 2.3942e-03 eta 0:05:47
epoch [21/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.9351 (2.0027) lr 2.3942e-03 eta 0:05:44
epoch [21/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.3125 (1.9973) lr 2.3942e-03 eta 0:05:42
epoch [21/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 3.0078 (1.9684) lr 2.3942e-03 eta 0:05:40
epoch [22/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 2.9902 (1.6843) lr 2.2908e-03 eta 0:06:24
epoch [22/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.2988 (1.8412) lr 2.2908e-03 eta 0:05:58
epoch [22/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 1.4951 (1.8707) lr 2.2908e-03 eta 0:05:48
epoch [22/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 3.2656 (1.8936) lr 2.2908e-03 eta 0:05:42
epoch [22/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.0137 (1.8979) lr 2.2908e-03 eta 0:05:38
epoch [22/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.1680 (1.8956) lr 2.2908e-03 eta 0:05:35
epoch [22/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.9141 (1.9160) lr 2.2908e-03 eta 0:05:33
epoch [22/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.4102 (1.8921) lr 2.2908e-03 eta 0:05:31
epoch [22/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.3877 (1.8866) lr 2.2908e-03 eta 0:05:29
epoch [23/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 2.2598 (2.0008) lr 2.1852e-03 eta 0:06:10
epoch [23/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.1777 (1.9822) lr 2.1852e-03 eta 0:05:44
epoch [23/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.5684 (2.0062) lr 2.1852e-03 eta 0:05:35
epoch [23/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 1.9736 (1.9563) lr 2.1852e-03 eta 0:05:30
epoch [23/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.1953 (1.9675) lr 2.1852e-03 eta 0:05:26
epoch [23/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.0000 (1.9609) lr 2.1852e-03 eta 0:05:24
epoch [23/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.9004 (1.9646) lr 2.1852e-03 eta 0:05:21
epoch [23/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.2812 (1.9445) lr 2.1852e-03 eta 0:05:19
epoch [23/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.6006 (1.8887) lr 2.1852e-03 eta 0:05:17
epoch [24/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 2.8301 (1.9921) lr 2.0779e-03 eta 0:05:59
epoch [24/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.0898 (2.0204) lr 2.0779e-03 eta 0:05:33
epoch [24/50] batch [60/188] time 0.062 (0.065) data 0.000 (0.003) loss 1.1104 (1.8975) lr 2.0779e-03 eta 0:05:25
epoch [24/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 1.5303 (1.8976) lr 2.0779e-03 eta 0:05:19
epoch [24/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.5186 (1.9096) lr 2.0779e-03 eta 0:05:15
epoch [24/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.2812 (1.8816) lr 2.0779e-03 eta 0:05:12
epoch [24/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.4570 (1.8651) lr 2.0779e-03 eta 0:05:10
epoch [24/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.5176 (1.8744) lr 2.0779e-03 eta 0:05:07
epoch [24/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.4092 (1.8810) lr 2.0779e-03 eta 0:05:06
epoch [25/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 1.0771 (1.6668) lr 1.9693e-03 eta 0:05:45
epoch [25/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.0508 (1.8288) lr 1.9693e-03 eta 0:05:20
epoch [25/50] batch [60/188] time 0.062 (0.065) data 0.000 (0.003) loss 2.4609 (1.7527) lr 1.9693e-03 eta 0:05:11
epoch [25/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.0645 (1.8388) lr 1.9693e-03 eta 0:05:06
epoch [25/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9336 (1.8715) lr 1.9693e-03 eta 0:05:03
epoch [25/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.4717 (1.8974) lr 1.9693e-03 eta 0:05:00
epoch [25/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.3350 (1.9043) lr 1.9693e-03 eta 0:04:57
epoch [25/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 0.7368 (1.8889) lr 1.9693e-03 eta 0:04:55
epoch [25/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.5615 (1.8765) lr 1.9693e-03 eta 0:04:54
epoch [26/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.1709 (1.6285) lr 1.8599e-03 eta 0:05:29
epoch [26/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.0078 (1.7353) lr 1.8599e-03 eta 0:05:07
epoch [26/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.4424 (1.7509) lr 1.8599e-03 eta 0:04:59
epoch [26/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.6953 (1.7915) lr 1.8599e-03 eta 0:04:54
epoch [26/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.0938 (1.8013) lr 1.8599e-03 eta 0:04:50
epoch [26/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.2227 (1.7926) lr 1.8599e-03 eta 0:04:48
epoch [26/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.5869 (1.8048) lr 1.8599e-03 eta 0:04:46
epoch [26/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.1387 (1.8112) lr 1.8599e-03 eta 0:04:43
epoch [26/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.0781 (1.8238) lr 1.8599e-03 eta 0:04:42
epoch [27/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 2.3711 (1.7645) lr 1.7500e-03 eta 0:05:18
epoch [27/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.4082 (1.8097) lr 1.7500e-03 eta 0:04:55
epoch [27/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.9854 (1.7979) lr 1.7500e-03 eta 0:04:47
epoch [27/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.1406 (1.7524) lr 1.7500e-03 eta 0:04:42
epoch [27/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.6377 (1.7288) lr 1.7500e-03 eta 0:04:39
epoch [27/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.5000 (1.7413) lr 1.7500e-03 eta 0:04:36
epoch [27/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.7373 (1.7711) lr 1.7500e-03 eta 0:04:34
epoch [27/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.6240 (1.7969) lr 1.7500e-03 eta 0:04:32
epoch [27/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.6133 (1.8216) lr 1.7500e-03 eta 0:04:30
epoch [28/50] batch [20/188] time 0.062 (0.072) data 0.000 (0.010) loss 3.2871 (2.0291) lr 1.6401e-03 eta 0:05:07
epoch [28/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.6484 (1.8486) lr 1.6401e-03 eta 0:04:44
epoch [28/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.7363 (1.7865) lr 1.6401e-03 eta 0:04:36
epoch [28/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.3262 (1.7475) lr 1.6401e-03 eta 0:04:31
epoch [28/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.9736 (1.7756) lr 1.6401e-03 eta 0:04:27
epoch [28/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 0.5415 (1.7739) lr 1.6401e-03 eta 0:04:25
epoch [28/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.002) loss 0.7969 (1.7806) lr 1.6401e-03 eta 0:04:22
epoch [28/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.5566 (1.7833) lr 1.6401e-03 eta 0:04:20
epoch [28/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 3.1680 (1.8064) lr 1.6401e-03 eta 0:04:19
epoch [29/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.7197 (1.6674) lr 1.5307e-03 eta 0:04:51
epoch [29/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.7324 (1.6986) lr 1.5307e-03 eta 0:04:30
epoch [29/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.6719 (1.6243) lr 1.5307e-03 eta 0:04:22
epoch [29/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 0.8916 (1.6783) lr 1.5307e-03 eta 0:04:18
epoch [29/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.6602 (1.7252) lr 1.5307e-03 eta 0:04:15
epoch [29/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.1680 (1.7311) lr 1.5307e-03 eta 0:04:12
epoch [29/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.9355 (1.7486) lr 1.5307e-03 eta 0:04:10
epoch [29/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.1836 (1.7395) lr 1.5307e-03 eta 0:04:08
epoch [29/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.4082 (1.7639) lr 1.5307e-03 eta 0:04:06
epoch [30/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 1.0850 (1.8092) lr 1.4221e-03 eta 0:04:39
epoch [30/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 0.8325 (1.7054) lr 1.4221e-03 eta 0:04:18
epoch [30/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 1.2969 (1.6944) lr 1.4221e-03 eta 0:04:11
epoch [30/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.9805 (1.7490) lr 1.4221e-03 eta 0:04:07
epoch [30/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.4021 (1.6861) lr 1.4221e-03 eta 0:04:04
epoch [30/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.7563 (1.6723) lr 1.4221e-03 eta 0:04:01
epoch [30/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.0215 (1.6923) lr 1.4221e-03 eta 0:03:59
epoch [30/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.8535 (1.7230) lr 1.4221e-03 eta 0:03:57
epoch [30/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.4727 (1.7242) lr 1.4221e-03 eta 0:03:55
epoch [31/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 0.9780 (1.6454) lr 1.3148e-03 eta 0:04:24
epoch [31/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 3.5371 (1.7322) lr 1.3148e-03 eta 0:04:05
epoch [31/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.0078 (1.8779) lr 1.3148e-03 eta 0:03:58
epoch [31/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 1.1875 (1.8186) lr 1.3148e-03 eta 0:03:54
epoch [31/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.2227 (1.7762) lr 1.3148e-03 eta 0:03:51
epoch [31/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.5566 (1.7440) lr 1.3148e-03 eta 0:03:49
epoch [31/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.7871 (1.6772) lr 1.3148e-03 eta 0:03:47
epoch [31/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.3359 (1.6642) lr 1.3148e-03 eta 0:03:45
epoch [31/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.4121 (1.6980) lr 1.3148e-03 eta 0:03:43
epoch [32/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.6328 (1.6693) lr 1.2092e-03 eta 0:04:11
epoch [32/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.3760 (1.7192) lr 1.2092e-03 eta 0:03:53
epoch [32/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 1.7139 (1.6502) lr 1.2092e-03 eta 0:03:46
epoch [32/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.0156 (1.6323) lr 1.2092e-03 eta 0:03:42
epoch [32/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.7422 (1.6367) lr 1.2092e-03 eta 0:03:39
epoch [32/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.5225 (1.6175) lr 1.2092e-03 eta 0:03:37
epoch [32/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.5527 (1.6449) lr 1.2092e-03 eta 0:03:35
epoch [32/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.8037 (1.6520) lr 1.2092e-03 eta 0:03:33
epoch [32/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.0547 (1.6816) lr 1.2092e-03 eta 0:03:31
epoch [33/50] batch [20/188] time 0.061 (0.072) data 0.000 (0.010) loss 1.3789 (1.5176) lr 1.1058e-03 eta 0:04:01
epoch [33/50] batch [40/188] time 0.061 (0.067) data 0.000 (0.005) loss 1.7109 (1.6894) lr 1.1058e-03 eta 0:03:42
epoch [33/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.2441 (1.6569) lr 1.1058e-03 eta 0:03:35
epoch [33/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.003) loss 0.8618 (1.6789) lr 1.1058e-03 eta 0:03:31
epoch [33/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.9590 (1.6854) lr 1.1058e-03 eta 0:03:28
epoch [33/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.1250 (1.6797) lr 1.1058e-03 eta 0:03:26
epoch [33/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.2236 (1.6664) lr 1.1058e-03 eta 0:03:23
epoch [33/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.5928 (1.6581) lr 1.1058e-03 eta 0:03:22
epoch [33/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.1758 (1.6604) lr 1.1058e-03 eta 0:03:20
epoch [34/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 2.6602 (1.4690) lr 1.0049e-03 eta 0:03:44
epoch [34/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.3125 (1.5690) lr 1.0049e-03 eta 0:03:28
epoch [34/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.0703 (1.6784) lr 1.0049e-03 eta 0:03:22
epoch [34/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 0.8203 (1.6763) lr 1.0049e-03 eta 0:03:18
epoch [34/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.9243 (1.6394) lr 1.0049e-03 eta 0:03:15
epoch [34/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.0615 (1.6938) lr 1.0049e-03 eta 0:03:13
epoch [34/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.5386 (1.6628) lr 1.0049e-03 eta 0:03:11
epoch [34/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.0059 (1.6580) lr 1.0049e-03 eta 0:03:09
epoch [34/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.2490 (1.6494) lr 1.0049e-03 eta 0:03:08
epoch [35/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 1.0205 (1.6169) lr 9.0693e-04 eta 0:03:32
epoch [35/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.1680 (1.6171) lr 9.0693e-04 eta 0:03:16
epoch [35/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 0.8906 (1.6226) lr 9.0693e-04 eta 0:03:10
epoch [35/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 1.9922 (1.5554) lr 9.0693e-04 eta 0:03:06
epoch [35/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.6406 (1.5870) lr 9.0693e-04 eta 0:03:04
epoch [35/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.0205 (1.6083) lr 9.0693e-04 eta 0:03:02
epoch [35/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.9785 (1.6043) lr 9.0693e-04 eta 0:03:00
epoch [35/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.0449 (1.6142) lr 9.0693e-04 eta 0:02:58
epoch [35/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.8047 (1.6359) lr 9.0693e-04 eta 0:02:56
epoch [36/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.010) loss 1.3018 (1.6260) lr 8.1230e-04 eta 0:03:19
epoch [36/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 2.0762 (1.6865) lr 8.1230e-04 eta 0:03:04
epoch [36/50] batch [60/188] time 0.062 (0.065) data 0.000 (0.003) loss 1.1045 (1.6180) lr 8.1230e-04 eta 0:02:58
epoch [36/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.003) loss 0.9287 (1.6023) lr 8.1230e-04 eta 0:02:54
epoch [36/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.6846 (1.6255) lr 8.1230e-04 eta 0:02:52
epoch [36/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.8848 (1.6206) lr 8.1230e-04 eta 0:02:50
epoch [36/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.3203 (1.5925) lr 8.1230e-04 eta 0:02:48
epoch [36/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.6328 (1.6025) lr 8.1230e-04 eta 0:02:46
epoch [36/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.6807 (1.6250) lr 8.1230e-04 eta 0:02:45
epoch [37/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 0.5996 (1.6302) lr 7.2138e-04 eta 0:03:04
epoch [37/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.6152 (1.4479) lr 7.2138e-04 eta 0:02:51
epoch [37/50] batch [60/188] time 0.062 (0.064) data 0.000 (0.003) loss 1.8516 (1.5905) lr 7.2138e-04 eta 0:02:45
epoch [37/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 0.6724 (1.5406) lr 7.2138e-04 eta 0:02:42
epoch [37/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.4258 (1.5493) lr 7.2138e-04 eta 0:02:40
epoch [37/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.6035 (1.5832) lr 7.2138e-04 eta 0:02:38
epoch [37/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.3096 (1.6171) lr 7.2138e-04 eta 0:02:36
epoch [37/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.2256 (1.5904) lr 7.2138e-04 eta 0:02:34
epoch [37/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.3301 (1.6173) lr 7.2138e-04 eta 0:02:33
epoch [38/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 2.2754 (1.6862) lr 6.3451e-04 eta 0:02:51
epoch [38/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 3.3848 (1.6701) lr 6.3451e-04 eta 0:02:38
epoch [38/50] batch [60/188] time 0.062 (0.064) data 0.000 (0.003) loss 0.8794 (1.6026) lr 6.3451e-04 eta 0:02:33
epoch [38/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 1.5889 (1.6352) lr 6.3451e-04 eta 0:02:30
epoch [38/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.7871 (1.6260) lr 6.3451e-04 eta 0:02:28
epoch [38/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.6709 (1.6459) lr 6.3451e-04 eta 0:02:26
epoch [38/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.9229 (1.6317) lr 6.3451e-04 eta 0:02:24
epoch [38/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.4043 (1.6301) lr 6.3451e-04 eta 0:02:22
epoch [38/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.1133 (1.6225) lr 6.3451e-04 eta 0:02:21
epoch [39/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 2.0957 (1.2758) lr 5.5204e-04 eta 0:02:38
epoch [39/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.4844 (1.3574) lr 5.5204e-04 eta 0:02:26
epoch [39/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 1.1250 (1.4814) lr 5.5204e-04 eta 0:02:21
epoch [39/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.6992 (1.4756) lr 5.5204e-04 eta 0:02:18
epoch [39/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.5908 (1.4898) lr 5.5204e-04 eta 0:02:16
epoch [39/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.8779 (1.4867) lr 5.5204e-04 eta 0:02:14
epoch [39/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.9268 (1.5160) lr 5.5204e-04 eta 0:02:12
epoch [39/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.8916 (1.5390) lr 5.5204e-04 eta 0:02:11
epoch [39/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.5596 (1.5481) lr 5.5204e-04 eta 0:02:09
epoch [40/50] batch [20/188] time 0.061 (0.072) data 0.000 (0.010) loss 0.6919 (1.3074) lr 4.7430e-04 eta 0:02:26
epoch [40/50] batch [40/188] time 0.061 (0.067) data 0.000 (0.005) loss 1.0771 (1.3722) lr 4.7430e-04 eta 0:02:14
epoch [40/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 1.2754 (1.4233) lr 4.7430e-04 eta 0:02:10
epoch [40/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.003) loss 1.1572 (1.5251) lr 4.7430e-04 eta 0:02:07
epoch [40/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.0879 (1.5248) lr 4.7430e-04 eta 0:02:04
epoch [40/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 2.7969 (1.5444) lr 4.7430e-04 eta 0:02:02
epoch [40/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.6484 (1.5297) lr 4.7430e-04 eta 0:02:01
epoch [40/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.4971 (1.5464) lr 4.7430e-04 eta 0:01:59
epoch [40/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.7754 (1.5649) lr 4.7430e-04 eta 0:01:58
epoch [41/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.9902 (1.4592) lr 4.0160e-04 eta 0:02:11
epoch [41/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.5098 (1.4238) lr 4.0160e-04 eta 0:02:01
epoch [41/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.8037 (1.4501) lr 4.0160e-04 eta 0:01:57
epoch [41/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 0.8940 (1.4657) lr 4.0160e-04 eta 0:01:54
epoch [41/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.1504 (1.5062) lr 4.0160e-04 eta 0:01:52
epoch [41/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.2314 (1.5241) lr 4.0160e-04 eta 0:01:50
epoch [41/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.4619 (1.5056) lr 4.0160e-04 eta 0:01:49
epoch [41/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.2393 (1.5411) lr 4.0160e-04 eta 0:01:47
epoch [41/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.9121 (1.5563) lr 4.0160e-04 eta 0:01:46
epoch [42/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 2.1699 (1.6466) lr 3.3422e-04 eta 0:01:58
epoch [42/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 0.9741 (1.4796) lr 3.3422e-04 eta 0:01:49
epoch [42/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.5957 (1.5626) lr 3.3422e-04 eta 0:01:45
epoch [42/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 1.6357 (1.5483) lr 3.3422e-04 eta 0:01:42
epoch [42/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.6113 (1.5651) lr 3.3422e-04 eta 0:01:40
epoch [42/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.1074 (1.5741) lr 3.3422e-04 eta 0:01:39
epoch [42/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.6289 (1.5370) lr 3.3422e-04 eta 0:01:37
epoch [42/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.8945 (1.5118) lr 3.3422e-04 eta 0:01:36
epoch [42/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.9619 (1.5254) lr 3.3422e-04 eta 0:01:34
epoch [43/50] batch [20/188] time 0.061 (0.072) data 0.000 (0.011) loss 1.2568 (1.7900) lr 2.7243e-04 eta 0:01:47
epoch [43/50] batch [40/188] time 0.062 (0.067) data 0.000 (0.005) loss 1.4727 (1.6539) lr 2.7243e-04 eta 0:01:38
epoch [43/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.004) loss 1.5176 (1.6013) lr 2.7243e-04 eta 0:01:34
epoch [43/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.003) loss 3.6172 (1.5800) lr 2.7243e-04 eta 0:01:31
epoch [43/50] batch [100/188] time 0.061 (0.064) data 0.000 (0.002) loss 0.5723 (1.5254) lr 2.7243e-04 eta 0:01:29
epoch [43/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.5059 (1.4579) lr 2.7243e-04 eta 0:01:27
epoch [43/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.2891 (1.4549) lr 2.7243e-04 eta 0:01:26
epoch [43/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.9561 (1.4976) lr 2.7243e-04 eta 0:01:24
epoch [43/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.1211 (1.5097) lr 2.7243e-04 eta 0:01:23
epoch [44/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.0332 (1.5848) lr 2.1646e-04 eta 0:01:31
epoch [44/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.7969 (1.4969) lr 2.1646e-04 eta 0:01:24
epoch [44/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.0781 (1.4614) lr 2.1646e-04 eta 0:01:20
epoch [44/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 0.6860 (1.4222) lr 2.1646e-04 eta 0:01:18
epoch [44/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.3984 (1.4422) lr 2.1646e-04 eta 0:01:16
epoch [44/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 3.1016 (1.4355) lr 2.1646e-04 eta 0:01:15
epoch [44/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.2119 (1.4659) lr 2.1646e-04 eta 0:01:13
epoch [44/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.1055 (1.4903) lr 2.1646e-04 eta 0:01:12
epoch [44/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.2363 (1.5000) lr 2.1646e-04 eta 0:01:10
epoch [45/50] batch [20/188] time 0.061 (0.070) data 0.000 (0.009) loss 0.9243 (1.4863) lr 1.6655e-04 eta 0:01:18
epoch [45/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.004) loss 1.9531 (1.3852) lr 1.6655e-04 eta 0:01:11
epoch [45/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.2920 (1.4095) lr 1.6655e-04 eta 0:01:08
epoch [45/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 0.9272 (1.4116) lr 1.6655e-04 eta 0:01:06
epoch [45/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.1748 (1.3853) lr 1.6655e-04 eta 0:01:04
epoch [45/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.5840 (1.4148) lr 1.6655e-04 eta 0:01:03
epoch [45/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.9824 (1.4472) lr 1.6655e-04 eta 0:01:01
epoch [45/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.9165 (1.4845) lr 1.6655e-04 eta 0:01:00
epoch [45/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 0.9937 (1.4767) lr 1.6655e-04 eta 0:00:59
epoch [46/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.5654 (1.4667) lr 1.2289e-04 eta 0:01:05
epoch [46/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 0.9907 (1.5173) lr 1.2289e-04 eta 0:00:59
epoch [46/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 0.4893 (1.4540) lr 1.2289e-04 eta 0:00:56
epoch [46/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.002) loss 1.1016 (1.4621) lr 1.2289e-04 eta 0:00:54
epoch [46/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.3320 (1.4368) lr 1.2289e-04 eta 0:00:53
epoch [46/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.0449 (1.4686) lr 1.2289e-04 eta 0:00:51
epoch [46/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.9688 (1.4741) lr 1.2289e-04 eta 0:00:50
epoch [46/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 2.0273 (1.5019) lr 1.2289e-04 eta 0:00:48
epoch [46/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 2.7246 (1.4952) lr 1.2289e-04 eta 0:00:47
epoch [47/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.009) loss 1.7783 (1.6154) lr 8.5651e-05 eta 0:00:51
epoch [47/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 2.4492 (1.5966) lr 8.5651e-05 eta 0:00:46
epoch [47/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 2.2715 (1.5557) lr 8.5651e-05 eta 0:00:44
epoch [47/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 2.0664 (1.5232) lr 8.5651e-05 eta 0:00:42
epoch [47/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.8828 (1.5211) lr 8.5651e-05 eta 0:00:41
epoch [47/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.1748 (1.4889) lr 8.5651e-05 eta 0:00:39
epoch [47/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.6406 (1.4845) lr 8.5651e-05 eta 0:00:38
epoch [47/50] batch [160/188] time 0.062 (0.063) data 0.000 (0.001) loss 1.5107 (1.4993) lr 8.5651e-05 eta 0:00:37
epoch [47/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 0.4890 (1.4776) lr 8.5651e-05 eta 0:00:35
epoch [48/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 1.3682 (1.4598) lr 5.4979e-05 eta 0:00:38
epoch [48/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.4941 (1.4419) lr 5.4979e-05 eta 0:00:34
epoch [48/50] batch [60/188] time 0.061 (0.064) data 0.000 (0.003) loss 1.2451 (1.3643) lr 5.4979e-05 eta 0:00:32
epoch [48/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 1.1094 (1.4055) lr 5.4979e-05 eta 0:00:30
epoch [48/50] batch [100/188] time 0.062 (0.063) data 0.000 (0.002) loss 1.7939 (1.4361) lr 5.4979e-05 eta 0:00:29
epoch [48/50] batch [120/188] time 0.062 (0.063) data 0.000 (0.002) loss 2.4492 (1.4304) lr 5.4979e-05 eta 0:00:27
epoch [48/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.0342 (1.4552) lr 5.4979e-05 eta 0:00:26
epoch [48/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 2.3281 (1.4637) lr 5.4979e-05 eta 0:00:25
epoch [48/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.1436 (1.4735) lr 5.4979e-05 eta 0:00:23
epoch [49/50] batch [20/188] time 0.062 (0.071) data 0.000 (0.009) loss 1.0000 (1.1750) lr 3.0997e-05 eta 0:00:25
epoch [49/50] batch [40/188] time 0.062 (0.066) data 0.000 (0.005) loss 1.0107 (1.3005) lr 3.0997e-05 eta 0:00:22
epoch [49/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.2852 (1.4275) lr 3.0997e-05 eta 0:00:20
epoch [49/50] batch [80/188] time 0.061 (0.064) data 0.000 (0.002) loss 1.5986 (1.4472) lr 3.0997e-05 eta 0:00:18
epoch [49/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.2490 (1.4595) lr 3.0997e-05 eta 0:00:17
epoch [49/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.5771 (1.4931) lr 3.0997e-05 eta 0:00:16
epoch [49/50] batch [140/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.5791 (1.4907) lr 3.0997e-05 eta 0:00:14
epoch [49/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.5205 (1.4736) lr 3.0997e-05 eta 0:00:13
epoch [49/50] batch [180/188] time 0.061 (0.062) data 0.000 (0.001) loss 1.6328 (1.4537) lr 3.0997e-05 eta 0:00:12
epoch [50/50] batch [20/188] time 0.061 (0.071) data 0.000 (0.010) loss 2.3496 (1.3947) lr 1.3799e-05 eta 0:00:12
epoch [50/50] batch [40/188] time 0.061 (0.066) data 0.000 (0.005) loss 1.5498 (1.4702) lr 1.3799e-05 eta 0:00:09
epoch [50/50] batch [60/188] time 0.061 (0.065) data 0.000 (0.003) loss 2.1875 (1.4753) lr 1.3799e-05 eta 0:00:08
epoch [50/50] batch [80/188] time 0.062 (0.064) data 0.000 (0.003) loss 0.6187 (1.4482) lr 1.3799e-05 eta 0:00:06
epoch [50/50] batch [100/188] time 0.061 (0.063) data 0.000 (0.002) loss 1.5303 (1.4533) lr 1.3799e-05 eta 0:00:05
epoch [50/50] batch [120/188] time 0.061 (0.063) data 0.000 (0.002) loss 0.7334 (1.4682) lr 1.3799e-05 eta 0:00:04
epoch [50/50] batch [140/188] time 0.062 (0.063) data 0.000 (0.002) loss 0.8232 (1.4528) lr 1.3799e-05 eta 0:00:03
epoch [50/50] batch [160/188] time 0.061 (0.063) data 0.000 (0.001) loss 1.1523 (1.4741) lr 1.3799e-05 eta 0:00:01
epoch [50/50] batch [180/188] time 0.061 (0.063) data 0.000 (0.001) loss 0.6797 (1.4371) lr 1.3799e-05 eta 0:00:00
Checkpoint saved to output/dtd/RMaPLe/vit_b16_c2_ep50_batch4_16shots/nctx2_depth9/GCE_False/16shots_4noise/seed3/MultiModalPromptLearner/model.pth.tar-50
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 1,692
* correct: 1,114
* accuracy: 65.8%
* error: 34.2%
* macro_f1: 65.3%
Elapsed: 0:09:54
