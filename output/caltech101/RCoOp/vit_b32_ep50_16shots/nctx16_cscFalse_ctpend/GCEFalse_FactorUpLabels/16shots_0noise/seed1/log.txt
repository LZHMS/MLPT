***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/RCoOp/vit_b32_ep50.yaml
dataset_config_file: configs/datasets/caltech101.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
num_fp: 0
opts: ['TRAINER.RCOOP.N_CTX', '16', 'TRAINER.RCOOP.CSC', 'False', 'TRAINER.RCOOP.CLASS_TOKEN_POSITION', 'end', 'DATASET.NUM_SHOTS', '16']
output_dir: output/caltech101/RCoOp/vit_b32_ep50_16shots/nctx16_cscFalse_ctpend/GCEFalse_FactorUpLabels/16shots_0noise/seed1
prompt_depth: 9
resume: 
root: data
seed: 1
source_domains: None
target_domains: None
trainer: RCoOp
transforms: None
use_robustloss: False
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 100
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Caltech101
  NUM_EXPAND: 5
  NUM_FP: 0
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: data
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: all
  TARGET_DOMAINS: ()
  USE_ROBUSTLOSS: False
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/32
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.002
  LR_SCHEDULER: cosine
  MAX_EPOCH: 50
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/caltech101/RCoOp/vit_b32_ep50_16shots/nctx16_cscFalse_ctpend/GCEFalse_FactorUpLabels/16shots_0noise/seed1
RESUME: 
SEED: 1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 5
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  COCOOP:
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  COOP:
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MAPLE:
    CTX_INIT: a photo of a
    N_CTX: 2
    PREC: fp16
    PROMPT_DEPTH: 9
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: RCoOp
  RCOOP:
    ALPHA: 4
    CLASS_TOKEN_POSITION: end
    CSC: False
    CTX_INIT: 
    N_CTX: 16
    PREC: fp16
    TEM: 0.5
  RMAPLE:
    CTX_INIT: a photo of a
    N_CTX: 2
    PREC: fp16
    PROMPT_DEPTH: 9
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
WARMUP:
  EPOCH: 10
  THRESHOLD: 0.5
Collecting env info ...
** System info **
PyTorch version: 1.11.0
Is debug build: False
CUDA used to build PyTorch: 11.3
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: Could not collect
GPU models and configuration: 
GPU 0: NVIDIA GeForce RTX 2080 Ti
GPU 1: NVIDIA GeForce RTX 2080 Ti

Nvidia driver version: 470.86
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.24.3
[pip3] torch==1.11.0
[pip3] torchvision==0.12.0
[conda] blas                      1.0                         mkl    defaults
[conda] cudatoolkit               11.3.1               h2bc3f7f_2    defaults
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2021.4.0           h06a4308_640    defaults
[conda] mkl-service               2.4.0            py38h7f8727e_0    defaults
[conda] mkl_fft                   1.3.1            py38hd3c417c_0    defaults
[conda] mkl_random                1.2.2            py38h51133e4_0    defaults
[conda] numpy                     1.24.3           py38h14f4228_0    defaults
[conda] numpy-base                1.24.3           py38h31eccc5_0    defaults
[conda] pytorch                   1.11.0          py3.8_cuda11.3_cudnn8.2.0_0    https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchvision               0.12.0               py38_cu113    https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch
        Pillow (9.4.0)

Loading trainer: RCoOp
Loading dataset: Caltech101
Reading split from /home/zhli/projects/RMaPLe/data/caltech-101/split_zhou_Caltech101.json
Loading preprocessed noisy few-shot data from /home/zhli/projects/RMaPLe/data/caltech-101/split_fewshot/shot_16-numfp_0-seed_1.pkl
Loading preprocessed noisy expand data from /home/zhli/projects/RMaPLe/data/caltech-101/split_expand/shot_80-numfp_0-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  ----------
Dataset    Caltech101
# classes  100
# train_x  1,600
# val      1,600
# test     2,465
---------  ----------
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Loading CLIP (backbone: ViT-B/32)
Building custom CLIP (Two CLIP models)
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Initializing a generic context
Initial context: "X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/caltech101/RCoOp/vit_b32_ep50_16shots/nctx16_cscFalse_ctpend/GCEFalse_FactorUpLabels/16shots_0noise/seed1/tensorboard)
Warmup CLIP1
epoch [1/50] batch [5/50] time 0.095 (0.279) data 0.000 (0.063) loss 3.1133 (3.1492) acc 34.3750 (30.0000) lr 1.0000e-05 eta 0:11:36
epoch [1/50] batch [10/50] time 0.095 (0.187) data 0.000 (0.031) loss 2.7227 (2.8742) acc 46.8750 (41.2500) lr 1.0000e-05 eta 0:07:45
epoch [1/50] batch [15/50] time 0.095 (0.156) data 0.000 (0.021) loss 1.9971 (2.6479) acc 68.7500 (48.1250) lr 1.0000e-05 eta 0:06:28
epoch [1/50] batch [20/50] time 0.095 (0.141) data 0.000 (0.016) loss 2.1016 (2.4750) acc 56.2500 (51.4062) lr 1.0000e-05 eta 0:05:49
epoch [1/50] batch [25/50] time 0.095 (0.132) data 0.000 (0.013) loss 1.7354 (2.3286) acc 65.6250 (54.5000) lr 1.0000e-05 eta 0:05:25
epoch [1/50] batch [30/50] time 0.095 (0.125) data 0.000 (0.011) loss 1.1816 (2.1962) acc 65.6250 (56.3542) lr 1.0000e-05 eta 0:05:09
epoch [1/50] batch [35/50] time 0.095 (0.121) data 0.000 (0.009) loss 1.7910 (2.1027) acc 53.1250 (57.2321) lr 1.0000e-05 eta 0:04:58
epoch [1/50] batch [40/50] time 0.094 (0.118) data 0.000 (0.008) loss 1.3643 (1.9939) acc 68.7500 (59.1406) lr 1.0000e-05 eta 0:04:49
epoch [1/50] batch [45/50] time 0.094 (0.115) data 0.000 (0.007) loss 1.0986 (1.9263) acc 75.0000 (60.0000) lr 1.0000e-05 eta 0:04:42
epoch [1/50] batch [50/50] time 0.094 (0.113) data 0.000 (0.006) loss 0.6924 (1.8400) acc 81.2500 (61.2500) lr 2.0000e-03 eta 0:04:36
Warmup CLIP2
epoch [1/50] batch [5/50] time 0.095 (0.143) data 0.000 (0.048) loss 2.3301 (2.1887) acc 43.7500 (57.5000) lr 2.0000e-03 eta 0:05:55
epoch [1/50] batch [10/50] time 0.095 (0.119) data 0.000 (0.024) loss 2.5449 (2.2110) acc 37.5000 (56.5625) lr 2.0000e-03 eta 0:04:55
epoch [1/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 1.6777 (2.0837) acc 56.2500 (57.9167) lr 2.0000e-03 eta 0:04:34
epoch [1/50] batch [20/50] time 0.094 (0.107) data 0.000 (0.012) loss 1.6836 (1.9190) acc 65.6250 (61.7188) lr 2.0000e-03 eta 0:04:24
epoch [1/50] batch [25/50] time 0.095 (0.104) data 0.000 (0.010) loss 1.3779 (1.8403) acc 71.8750 (62.7500) lr 2.0000e-03 eta 0:04:17
epoch [1/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 1.3887 (1.7290) acc 78.1250 (64.8958) lr 2.0000e-03 eta 0:04:13
epoch [1/50] batch [35/50] time 0.094 (0.101) data 0.000 (0.007) loss 0.8193 (1.6482) acc 75.0000 (65.5357) lr 2.0000e-03 eta 0:04:10
epoch [1/50] batch [40/50] time 0.094 (0.101) data 0.000 (0.006) loss 0.9717 (1.5927) acc 75.0000 (66.2500) lr 2.0000e-03 eta 0:04:07
epoch [1/50] batch [45/50] time 0.094 (0.100) data 0.000 (0.005) loss 0.7773 (1.5207) acc 81.2500 (67.2917) lr 2.0000e-03 eta 0:04:05
epoch [1/50] batch [50/50] time 0.094 (0.099) data 0.000 (0.005) loss 1.0254 (1.5011) acc 84.3750 (67.3125) lr 2.0000e-03 eta 0:04:03
Warmup CLIP1
epoch [2/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.050) loss 0.9404 (1.1609) acc 75.0000 (68.7500) lr 2.0000e-03 eta 0:05:53
epoch [2/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.025) loss 1.0908 (1.0885) acc 75.0000 (71.8750) lr 2.0000e-03 eta 0:04:51
epoch [2/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.017) loss 0.4924 (0.9890) acc 87.5000 (74.3750) lr 2.0000e-03 eta 0:04:30
epoch [2/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 1.3408 (0.9522) acc 71.8750 (75.1562) lr 2.0000e-03 eta 0:04:20
epoch [2/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.9399 (0.9236) acc 68.7500 (75.6250) lr 2.0000e-03 eta 0:04:13
epoch [2/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 1.1475 (0.8928) acc 65.6250 (75.6250) lr 2.0000e-03 eta 0:04:09
epoch [2/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.8550 (0.9042) acc 75.0000 (75.2679) lr 2.0000e-03 eta 0:04:06
epoch [2/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.3667 (0.8977) acc 90.6250 (75.6250) lr 2.0000e-03 eta 0:04:03
epoch [2/50] batch [45/50] time 0.094 (0.100) data 0.000 (0.006) loss 1.1924 (0.8936) acc 68.7500 (75.8333) lr 2.0000e-03 eta 0:04:01
epoch [2/50] batch [50/50] time 0.094 (0.100) data 0.000 (0.005) loss 1.1016 (0.8845) acc 71.8750 (76.1875) lr 1.9980e-03 eta 0:03:59
Warmup CLIP2
epoch [2/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.049) loss 1.2666 (1.1410) acc 59.3750 (71.2500) lr 1.9980e-03 eta 0:05:52
epoch [2/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.025) loss 0.9565 (1.0857) acc 71.8750 (72.1875) lr 1.9980e-03 eta 0:04:51
epoch [2/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 0.6904 (1.0081) acc 81.2500 (73.1250) lr 1.9980e-03 eta 0:04:31
epoch [2/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.6597 (0.9328) acc 81.2500 (75.0000) lr 1.9980e-03 eta 0:04:20
epoch [2/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.8936 (0.8992) acc 68.7500 (75.6250) lr 1.9980e-03 eta 0:04:14
epoch [2/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.5591 (0.8609) acc 81.2500 (76.4583) lr 1.9980e-03 eta 0:04:09
epoch [2/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 1.3242 (0.8801) acc 65.6250 (75.7143) lr 1.9980e-03 eta 0:04:06
epoch [2/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 1.0010 (0.8822) acc 78.1250 (75.5469) lr 1.9980e-03 eta 0:04:03
epoch [2/50] batch [45/50] time 0.094 (0.100) data 0.000 (0.006) loss 0.7793 (0.8810) acc 75.0000 (75.5556) lr 1.9980e-03 eta 0:04:01
epoch [2/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.9893 (0.8650) acc 71.8750 (76.0625) lr 1.9980e-03 eta 0:03:59
Warmup CLIP1
epoch [3/50] batch [5/50] time 0.095 (0.143) data 0.000 (0.048) loss 0.6489 (0.6596) acc 81.2500 (85.0000) lr 1.9980e-03 eta 0:05:43
epoch [3/50] batch [10/50] time 0.095 (0.119) data 0.000 (0.024) loss 0.5410 (0.6060) acc 84.3750 (84.6875) lr 1.9980e-03 eta 0:04:44
epoch [3/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 0.8892 (0.6614) acc 71.8750 (82.7083) lr 1.9980e-03 eta 0:04:24
epoch [3/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.7603 (0.6668) acc 75.0000 (81.5625) lr 1.9980e-03 eta 0:04:14
epoch [3/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.5894 (0.6830) acc 81.2500 (80.8750) lr 1.9980e-03 eta 0:04:08
epoch [3/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.8071 (0.6911) acc 78.1250 (80.9375) lr 1.9980e-03 eta 0:04:04
epoch [3/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.4824 (0.7093) acc 87.5000 (80.8036) lr 1.9980e-03 eta 0:04:00
epoch [3/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.6841 (0.7170) acc 75.0000 (80.8594) lr 1.9980e-03 eta 0:03:58
epoch [3/50] batch [45/50] time 0.094 (0.100) data 0.000 (0.005) loss 0.8115 (0.7303) acc 75.0000 (80.1389) lr 1.9980e-03 eta 0:03:56
epoch [3/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.6191 (0.7379) acc 78.1250 (80.0000) lr 1.9921e-03 eta 0:03:54
Warmup CLIP2
epoch [3/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.048) loss 0.8809 (0.8329) acc 71.8750 (76.2500) lr 1.9921e-03 eta 0:05:45
epoch [3/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.024) loss 0.9639 (0.8184) acc 75.0000 (76.8750) lr 1.9921e-03 eta 0:04:45
epoch [3/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 1.1846 (0.8423) acc 65.6250 (75.6250) lr 1.9921e-03 eta 0:04:25
epoch [3/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.9263 (0.8103) acc 71.8750 (76.4062) lr 1.9921e-03 eta 0:04:15
epoch [3/50] batch [25/50] time 0.096 (0.105) data 0.000 (0.010) loss 1.1807 (0.8483) acc 78.1250 (76.3750) lr 1.9921e-03 eta 0:04:09
epoch [3/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.7212 (0.8266) acc 71.8750 (77.6042) lr 1.9921e-03 eta 0:04:04
epoch [3/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.7114 (0.8320) acc 75.0000 (77.2321) lr 1.9921e-03 eta 0:04:01
epoch [3/50] batch [40/50] time 0.094 (0.101) data 0.000 (0.006) loss 0.8813 (0.8192) acc 78.1250 (77.5000) lr 1.9921e-03 eta 0:03:58
epoch [3/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.9390 (0.8021) acc 81.2500 (78.1944) lr 1.9921e-03 eta 0:03:56
epoch [3/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.8994 (0.7959) acc 81.2500 (78.5000) lr 1.9921e-03 eta 0:03:54
Warmup CLIP1
epoch [4/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.049) loss 1.1045 (0.7153) acc 68.7500 (78.1250) lr 1.9921e-03 eta 0:05:37
epoch [4/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.024) loss 0.9839 (0.7657) acc 71.8750 (79.6875) lr 1.9921e-03 eta 0:04:39
epoch [4/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 0.7690 (0.7622) acc 84.3750 (79.3750) lr 1.9921e-03 eta 0:04:19
epoch [4/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.5073 (0.7560) acc 84.3750 (78.7500) lr 1.9921e-03 eta 0:04:09
epoch [4/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.5000 (0.7259) acc 84.3750 (79.6250) lr 1.9921e-03 eta 0:04:03
epoch [4/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.9473 (0.6930) acc 75.0000 (80.4167) lr 1.9921e-03 eta 0:03:59
epoch [4/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.7520 (0.6934) acc 71.8750 (80.4464) lr 1.9921e-03 eta 0:03:56
epoch [4/50] batch [40/50] time 0.094 (0.101) data 0.000 (0.006) loss 0.1427 (0.6905) acc 93.7500 (80.6250) lr 1.9921e-03 eta 0:03:53
epoch [4/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.006) loss 0.7031 (0.6997) acc 81.2500 (80.7639) lr 1.9921e-03 eta 0:03:51
epoch [4/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.8306 (0.6909) acc 75.0000 (80.6875) lr 1.9823e-03 eta 0:03:49
Warmup CLIP2
epoch [4/50] batch [5/50] time 0.095 (0.147) data 0.000 (0.052) loss 0.8354 (0.6827) acc 71.8750 (81.2500) lr 1.9823e-03 eta 0:05:44
epoch [4/50] batch [10/50] time 0.095 (0.121) data 0.000 (0.026) loss 1.1201 (0.7508) acc 78.1250 (80.9375) lr 1.9823e-03 eta 0:04:42
epoch [4/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.017) loss 0.9624 (0.8097) acc 71.8750 (78.3333) lr 1.9823e-03 eta 0:04:22
epoch [4/50] batch [20/50] time 0.095 (0.108) data 0.000 (0.013) loss 0.4622 (0.7906) acc 81.2500 (78.9062) lr 1.9823e-03 eta 0:04:11
epoch [4/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.7783 (0.7861) acc 78.1250 (79.1250) lr 1.9823e-03 eta 0:04:04
epoch [4/50] batch [30/50] time 0.095 (0.104) data 0.000 (0.009) loss 0.8379 (0.7974) acc 68.7500 (78.8542) lr 1.9823e-03 eta 0:04:00
epoch [4/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.6221 (0.7814) acc 84.3750 (79.3750) lr 1.9823e-03 eta 0:03:57
epoch [4/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.007) loss 0.6606 (0.7928) acc 81.2500 (79.0625) lr 1.9823e-03 eta 0:03:54
epoch [4/50] batch [45/50] time 0.094 (0.101) data 0.000 (0.006) loss 0.6113 (0.7795) acc 87.5000 (79.4444) lr 1.9823e-03 eta 0:03:51
epoch [4/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.9165 (0.7736) acc 71.8750 (79.2500) lr 1.9823e-03 eta 0:03:50
Warmup CLIP1
epoch [5/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.049) loss 0.3606 (0.7061) acc 93.7500 (80.0000) lr 1.9823e-03 eta 0:05:30
epoch [5/50] batch [10/50] time 0.095 (0.119) data 0.000 (0.024) loss 1.1240 (0.7133) acc 71.8750 (79.3750) lr 1.9823e-03 eta 0:04:33
epoch [5/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 0.2404 (0.6371) acc 96.8750 (81.6667) lr 1.9823e-03 eta 0:04:14
epoch [5/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.7563 (0.6228) acc 81.2500 (82.5000) lr 1.9823e-03 eta 0:04:04
epoch [5/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.6416 (0.6538) acc 78.1250 (82.1250) lr 1.9823e-03 eta 0:03:58
epoch [5/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.5811 (0.6567) acc 87.5000 (81.9792) lr 1.9823e-03 eta 0:03:54
epoch [5/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.9233 (0.6866) acc 78.1250 (81.1607) lr 1.9823e-03 eta 0:03:50
epoch [5/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.9199 (0.7069) acc 71.8750 (80.5469) lr 1.9823e-03 eta 0:03:48
epoch [5/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.006) loss 0.5137 (0.7205) acc 81.2500 (79.9306) lr 1.9823e-03 eta 0:03:46
epoch [5/50] batch [50/50] time 0.094 (0.100) data 0.000 (0.005) loss 0.5269 (0.7265) acc 87.5000 (79.7500) lr 1.9686e-03 eta 0:03:44
Warmup CLIP2
epoch [5/50] batch [5/50] time 0.095 (0.145) data 0.000 (0.050) loss 0.9072 (0.8261) acc 65.6250 (79.3750) lr 1.9686e-03 eta 0:05:32
epoch [5/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.025) loss 0.4561 (0.6927) acc 84.3750 (81.8750) lr 1.9686e-03 eta 0:04:34
epoch [5/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.017) loss 0.7974 (0.7226) acc 78.1250 (80.6250) lr 1.9686e-03 eta 0:04:15
epoch [5/50] batch [20/50] time 0.095 (0.108) data 0.000 (0.013) loss 0.5015 (0.7011) acc 84.3750 (81.2500) lr 1.9686e-03 eta 0:04:05
epoch [5/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.4736 (0.6954) acc 84.3750 (80.7500) lr 1.9686e-03 eta 0:03:58
epoch [5/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 1.4053 (0.7288) acc 62.5000 (79.7917) lr 1.9686e-03 eta 0:03:54
epoch [5/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.6343 (0.7114) acc 78.1250 (79.9107) lr 1.9686e-03 eta 0:03:51
epoch [5/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.6499 (0.7107) acc 87.5000 (80.1562) lr 1.9686e-03 eta 0:03:48
epoch [5/50] batch [45/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.5259 (0.7079) acc 87.5000 (80.1389) lr 1.9686e-03 eta 0:03:46
epoch [5/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.9688 (0.7190) acc 81.2500 (80.1250) lr 1.9686e-03 eta 0:03:44
Warmup CLIP1
epoch [6/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.048) loss 0.4353 (0.5564) acc 90.6250 (82.5000) lr 1.9686e-03 eta 0:05:23
epoch [6/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.024) loss 0.8237 (0.6327) acc 75.0000 (81.8750) lr 1.9686e-03 eta 0:04:27
epoch [6/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 1.0039 (0.6535) acc 75.0000 (82.0833) lr 1.9686e-03 eta 0:04:08
epoch [6/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.7319 (0.6427) acc 71.8750 (80.7812) lr 1.9686e-03 eta 0:03:59
epoch [6/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 1.0332 (0.6745) acc 68.7500 (79.8750) lr 1.9686e-03 eta 0:03:53
epoch [6/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.7144 (0.6875) acc 78.1250 (80.0000) lr 1.9686e-03 eta 0:03:49
epoch [6/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.9399 (0.6858) acc 81.2500 (80.3571) lr 1.9686e-03 eta 0:03:46
epoch [6/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.6973 (0.6907) acc 84.3750 (80.6250) lr 1.9686e-03 eta 0:03:43
epoch [6/50] batch [45/50] time 0.094 (0.100) data 0.000 (0.005) loss 0.4646 (0.6754) acc 81.2500 (81.0417) lr 1.9686e-03 eta 0:03:41
epoch [6/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.4097 (0.6703) acc 90.6250 (81.3125) lr 1.9511e-03 eta 0:03:39
Warmup CLIP2
epoch [6/50] batch [5/50] time 0.095 (0.145) data 0.000 (0.049) loss 0.2554 (0.5479) acc 90.6250 (84.3750) lr 1.9511e-03 eta 0:05:24
epoch [6/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.024) loss 0.4031 (0.6658) acc 87.5000 (80.3125) lr 1.9511e-03 eta 0:04:28
epoch [6/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.016) loss 0.9434 (0.7267) acc 75.0000 (80.2083) lr 1.9511e-03 eta 0:04:09
epoch [6/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.4905 (0.7144) acc 93.7500 (80.6250) lr 1.9511e-03 eta 0:03:59
epoch [6/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.4316 (0.6954) acc 87.5000 (81.0000) lr 1.9511e-03 eta 0:03:53
epoch [6/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.8096 (0.7118) acc 78.1250 (80.2083) lr 1.9511e-03 eta 0:03:49
epoch [6/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.6592 (0.7528) acc 84.3750 (79.2857) lr 1.9511e-03 eta 0:03:46
epoch [6/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.6821 (0.7497) acc 84.3750 (79.0625) lr 1.9511e-03 eta 0:03:43
epoch [6/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.006) loss 0.5122 (0.7442) acc 84.3750 (79.0972) lr 1.9511e-03 eta 0:03:41
epoch [6/50] batch [50/50] time 0.094 (0.100) data 0.000 (0.005) loss 1.2383 (0.7465) acc 65.6250 (78.6875) lr 1.9511e-03 eta 0:03:39
Warmup CLIP1
epoch [7/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.049) loss 0.5767 (0.7165) acc 81.2500 (79.3750) lr 1.9511e-03 eta 0:05:16
epoch [7/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.025) loss 0.4399 (0.6992) acc 90.6250 (80.6250) lr 1.9511e-03 eta 0:04:22
epoch [7/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 0.5361 (0.7256) acc 84.3750 (79.7917) lr 1.9511e-03 eta 0:04:03
epoch [7/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.6616 (0.7001) acc 75.0000 (79.8438) lr 1.9511e-03 eta 0:03:54
epoch [7/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.8911 (0.7106) acc 84.3750 (79.8750) lr 1.9511e-03 eta 0:03:48
epoch [7/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.5674 (0.7040) acc 90.6250 (80.2083) lr 1.9511e-03 eta 0:03:44
epoch [7/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.4744 (0.7055) acc 87.5000 (80.5357) lr 1.9511e-03 eta 0:03:40
epoch [7/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 1.1553 (0.7056) acc 68.7500 (80.6250) lr 1.9511e-03 eta 0:03:38
epoch [7/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.006) loss 0.5996 (0.6930) acc 78.1250 (80.7639) lr 1.9511e-03 eta 0:03:36
epoch [7/50] batch [50/50] time 0.094 (0.100) data 0.000 (0.005) loss 0.8975 (0.6940) acc 78.1250 (80.6250) lr 1.9298e-03 eta 0:03:34
Warmup CLIP2
epoch [7/50] batch [5/50] time 0.095 (0.146) data 0.000 (0.050) loss 0.7036 (0.7550) acc 71.8750 (78.1250) lr 1.9298e-03 eta 0:05:19
epoch [7/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.025) loss 0.6675 (0.7772) acc 81.2500 (77.1875) lr 1.9298e-03 eta 0:04:23
epoch [7/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.017) loss 0.5078 (0.7424) acc 84.3750 (78.5417) lr 1.9298e-03 eta 0:04:04
epoch [7/50] batch [20/50] time 0.095 (0.108) data 0.000 (0.013) loss 0.8174 (0.7340) acc 68.7500 (78.2812) lr 1.9298e-03 eta 0:03:54
epoch [7/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.5166 (0.7100) acc 84.3750 (78.6250) lr 1.9298e-03 eta 0:03:48
epoch [7/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.7344 (0.6867) acc 81.2500 (79.1667) lr 1.9298e-03 eta 0:03:44
epoch [7/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.5713 (0.6758) acc 81.2500 (79.9107) lr 1.9298e-03 eta 0:03:41
epoch [7/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.6880 (0.6905) acc 81.2500 (79.8438) lr 1.9298e-03 eta 0:03:38
epoch [7/50] batch [45/50] time 0.094 (0.101) data 0.000 (0.006) loss 0.8457 (0.6895) acc 75.0000 (79.4444) lr 1.9298e-03 eta 0:03:36
epoch [7/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.5728 (0.6911) acc 90.6250 (79.7500) lr 1.9298e-03 eta 0:03:34
Warmup CLIP1
epoch [8/50] batch [5/50] time 0.095 (0.146) data 0.000 (0.051) loss 0.6694 (0.6167) acc 78.1250 (76.8750) lr 1.9298e-03 eta 0:05:12
epoch [8/50] batch [10/50] time 0.095 (0.121) data 0.000 (0.025) loss 0.5698 (0.6244) acc 84.3750 (79.0625) lr 1.9298e-03 eta 0:04:17
epoch [8/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.017) loss 0.5415 (0.5923) acc 90.6250 (81.8750) lr 1.9298e-03 eta 0:03:59
epoch [8/50] batch [20/50] time 0.095 (0.108) data 0.000 (0.013) loss 0.6851 (0.5980) acc 81.2500 (81.7188) lr 1.9298e-03 eta 0:03:49
epoch [8/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.9346 (0.6050) acc 68.7500 (81.5000) lr 1.9298e-03 eta 0:03:43
epoch [8/50] batch [30/50] time 0.095 (0.104) data 0.000 (0.009) loss 0.6191 (0.6141) acc 87.5000 (81.4583) lr 1.9298e-03 eta 0:03:39
epoch [8/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.7500 (0.6188) acc 78.1250 (81.7857) lr 1.9298e-03 eta 0:03:36
epoch [8/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.5015 (0.6285) acc 78.1250 (81.4062) lr 1.9298e-03 eta 0:03:33
epoch [8/50] batch [45/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.6011 (0.6073) acc 81.2500 (82.1528) lr 1.9298e-03 eta 0:03:31
epoch [8/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.7495 (0.6310) acc 75.0000 (81.6250) lr 1.9048e-03 eta 0:03:30
Warmup CLIP2
epoch [8/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.048) loss 0.7920 (0.7539) acc 81.2500 (83.1250) lr 1.9048e-03 eta 0:05:08
epoch [8/50] batch [10/50] time 0.095 (0.119) data 0.000 (0.024) loss 0.7036 (0.6714) acc 84.3750 (82.5000) lr 1.9048e-03 eta 0:04:15
epoch [8/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 0.3811 (0.6265) acc 84.3750 (82.9167) lr 1.9048e-03 eta 0:03:57
epoch [8/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.4272 (0.6202) acc 84.3750 (82.1875) lr 1.9048e-03 eta 0:03:48
epoch [8/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.3806 (0.6081) acc 87.5000 (82.1250) lr 1.9048e-03 eta 0:03:42
epoch [8/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.5186 (0.6249) acc 84.3750 (82.1875) lr 1.9048e-03 eta 0:03:38
epoch [8/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 1.0674 (0.6242) acc 71.8750 (82.3214) lr 1.9048e-03 eta 0:03:35
epoch [8/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.8242 (0.6248) acc 71.8750 (82.0312) lr 1.9048e-03 eta 0:03:33
epoch [8/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.005) loss 1.1064 (0.6688) acc 68.7500 (81.1111) lr 1.9048e-03 eta 0:03:31
epoch [8/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 1.0811 (0.6911) acc 71.8750 (80.3750) lr 1.9048e-03 eta 0:03:29
Warmup CLIP1
epoch [9/50] batch [5/50] time 0.095 (0.146) data 0.000 (0.051) loss 0.9365 (0.7304) acc 65.6250 (78.7500) lr 1.9048e-03 eta 0:05:06
epoch [9/50] batch [10/50] time 0.095 (0.121) data 0.000 (0.025) loss 0.8535 (0.6951) acc 78.1250 (81.5625) lr 1.9048e-03 eta 0:04:12
epoch [9/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.017) loss 0.9312 (0.7142) acc 68.7500 (80.4167) lr 1.9048e-03 eta 0:03:53
epoch [9/50] batch [20/50] time 0.095 (0.108) data 0.000 (0.013) loss 0.6777 (0.7008) acc 81.2500 (80.7812) lr 1.9048e-03 eta 0:03:44
epoch [9/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.2583 (0.6571) acc 90.6250 (81.6250) lr 1.9048e-03 eta 0:03:38
epoch [9/50] batch [30/50] time 0.095 (0.104) data 0.000 (0.009) loss 0.9614 (0.6677) acc 75.0000 (80.4167) lr 1.9048e-03 eta 0:03:34
epoch [9/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.7407 (0.6860) acc 75.0000 (79.9107) lr 1.9048e-03 eta 0:03:31
epoch [9/50] batch [40/50] time 0.094 (0.101) data 0.000 (0.006) loss 1.3809 (0.7071) acc 68.7500 (79.6094) lr 1.9048e-03 eta 0:03:29
epoch [9/50] batch [45/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.7261 (0.7122) acc 84.3750 (79.3750) lr 1.9048e-03 eta 0:03:26
epoch [9/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.6343 (0.6911) acc 81.2500 (80.0625) lr 1.8763e-03 eta 0:03:25
Warmup CLIP2
epoch [9/50] batch [5/50] time 0.095 (0.144) data 0.000 (0.049) loss 0.8696 (0.6093) acc 71.8750 (79.3750) lr 1.8763e-03 eta 0:05:02
epoch [9/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.025) loss 0.9692 (0.6046) acc 68.7500 (80.9375) lr 1.8763e-03 eta 0:04:10
epoch [9/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.016) loss 0.9492 (0.7181) acc 65.6250 (77.7083) lr 1.8763e-03 eta 0:03:52
epoch [9/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.4985 (0.7089) acc 87.5000 (79.2188) lr 1.8763e-03 eta 0:03:43
epoch [9/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.9053 (0.7601) acc 71.8750 (78.3750) lr 1.8763e-03 eta 0:03:37
epoch [9/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.4668 (0.7367) acc 87.5000 (79.0625) lr 1.8763e-03 eta 0:03:33
epoch [9/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.7402 (0.7068) acc 78.1250 (79.9107) lr 1.8763e-03 eta 0:03:30
epoch [9/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.5015 (0.6910) acc 90.6250 (80.7812) lr 1.8763e-03 eta 0:03:28
epoch [9/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.006) loss 0.6606 (0.6821) acc 75.0000 (80.7639) lr 1.8763e-03 eta 0:03:26
epoch [9/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.7798 (0.6790) acc 78.1250 (80.8750) lr 1.8763e-03 eta 0:03:24
Warmup CLIP1
epoch [10/50] batch [5/50] time 0.095 (0.146) data 0.000 (0.050) loss 0.8301 (0.6800) acc 71.8750 (78.1250) lr 1.8763e-03 eta 0:04:57
epoch [10/50] batch [10/50] time 0.095 (0.120) data 0.000 (0.025) loss 0.4519 (0.7182) acc 90.6250 (78.4375) lr 1.8763e-03 eta 0:04:05
epoch [10/50] batch [15/50] time 0.095 (0.112) data 0.000 (0.017) loss 0.6543 (0.7086) acc 78.1250 (78.5417) lr 1.8763e-03 eta 0:03:47
epoch [10/50] batch [20/50] time 0.095 (0.108) data 0.000 (0.013) loss 0.7271 (0.7116) acc 78.1250 (78.5938) lr 1.8763e-03 eta 0:03:38
epoch [10/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.9434 (0.6770) acc 71.8750 (79.7500) lr 1.8763e-03 eta 0:03:33
epoch [10/50] batch [30/50] time 0.095 (0.104) data 0.000 (0.008) loss 0.7559 (0.7092) acc 78.1250 (79.3750) lr 1.8763e-03 eta 0:03:29
epoch [10/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 1.3301 (0.7475) acc 71.8750 (78.9286) lr 1.8763e-03 eta 0:03:26
epoch [10/50] batch [40/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.5234 (0.7238) acc 81.2500 (79.7656) lr 1.8763e-03 eta 0:03:23
epoch [10/50] batch [45/50] time 0.095 (0.101) data 0.000 (0.006) loss 0.8232 (0.7240) acc 81.2500 (80.0000) lr 1.8763e-03 eta 0:03:21
epoch [10/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.3489 (0.7012) acc 90.6250 (80.3750) lr 1.8443e-03 eta 0:03:20
Warmup CLIP2
epoch [10/50] batch [5/50] time 0.095 (0.143) data 0.000 (0.048) loss 0.7197 (0.6722) acc 78.1250 (80.6250) lr 1.8443e-03 eta 0:04:52
epoch [10/50] batch [10/50] time 0.095 (0.119) data 0.000 (0.024) loss 0.6597 (0.7464) acc 75.0000 (78.1250) lr 1.8443e-03 eta 0:04:03
epoch [10/50] batch [15/50] time 0.095 (0.111) data 0.000 (0.016) loss 0.7065 (0.7349) acc 84.3750 (78.9583) lr 1.8443e-03 eta 0:03:46
epoch [10/50] batch [20/50] time 0.095 (0.107) data 0.000 (0.012) loss 0.5928 (0.7492) acc 81.2500 (78.4375) lr 1.8443e-03 eta 0:03:37
epoch [10/50] batch [25/50] time 0.095 (0.105) data 0.000 (0.010) loss 0.4507 (0.7122) acc 87.5000 (79.6250) lr 1.8443e-03 eta 0:03:32
epoch [10/50] batch [30/50] time 0.095 (0.103) data 0.000 (0.008) loss 0.5562 (0.7190) acc 81.2500 (79.5833) lr 1.8443e-03 eta 0:03:28
epoch [10/50] batch [35/50] time 0.095 (0.102) data 0.000 (0.007) loss 0.6143 (0.7081) acc 81.2500 (80.1786) lr 1.8443e-03 eta 0:03:25
epoch [10/50] batch [40/50] time 0.094 (0.101) data 0.000 (0.006) loss 0.6069 (0.6853) acc 81.2500 (81.0156) lr 1.8443e-03 eta 0:03:23
epoch [10/50] batch [45/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.5518 (0.6734) acc 84.3750 (81.3889) lr 1.8443e-03 eta 0:03:21
epoch [10/50] batch [50/50] time 0.095 (0.100) data 0.000 (0.005) loss 0.4956 (0.6669) acc 84.3750 (81.4375) lr 1.8443e-03 eta 0:03:19
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [11/50] batch [5/45] time 0.646 (0.519) data 0.000 (0.085) loss 0.6694 (0.5337) acc 84.3750 (86.8750) lr 1.8443e-03 eta 0:15:31
epoch [11/50] batch [10/45] time 0.380 (0.485) data 0.000 (0.043) loss 0.5739 (0.5813) acc 81.2500 (84.3750) lr 1.8443e-03 eta 0:14:28
epoch [11/50] batch [15/45] time 0.380 (0.472) data 0.000 (0.029) loss 1.0768 (0.6029) acc 71.8750 (84.1667) lr 1.8443e-03 eta 0:14:01
epoch [11/50] batch [20/45] time 0.380 (0.463) data 0.000 (0.021) loss 0.3564 (0.5929) acc 90.6250 (84.3750) lr 1.8443e-03 eta 0:13:43
epoch [11/50] batch [25/45] time 0.714 (0.473) data 0.000 (0.017) loss 0.6352 (0.5626) acc 78.1250 (84.8750) lr 1.8443e-03 eta 0:13:58
epoch [11/50] batch [30/45] time 0.380 (0.467) data 0.000 (0.014) loss 0.7373 (0.5652) acc 84.3750 (84.6875) lr 1.8443e-03 eta 0:13:46
epoch [11/50] batch [35/45] time 0.380 (0.464) data 0.000 (0.012) loss 0.2915 (0.5448) acc 87.5000 (84.9107) lr 1.8443e-03 eta 0:13:38
epoch [11/50] batch [40/45] time 0.380 (0.461) data 0.000 (0.011) loss 0.5091 (0.5326) acc 90.6250 (85.5469) lr 1.8443e-03 eta 0:13:32
epoch [11/50] batch [45/45] time 0.708 (0.467) data 0.000 (0.010) loss 0.6665 (0.5446) acc 84.3750 (85.2778) lr 1.8090e-03 eta 0:13:39
Train CLIP2
Creating a 16-shot dataset
epoch [11/50] batch [5/46] time 0.380 (0.537) data 0.000 (0.088) loss 0.6271 (0.5733) acc 87.5000 (82.5000) lr 1.8090e-03 eta 0:16:24
epoch [11/50] batch [10/46] time 0.705 (0.524) data 0.000 (0.044) loss 0.4265 (0.5116) acc 90.6250 (85.6250) lr 1.8090e-03 eta 0:15:59
epoch [11/50] batch [15/46] time 0.380 (0.498) data 0.000 (0.029) loss 0.4066 (0.5063) acc 90.6250 (86.6667) lr 1.8090e-03 eta 0:15:08
epoch [11/50] batch [20/46] time 0.380 (0.501) data 0.000 (0.022) loss 0.4758 (0.5406) acc 87.5000 (85.6250) lr 1.8090e-03 eta 0:15:11
epoch [11/50] batch [25/46] time 0.671 (0.500) data 0.000 (0.018) loss 0.3665 (0.5271) acc 84.3750 (85.8750) lr 1.8090e-03 eta 0:15:07
epoch [11/50] batch [30/46] time 0.380 (0.489) data 0.000 (0.015) loss 0.4377 (0.5528) acc 93.7500 (85.8333) lr 1.8090e-03 eta 0:14:45
epoch [11/50] batch [35/46] time 0.379 (0.490) data 0.000 (0.013) loss 0.9469 (0.5792) acc 78.1250 (85.5357) lr 1.8090e-03 eta 0:14:43
epoch [11/50] batch [40/46] time 0.649 (0.489) data 0.000 (0.011) loss 0.6516 (0.5641) acc 84.3750 (85.7812) lr 1.8090e-03 eta 0:14:41
epoch [11/50] batch [45/46] time 0.380 (0.483) data 0.000 (0.010) loss 1.0057 (0.5901) acc 81.2500 (85.3472) lr 1.8090e-03 eta 0:14:27
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [12/50] batch [5/45] time 0.655 (0.519) data 0.000 (0.084) loss 0.6595 (0.3742) acc 81.2500 (88.1250) lr 1.8090e-03 eta 0:15:08
epoch [12/50] batch [10/45] time 0.380 (0.478) data 0.000 (0.042) loss 0.7319 (0.4051) acc 78.1250 (88.1250) lr 1.8090e-03 eta 0:13:54
epoch [12/50] batch [15/45] time 0.380 (0.465) data 0.000 (0.028) loss 0.6410 (0.4438) acc 81.2500 (87.0833) lr 1.8090e-03 eta 0:13:28
epoch [12/50] batch [20/45] time 0.380 (0.458) data 0.000 (0.021) loss 0.3919 (0.4299) acc 90.6250 (87.5000) lr 1.8090e-03 eta 0:13:13
epoch [12/50] batch [25/45] time 0.668 (0.465) data 0.000 (0.017) loss 0.5615 (0.4415) acc 87.5000 (87.1250) lr 1.8090e-03 eta 0:13:24
epoch [12/50] batch [30/45] time 0.380 (0.460) data 0.000 (0.014) loss 0.5551 (0.4847) acc 84.3750 (86.2500) lr 1.8090e-03 eta 0:13:13
epoch [12/50] batch [35/45] time 0.380 (0.456) data 0.000 (0.012) loss 0.3898 (0.5099) acc 90.6250 (86.1607) lr 1.8090e-03 eta 0:13:05
epoch [12/50] batch [40/45] time 0.380 (0.454) data 0.000 (0.011) loss 0.4387 (0.5013) acc 90.6250 (86.4062) lr 1.8090e-03 eta 0:12:58
epoch [12/50] batch [45/45] time 0.660 (0.458) data 0.000 (0.010) loss 0.2902 (0.5038) acc 93.7500 (86.5278) lr 1.7705e-03 eta 0:13:03
Train CLIP2
Creating a 16-shot dataset
epoch [12/50] batch [5/46] time 0.380 (0.529) data 0.000 (0.087) loss 0.6136 (0.6531) acc 78.1250 (78.7500) lr 1.7705e-03 eta 0:15:46
epoch [12/50] batch [10/46] time 0.659 (0.510) data 0.000 (0.043) loss 1.0284 (0.6339) acc 75.0000 (82.8125) lr 1.7705e-03 eta 0:15:09
epoch [12/50] batch [15/46] time 0.380 (0.486) data 0.000 (0.029) loss 0.4822 (0.5865) acc 87.5000 (84.1667) lr 1.7705e-03 eta 0:14:23
epoch [12/50] batch [20/46] time 0.380 (0.487) data 0.000 (0.022) loss 0.4071 (0.5951) acc 81.2500 (83.1250) lr 1.7705e-03 eta 0:14:23
epoch [12/50] batch [25/46] time 0.657 (0.488) data 0.000 (0.017) loss 0.2125 (0.5443) acc 90.6250 (84.0000) lr 1.7705e-03 eta 0:14:23
epoch [12/50] batch [30/46] time 0.380 (0.481) data 0.000 (0.015) loss 0.3678 (0.5398) acc 93.7500 (84.5833) lr 1.7705e-03 eta 0:14:07
epoch [12/50] batch [35/46] time 0.379 (0.482) data 0.000 (0.013) loss 0.9363 (0.5444) acc 78.1250 (84.7321) lr 1.7705e-03 eta 0:14:07
epoch [12/50] batch [40/46] time 0.650 (0.483) data 0.000 (0.011) loss 0.4983 (0.5519) acc 84.3750 (84.5312) lr 1.7705e-03 eta 0:14:07
epoch [12/50] batch [45/46] time 0.379 (0.478) data 0.000 (0.010) loss 0.6708 (0.5529) acc 81.2500 (84.5833) lr 1.7705e-03 eta 0:13:55
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [13/50] batch [5/45] time 0.600 (0.494) data 0.000 (0.071) loss 0.4644 (0.6002) acc 84.3750 (84.3750) lr 1.7705e-03 eta 0:14:02
epoch [13/50] batch [10/45] time 0.380 (0.466) data 0.000 (0.036) loss 0.4808 (0.6310) acc 90.6250 (84.0625) lr 1.7705e-03 eta 0:13:12
epoch [13/50] batch [15/45] time 0.380 (0.456) data 0.000 (0.024) loss 0.8315 (0.6204) acc 81.2500 (84.1667) lr 1.7705e-03 eta 0:12:53
epoch [13/50] batch [20/45] time 0.380 (0.452) data 0.000 (0.018) loss 0.7928 (0.6189) acc 81.2500 (84.2188) lr 1.7705e-03 eta 0:12:43
epoch [13/50] batch [25/45] time 0.665 (0.460) data 0.000 (0.014) loss 0.4339 (0.6169) acc 87.5000 (84.3750) lr 1.7705e-03 eta 0:12:55
epoch [13/50] batch [30/45] time 0.379 (0.456) data 0.000 (0.012) loss 0.3455 (0.5912) acc 90.6250 (84.6875) lr 1.7705e-03 eta 0:12:46
epoch [13/50] batch [35/45] time 0.380 (0.454) data 0.000 (0.010) loss 0.4569 (0.5514) acc 90.6250 (85.8929) lr 1.7705e-03 eta 0:12:39
epoch [13/50] batch [40/45] time 0.380 (0.451) data 0.000 (0.009) loss 0.6025 (0.5479) acc 84.3750 (85.9375) lr 1.7705e-03 eta 0:12:33
epoch [13/50] batch [45/45] time 0.669 (0.456) data 0.000 (0.008) loss 0.0767 (0.5477) acc 96.8750 (86.1111) lr 1.7290e-03 eta 0:12:38
Train CLIP2
Creating a 16-shot dataset
epoch [13/50] batch [5/45] time 0.653 (0.528) data 0.000 (0.093) loss 0.6230 (0.5536) acc 84.3750 (85.0000) lr 1.7290e-03 eta 0:15:00
epoch [13/50] batch [10/45] time 0.380 (0.484) data 0.000 (0.047) loss 0.5210 (0.5335) acc 87.5000 (85.9375) lr 1.7290e-03 eta 0:13:42
epoch [13/50] batch [15/45] time 0.380 (0.469) data 0.000 (0.031) loss 0.4727 (0.4929) acc 81.2500 (87.0833) lr 1.7290e-03 eta 0:13:14
epoch [13/50] batch [20/45] time 0.380 (0.461) data 0.000 (0.023) loss 0.5809 (0.5230) acc 78.1250 (86.2500) lr 1.7290e-03 eta 0:12:58
epoch [13/50] batch [25/45] time 0.659 (0.467) data 0.000 (0.019) loss 0.5240 (0.5408) acc 84.3750 (86.0000) lr 1.7290e-03 eta 0:13:06
epoch [13/50] batch [30/45] time 0.379 (0.462) data 0.000 (0.016) loss 0.3445 (0.5390) acc 87.5000 (85.7292) lr 1.7290e-03 eta 0:12:55
epoch [13/50] batch [35/45] time 0.380 (0.458) data 0.000 (0.013) loss 0.5500 (0.5197) acc 84.3750 (86.1607) lr 1.7290e-03 eta 0:12:47
epoch [13/50] batch [40/45] time 0.380 (0.455) data 0.000 (0.012) loss 0.3334 (0.5053) acc 87.5000 (86.2500) lr 1.7290e-03 eta 0:12:40
epoch [13/50] batch [45/45] time 0.672 (0.460) data 0.000 (0.010) loss 0.8610 (0.5169) acc 75.0000 (85.7639) lr 1.7290e-03 eta 0:12:46
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [14/50] batch [5/45] time 0.661 (0.524) data 0.000 (0.088) loss 0.6621 (0.5981) acc 78.1250 (85.0000) lr 1.7290e-03 eta 0:14:30
epoch [14/50] batch [10/45] time 0.380 (0.484) data 0.000 (0.044) loss 0.4765 (0.5702) acc 90.6250 (86.2500) lr 1.7290e-03 eta 0:13:21
epoch [14/50] batch [15/45] time 0.380 (0.468) data 0.000 (0.029) loss 0.3467 (0.4963) acc 87.5000 (87.2917) lr 1.7290e-03 eta 0:12:52
epoch [14/50] batch [20/45] time 0.380 (0.462) data 0.000 (0.022) loss 0.6265 (0.4945) acc 84.3750 (87.3438) lr 1.7290e-03 eta 0:12:39
epoch [14/50] batch [25/45] time 0.689 (0.469) data 0.000 (0.018) loss 0.5281 (0.5078) acc 84.3750 (87.0000) lr 1.7290e-03 eta 0:12:49
epoch [14/50] batch [30/45] time 0.379 (0.464) data 0.000 (0.015) loss 0.3515 (0.5408) acc 90.6250 (85.9375) lr 1.7290e-03 eta 0:12:38
epoch [14/50] batch [35/45] time 0.379 (0.460) data 0.000 (0.013) loss 0.9113 (0.5510) acc 75.0000 (85.7143) lr 1.7290e-03 eta 0:12:29
epoch [14/50] batch [40/45] time 0.380 (0.457) data 0.000 (0.011) loss 0.2818 (0.5548) acc 90.6250 (85.7812) lr 1.7290e-03 eta 0:12:22
epoch [14/50] batch [45/45] time 0.655 (0.461) data 0.000 (0.010) loss 1.0088 (0.5604) acc 75.0000 (85.6944) lr 1.6845e-03 eta 0:12:26
Train CLIP2
Creating a 16-shot dataset
epoch [14/50] batch [5/46] time 0.380 (0.524) data 0.000 (0.089) loss 0.1369 (0.4169) acc 90.6250 (88.1250) lr 1.6845e-03 eta 0:14:49
epoch [14/50] batch [10/46] time 0.604 (0.503) data 0.000 (0.044) loss 0.2639 (0.5042) acc 93.7500 (86.2500) lr 1.6845e-03 eta 0:14:10
epoch [14/50] batch [15/46] time 0.380 (0.481) data 0.000 (0.030) loss 0.7980 (0.5674) acc 78.1250 (84.7917) lr 1.6845e-03 eta 0:13:31
epoch [14/50] batch [20/46] time 0.379 (0.479) data 0.000 (0.022) loss 0.6902 (0.5721) acc 75.0000 (84.3750) lr 1.6845e-03 eta 0:13:25
epoch [14/50] batch [25/46] time 0.670 (0.482) data 0.000 (0.018) loss 0.2007 (0.5511) acc 90.6250 (84.1250) lr 1.6845e-03 eta 0:13:27
epoch [14/50] batch [30/46] time 0.379 (0.472) data 0.000 (0.015) loss 1.0839 (0.5769) acc 75.0000 (83.5417) lr 1.6845e-03 eta 0:13:09
epoch [14/50] batch [35/46] time 0.379 (0.473) data 0.000 (0.013) loss 0.5142 (0.5705) acc 87.5000 (83.8393) lr 1.6845e-03 eta 0:13:08
epoch [14/50] batch [40/46] time 0.652 (0.474) data 0.000 (0.011) loss 0.2227 (0.5486) acc 93.7500 (84.6094) lr 1.6845e-03 eta 0:13:07
epoch [14/50] batch [45/46] time 0.378 (0.470) data 0.000 (0.010) loss 0.6384 (0.5379) acc 84.3750 (85.0694) lr 1.6845e-03 eta 0:12:58
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [15/50] batch [5/45] time 0.663 (0.521) data 0.000 (0.084) loss 0.4184 (0.5287) acc 87.5000 (85.0000) lr 1.6845e-03 eta 0:14:01
epoch [15/50] batch [10/45] time 0.380 (0.478) data 0.000 (0.042) loss 0.5299 (0.5969) acc 78.1250 (83.1250) lr 1.6845e-03 eta 0:12:49
epoch [15/50] batch [15/45] time 0.380 (0.465) data 0.000 (0.028) loss 0.2347 (0.6078) acc 96.8750 (83.9583) lr 1.6845e-03 eta 0:12:26
epoch [15/50] batch [20/45] time 0.380 (0.459) data 0.000 (0.021) loss 0.3731 (0.5774) acc 93.7500 (84.8438) lr 1.6845e-03 eta 0:12:15
epoch [15/50] batch [25/45] time 0.694 (0.467) data 0.000 (0.017) loss 0.3911 (0.5363) acc 93.7500 (86.2500) lr 1.6845e-03 eta 0:12:25
epoch [15/50] batch [30/45] time 0.380 (0.462) data 0.000 (0.014) loss 0.6126 (0.5557) acc 81.2500 (86.0417) lr 1.6845e-03 eta 0:12:14
epoch [15/50] batch [35/45] time 0.379 (0.458) data 0.000 (0.012) loss 0.2526 (0.5302) acc 93.7500 (86.3393) lr 1.6845e-03 eta 0:12:06
epoch [15/50] batch [40/45] time 0.380 (0.456) data 0.000 (0.011) loss 0.4021 (0.5099) acc 84.3750 (86.6406) lr 1.6845e-03 eta 0:12:00
epoch [15/50] batch [45/45] time 0.670 (0.460) data 0.000 (0.009) loss 0.3393 (0.5158) acc 90.6250 (86.4583) lr 1.6374e-03 eta 0:12:05
Train CLIP2
Creating a 16-shot dataset
epoch [15/50] batch [5/46] time 0.380 (0.522) data 0.000 (0.086) loss 0.5576 (0.5800) acc 90.6250 (85.6250) lr 1.6374e-03 eta 0:14:22
epoch [15/50] batch [10/46] time 0.653 (0.507) data 0.000 (0.043) loss 0.5119 (0.5216) acc 84.3750 (86.2500) lr 1.6374e-03 eta 0:13:54
epoch [15/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.029) loss 0.5325 (0.5273) acc 87.5000 (86.0417) lr 1.6374e-03 eta 0:13:16
epoch [15/50] batch [20/46] time 0.380 (0.488) data 0.000 (0.022) loss 0.4075 (0.5035) acc 84.3750 (86.2500) lr 1.6374e-03 eta 0:13:17
epoch [15/50] batch [25/46] time 0.655 (0.489) data 0.000 (0.017) loss 0.2801 (0.5156) acc 90.6250 (85.6250) lr 1.6374e-03 eta 0:13:16
epoch [15/50] batch [30/46] time 0.380 (0.480) data 0.000 (0.015) loss 0.5185 (0.5164) acc 87.5000 (86.1458) lr 1.6374e-03 eta 0:13:00
epoch [15/50] batch [35/46] time 0.380 (0.482) data 0.000 (0.012) loss 0.5728 (0.5062) acc 84.3750 (86.4286) lr 1.6374e-03 eta 0:13:00
epoch [15/50] batch [40/46] time 0.659 (0.483) data 0.000 (0.011) loss 0.2594 (0.5094) acc 93.7500 (86.5625) lr 1.6374e-03 eta 0:13:00
epoch [15/50] batch [45/46] time 0.379 (0.478) data 0.000 (0.010) loss 0.3732 (0.4971) acc 84.3750 (86.6667) lr 1.6374e-03 eta 0:12:49
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [16/50] batch [5/45] time 0.684 (0.536) data 0.000 (0.095) loss 0.6275 (0.5958) acc 84.3750 (81.8750) lr 1.6374e-03 eta 0:14:01
epoch [16/50] batch [10/45] time 0.380 (0.486) data 0.000 (0.048) loss 0.4617 (0.4984) acc 90.6250 (86.2500) lr 1.6374e-03 eta 0:12:41
epoch [16/50] batch [15/45] time 0.380 (0.471) data 0.000 (0.032) loss 0.1792 (0.4809) acc 93.7500 (86.6667) lr 1.6374e-03 eta 0:12:14
epoch [16/50] batch [20/45] time 0.380 (0.462) data 0.000 (0.024) loss 0.4985 (0.4663) acc 81.2500 (87.3438) lr 1.6374e-03 eta 0:11:59
epoch [16/50] batch [25/45] time 0.671 (0.469) data 0.000 (0.019) loss 0.8029 (0.4928) acc 78.1250 (86.7500) lr 1.6374e-03 eta 0:12:07
epoch [16/50] batch [30/45] time 0.380 (0.465) data 0.000 (0.016) loss 0.5854 (0.5032) acc 90.6250 (86.5625) lr 1.6374e-03 eta 0:11:57
epoch [16/50] batch [35/45] time 0.380 (0.461) data 0.000 (0.014) loss 0.7907 (0.5043) acc 81.2500 (86.6964) lr 1.6374e-03 eta 0:11:50
epoch [16/50] batch [40/45] time 0.379 (0.458) data 0.000 (0.012) loss 0.3624 (0.5259) acc 87.5000 (86.0938) lr 1.6374e-03 eta 0:11:43
epoch [16/50] batch [45/45] time 0.660 (0.462) data 0.000 (0.011) loss 0.7913 (0.5328) acc 75.0000 (85.7639) lr 1.5878e-03 eta 0:11:47
Train CLIP2
Creating a 16-shot dataset
epoch [16/50] batch [5/45] time 0.680 (0.535) data 0.000 (0.096) loss 0.3937 (0.4645) acc 84.3750 (87.5000) lr 1.5878e-03 eta 0:14:00
epoch [16/50] batch [10/45] time 0.380 (0.489) data 0.000 (0.048) loss 0.9275 (0.5030) acc 75.0000 (85.9375) lr 1.5878e-03 eta 0:12:44
epoch [16/50] batch [15/45] time 0.380 (0.473) data 0.000 (0.032) loss 0.2685 (0.5158) acc 90.6250 (85.8333) lr 1.5878e-03 eta 0:12:18
epoch [16/50] batch [20/45] time 0.380 (0.464) data 0.000 (0.024) loss 0.2721 (0.5026) acc 90.6250 (86.8750) lr 1.5878e-03 eta 0:12:01
epoch [16/50] batch [25/45] time 0.663 (0.471) data 0.000 (0.019) loss 0.3063 (0.4969) acc 90.6250 (86.7500) lr 1.5878e-03 eta 0:12:10
epoch [16/50] batch [30/45] time 0.380 (0.467) data 0.000 (0.016) loss 0.2696 (0.5154) acc 90.6250 (86.4583) lr 1.5878e-03 eta 0:12:00
epoch [16/50] batch [35/45] time 0.379 (0.462) data 0.000 (0.014) loss 0.2208 (0.5154) acc 93.7500 (86.4286) lr 1.5878e-03 eta 0:11:51
epoch [16/50] batch [40/45] time 0.380 (0.459) data 0.000 (0.012) loss 0.3083 (0.5072) acc 90.6250 (86.6406) lr 1.5878e-03 eta 0:11:44
epoch [16/50] batch [45/45] time 0.655 (0.463) data 0.000 (0.011) loss 0.6126 (0.5144) acc 81.2500 (86.2500) lr 1.5878e-03 eta 0:11:47
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [17/50] batch [5/45] time 0.670 (0.535) data 0.000 (0.096) loss 0.8185 (0.4832) acc 78.1250 (86.8750) lr 1.5878e-03 eta 0:13:35
epoch [17/50] batch [10/45] time 0.380 (0.487) data 0.000 (0.048) loss 0.4033 (0.5269) acc 84.3750 (84.6875) lr 1.5878e-03 eta 0:12:19
epoch [17/50] batch [15/45] time 0.380 (0.470) data 0.000 (0.032) loss 0.2166 (0.5056) acc 93.7500 (85.2083) lr 1.5878e-03 eta 0:11:52
epoch [17/50] batch [20/45] time 0.380 (0.463) data 0.000 (0.024) loss 0.2476 (0.5290) acc 93.7500 (84.8438) lr 1.5878e-03 eta 0:11:39
epoch [17/50] batch [25/45] time 0.667 (0.470) data 0.000 (0.019) loss 0.4175 (0.5189) acc 84.3750 (85.1250) lr 1.5878e-03 eta 0:11:47
epoch [17/50] batch [30/45] time 0.380 (0.464) data 0.000 (0.016) loss 0.5984 (0.5046) acc 84.3750 (85.8333) lr 1.5878e-03 eta 0:11:36
epoch [17/50] batch [35/45] time 0.379 (0.460) data 0.000 (0.014) loss 0.4947 (0.5212) acc 90.6250 (85.0000) lr 1.5878e-03 eta 0:11:28
epoch [17/50] batch [40/45] time 0.380 (0.458) data 0.000 (0.012) loss 0.2258 (0.5044) acc 93.7500 (85.7031) lr 1.5878e-03 eta 0:11:21
epoch [17/50] batch [45/45] time 0.661 (0.462) data 0.000 (0.011) loss 0.2657 (0.5010) acc 93.7500 (85.7639) lr 1.5358e-03 eta 0:11:26
Train CLIP2
Creating a 16-shot dataset
epoch [17/50] batch [5/46] time 0.380 (0.525) data 0.000 (0.088) loss 1.1025 (0.6728) acc 78.1250 (82.5000) lr 1.5358e-03 eta 0:13:38
epoch [17/50] batch [10/46] time 0.610 (0.504) data 0.000 (0.044) loss 0.5256 (0.7110) acc 81.2500 (79.6875) lr 1.5358e-03 eta 0:13:03
epoch [17/50] batch [15/46] time 0.380 (0.478) data 0.000 (0.029) loss 0.4620 (0.6818) acc 81.2500 (80.0000) lr 1.5358e-03 eta 0:12:20
epoch [17/50] batch [20/46] time 0.379 (0.480) data 0.000 (0.022) loss 0.6875 (0.6536) acc 81.2500 (81.5625) lr 1.5358e-03 eta 0:12:21
epoch [17/50] batch [25/46] time 0.607 (0.479) data 0.000 (0.018) loss 0.6465 (0.6356) acc 84.3750 (82.3750) lr 1.5358e-03 eta 0:12:16
epoch [17/50] batch [30/46] time 0.379 (0.472) data 0.000 (0.015) loss 0.1673 (0.5875) acc 100.0000 (84.0625) lr 1.5358e-03 eta 0:12:03
epoch [17/50] batch [35/46] time 0.380 (0.474) data 0.000 (0.013) loss 1.2414 (0.6000) acc 71.8750 (84.0179) lr 1.5358e-03 eta 0:12:04
epoch [17/50] batch [40/46] time 0.658 (0.477) data 0.000 (0.011) loss 0.6459 (0.5982) acc 78.1250 (84.1406) lr 1.5358e-03 eta 0:12:06
epoch [17/50] batch [45/46] time 0.379 (0.472) data 0.000 (0.010) loss 0.7884 (0.5875) acc 81.2500 (84.1667) lr 1.5358e-03 eta 0:11:57
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [18/50] batch [5/45] time 0.682 (0.533) data 0.000 (0.093) loss 0.2581 (0.4985) acc 90.6250 (86.8750) lr 1.5358e-03 eta 0:13:09
epoch [18/50] batch [10/45] time 0.380 (0.485) data 0.000 (0.046) loss 0.7972 (0.4984) acc 78.1250 (86.8750) lr 1.5358e-03 eta 0:11:55
epoch [18/50] batch [15/45] time 0.380 (0.470) data 0.000 (0.031) loss 0.6659 (0.5359) acc 78.1250 (85.8333) lr 1.5358e-03 eta 0:11:30
epoch [18/50] batch [20/45] time 0.380 (0.463) data 0.000 (0.023) loss 0.1484 (0.4965) acc 90.6250 (86.8750) lr 1.5358e-03 eta 0:11:17
epoch [18/50] batch [25/45] time 0.700 (0.470) data 0.000 (0.019) loss 0.9004 (0.5057) acc 81.2500 (86.6250) lr 1.5358e-03 eta 0:11:26
epoch [18/50] batch [30/45] time 0.380 (0.465) data 0.000 (0.016) loss 0.4474 (0.5113) acc 90.6250 (86.0417) lr 1.5358e-03 eta 0:11:17
epoch [18/50] batch [35/45] time 0.380 (0.461) data 0.000 (0.013) loss 0.3526 (0.4971) acc 90.6250 (86.4286) lr 1.5358e-03 eta 0:11:08
epoch [18/50] batch [40/45] time 0.380 (0.459) data 0.000 (0.012) loss 0.6133 (0.4997) acc 81.2500 (86.6406) lr 1.5358e-03 eta 0:11:02
epoch [18/50] batch [45/45] time 0.664 (0.463) data 0.000 (0.010) loss 0.2709 (0.5084) acc 90.6250 (86.4583) lr 1.4818e-03 eta 0:11:06
Train CLIP2
Creating a 16-shot dataset
epoch [18/50] batch [5/45] time 0.668 (0.535) data 0.000 (0.097) loss 0.6228 (0.5688) acc 78.1250 (85.6250) lr 1.4818e-03 eta 0:13:11
epoch [18/50] batch [10/45] time 0.380 (0.485) data 0.000 (0.049) loss 0.4187 (0.5443) acc 90.6250 (85.9375) lr 1.4818e-03 eta 0:11:56
epoch [18/50] batch [15/45] time 0.380 (0.470) data 0.000 (0.032) loss 0.6111 (0.5694) acc 81.2500 (85.4167) lr 1.4818e-03 eta 0:11:31
epoch [18/50] batch [20/45] time 0.380 (0.462) data 0.000 (0.024) loss 0.5357 (0.5591) acc 90.6250 (86.0938) lr 1.4818e-03 eta 0:11:16
epoch [18/50] batch [25/45] time 0.606 (0.466) data 0.000 (0.020) loss 0.7218 (0.5730) acc 87.5000 (86.1250) lr 1.4818e-03 eta 0:11:20
epoch [18/50] batch [30/45] time 0.380 (0.461) data 0.000 (0.016) loss 0.5112 (0.5759) acc 90.6250 (86.0417) lr 1.4818e-03 eta 0:11:11
epoch [18/50] batch [35/45] time 0.380 (0.458) data 0.000 (0.014) loss 0.4770 (0.5549) acc 87.5000 (86.3393) lr 1.4818e-03 eta 0:11:04
epoch [18/50] batch [40/45] time 0.380 (0.455) data 0.000 (0.012) loss 0.2810 (0.5453) acc 90.6250 (86.6406) lr 1.4818e-03 eta 0:10:58
epoch [18/50] batch [45/45] time 0.657 (0.460) data 0.000 (0.011) loss 0.3815 (0.5260) acc 93.7500 (87.2917) lr 1.4818e-03 eta 0:11:01
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [19/50] batch [5/45] time 0.662 (0.531) data 0.000 (0.094) loss 0.7731 (0.5056) acc 84.3750 (86.2500) lr 1.4818e-03 eta 0:12:41
epoch [19/50] batch [10/45] time 0.380 (0.485) data 0.000 (0.047) loss 0.5471 (0.4273) acc 75.0000 (87.8125) lr 1.4818e-03 eta 0:11:33
epoch [19/50] batch [15/45] time 0.380 (0.469) data 0.000 (0.031) loss 1.0261 (0.5143) acc 71.8750 (86.0417) lr 1.4818e-03 eta 0:11:08
epoch [19/50] batch [20/45] time 0.380 (0.461) data 0.000 (0.024) loss 0.7786 (0.5072) acc 81.2500 (86.0938) lr 1.4818e-03 eta 0:10:54
epoch [19/50] batch [25/45] time 0.687 (0.469) data 0.000 (0.019) loss 0.5512 (0.4845) acc 87.5000 (86.6250) lr 1.4818e-03 eta 0:11:03
epoch [19/50] batch [30/45] time 0.379 (0.464) data 0.000 (0.016) loss 0.5713 (0.5087) acc 90.6250 (86.3542) lr 1.4818e-03 eta 0:10:54
epoch [19/50] batch [35/45] time 0.379 (0.460) data 0.000 (0.014) loss 0.6976 (0.5004) acc 87.5000 (86.7857) lr 1.4818e-03 eta 0:10:46
epoch [19/50] batch [40/45] time 0.379 (0.458) data 0.000 (0.012) loss 0.5578 (0.4945) acc 87.5000 (87.0312) lr 1.4818e-03 eta 0:10:40
epoch [19/50] batch [45/45] time 0.664 (0.462) data 0.000 (0.011) loss 0.5853 (0.5134) acc 90.6250 (86.6667) lr 1.4258e-03 eta 0:10:44
Train CLIP2
Creating a 16-shot dataset
epoch [19/50] batch [5/45] time 0.667 (0.527) data 0.000 (0.089) loss 0.5362 (0.4049) acc 87.5000 (88.1250) lr 1.4258e-03 eta 0:12:36
epoch [19/50] batch [10/45] time 0.380 (0.484) data 0.000 (0.045) loss 0.7818 (0.4751) acc 84.3750 (86.8750) lr 1.4258e-03 eta 0:11:31
epoch [19/50] batch [15/45] time 0.380 (0.468) data 0.000 (0.030) loss 0.4047 (0.4912) acc 87.5000 (86.0417) lr 1.4258e-03 eta 0:11:07
epoch [19/50] batch [20/45] time 0.380 (0.461) data 0.000 (0.022) loss 0.2188 (0.4850) acc 96.8750 (86.2500) lr 1.4258e-03 eta 0:10:54
epoch [19/50] batch [25/45] time 0.675 (0.468) data 0.000 (0.018) loss 1.0441 (0.5452) acc 78.1250 (84.6250) lr 1.4258e-03 eta 0:11:02
epoch [19/50] batch [30/45] time 0.380 (0.464) data 0.000 (0.015) loss 0.8323 (0.5384) acc 78.1250 (85.2083) lr 1.4258e-03 eta 0:10:53
epoch [19/50] batch [35/45] time 0.380 (0.458) data 0.000 (0.013) loss 0.5258 (0.5267) acc 84.3750 (85.5357) lr 1.4258e-03 eta 0:10:43
epoch [19/50] batch [40/45] time 0.378 (0.456) data 0.000 (0.011) loss 0.3537 (0.5255) acc 87.5000 (85.3906) lr 1.4258e-03 eta 0:10:38
epoch [19/50] batch [45/45] time 0.675 (0.459) data 0.000 (0.010) loss 0.5388 (0.5201) acc 81.2500 (85.6250) lr 1.4258e-03 eta 0:10:40
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [20/50] batch [5/45] time 0.658 (0.524) data 0.000 (0.088) loss 0.4855 (0.5722) acc 87.5000 (85.0000) lr 1.4258e-03 eta 0:12:08
epoch [20/50] batch [10/45] time 0.380 (0.481) data 0.000 (0.044) loss 0.3750 (0.5320) acc 87.5000 (85.6250) lr 1.4258e-03 eta 0:11:06
epoch [20/50] batch [15/45] time 0.380 (0.466) data 0.000 (0.030) loss 0.2440 (0.5335) acc 96.8750 (86.8750) lr 1.4258e-03 eta 0:10:43
epoch [20/50] batch [20/45] time 0.380 (0.459) data 0.000 (0.022) loss 0.5759 (0.5266) acc 81.2500 (86.4062) lr 1.4258e-03 eta 0:10:31
epoch [20/50] batch [25/45] time 0.669 (0.466) data 0.000 (0.018) loss 0.4315 (0.5392) acc 90.6250 (86.3750) lr 1.4258e-03 eta 0:10:39
epoch [20/50] batch [30/45] time 0.380 (0.462) data 0.000 (0.015) loss 0.2020 (0.5104) acc 96.8750 (86.7708) lr 1.4258e-03 eta 0:10:30
epoch [20/50] batch [35/45] time 0.380 (0.458) data 0.000 (0.013) loss 0.6566 (0.5499) acc 81.2500 (85.6250) lr 1.4258e-03 eta 0:10:23
epoch [20/50] batch [40/45] time 0.379 (0.456) data 0.000 (0.011) loss 0.5922 (0.5369) acc 90.6250 (85.9375) lr 1.4258e-03 eta 0:10:17
epoch [20/50] batch [45/45] time 0.667 (0.460) data 0.000 (0.010) loss 0.4116 (0.5428) acc 87.5000 (85.4167) lr 1.3681e-03 eta 0:10:21
Train CLIP2
Creating a 16-shot dataset
epoch [20/50] batch [5/45] time 0.617 (0.517) data 0.000 (0.090) loss 1.0814 (0.5877) acc 75.0000 (86.2500) lr 1.3681e-03 eta 0:11:59
epoch [20/50] batch [10/45] time 0.380 (0.477) data 0.000 (0.045) loss 0.3655 (0.5569) acc 84.3750 (86.2500) lr 1.3681e-03 eta 0:11:00
epoch [20/50] batch [15/45] time 0.380 (0.464) data 0.000 (0.030) loss 0.2631 (0.5025) acc 96.8750 (87.0833) lr 1.3681e-03 eta 0:10:40
epoch [20/50] batch [20/45] time 0.380 (0.458) data 0.000 (0.023) loss 0.5369 (0.4984) acc 87.5000 (86.8750) lr 1.3681e-03 eta 0:10:30
epoch [20/50] batch [25/45] time 0.608 (0.464) data 0.000 (0.018) loss 0.5299 (0.4801) acc 87.5000 (87.5000) lr 1.3681e-03 eta 0:10:35
epoch [20/50] batch [30/45] time 0.379 (0.458) data 0.000 (0.015) loss 0.2694 (0.4886) acc 90.6250 (87.3958) lr 1.3681e-03 eta 0:10:24
epoch [20/50] batch [35/45] time 0.380 (0.455) data 0.000 (0.013) loss 0.8522 (0.4903) acc 78.1250 (87.4107) lr 1.3681e-03 eta 0:10:18
epoch [20/50] batch [40/45] time 0.380 (0.453) data 0.000 (0.011) loss 0.7811 (0.5361) acc 81.2500 (86.0938) lr 1.3681e-03 eta 0:10:13
epoch [20/50] batch [45/45] time 0.654 (0.457) data 0.000 (0.010) loss 0.3488 (0.5152) acc 90.6250 (86.8750) lr 1.3681e-03 eta 0:10:17
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [21/50] batch [5/45] time 0.612 (0.513) data 0.000 (0.087) loss 0.7739 (0.6035) acc 75.0000 (82.5000) lr 1.3681e-03 eta 0:11:30
epoch [21/50] batch [10/45] time 0.380 (0.470) data 0.000 (0.044) loss 0.3212 (0.5469) acc 90.6250 (83.7500) lr 1.3681e-03 eta 0:10:29
epoch [21/50] batch [15/45] time 0.379 (0.460) data 0.000 (0.029) loss 0.5363 (0.5315) acc 84.3750 (85.0000) lr 1.3681e-03 eta 0:10:13
epoch [21/50] batch [20/45] time 0.379 (0.451) data 0.000 (0.022) loss 0.5497 (0.5288) acc 87.5000 (85.6250) lr 1.3681e-03 eta 0:10:00
epoch [21/50] batch [25/45] time 0.667 (0.460) data 0.000 (0.018) loss 0.2074 (0.4714) acc 90.6250 (87.2500) lr 1.3681e-03 eta 0:10:09
epoch [21/50] batch [30/45] time 0.380 (0.456) data 0.000 (0.015) loss 0.1351 (0.4322) acc 96.8750 (88.3333) lr 1.3681e-03 eta 0:10:02
epoch [21/50] batch [35/45] time 0.380 (0.454) data 0.000 (0.013) loss 0.0973 (0.4218) acc 96.8750 (88.5714) lr 1.3681e-03 eta 0:09:56
epoch [21/50] batch [40/45] time 0.380 (0.452) data 0.000 (0.011) loss 0.7737 (0.4553) acc 84.3750 (88.2031) lr 1.3681e-03 eta 0:09:52
epoch [21/50] batch [45/45] time 0.662 (0.457) data 0.000 (0.010) loss 0.4676 (0.4583) acc 87.5000 (88.1250) lr 1.3090e-03 eta 0:09:55
Train CLIP2
Creating a 16-shot dataset
epoch [21/50] batch [5/45] time 0.661 (0.526) data 0.000 (0.089) loss 0.5596 (0.4725) acc 84.3750 (88.1250) lr 1.3090e-03 eta 0:11:47
epoch [21/50] batch [10/45] time 0.380 (0.481) data 0.000 (0.045) loss 0.5937 (0.4409) acc 84.3750 (88.7500) lr 1.3090e-03 eta 0:10:44
epoch [21/50] batch [15/45] time 0.381 (0.466) data 0.000 (0.030) loss 0.2506 (0.4554) acc 90.6250 (87.9167) lr 1.3090e-03 eta 0:10:22
epoch [21/50] batch [20/45] time 0.380 (0.460) data 0.000 (0.022) loss 0.6319 (0.4660) acc 87.5000 (87.5000) lr 1.3090e-03 eta 0:10:11
epoch [21/50] batch [25/45] time 0.680 (0.467) data 0.000 (0.018) loss 0.5194 (0.4853) acc 90.6250 (87.1250) lr 1.3090e-03 eta 0:10:19
epoch [21/50] batch [30/45] time 0.380 (0.462) data 0.000 (0.015) loss 0.4004 (0.4811) acc 87.5000 (87.1875) lr 1.3090e-03 eta 0:10:10
epoch [21/50] batch [35/45] time 0.380 (0.459) data 0.000 (0.013) loss 0.2596 (0.4760) acc 93.7500 (87.5000) lr 1.3090e-03 eta 0:10:03
epoch [21/50] batch [40/45] time 0.380 (0.457) data 0.000 (0.011) loss 0.1762 (0.4806) acc 96.8750 (87.4219) lr 1.3090e-03 eta 0:09:58
epoch [21/50] batch [45/45] time 0.655 (0.460) data 0.000 (0.010) loss 0.6627 (0.4725) acc 75.0000 (87.2917) lr 1.3090e-03 eta 0:10:00
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [22/50] batch [5/45] time 0.613 (0.504) data 0.000 (0.079) loss 0.4477 (0.3486) acc 87.5000 (89.3750) lr 1.3090e-03 eta 0:10:55
epoch [22/50] batch [10/45] time 0.379 (0.465) data 0.000 (0.039) loss 0.7073 (0.4040) acc 81.2500 (88.7500) lr 1.3090e-03 eta 0:10:01
epoch [22/50] batch [15/45] time 0.381 (0.455) data 0.000 (0.026) loss 0.5469 (0.4509) acc 81.2500 (87.9167) lr 1.3090e-03 eta 0:09:47
epoch [22/50] batch [20/45] time 0.383 (0.452) data 0.000 (0.020) loss 0.5680 (0.4417) acc 87.5000 (88.9062) lr 1.3090e-03 eta 0:09:41
epoch [22/50] batch [25/45] time 0.693 (0.462) data 0.000 (0.016) loss 0.7472 (0.4416) acc 81.2500 (88.8750) lr 1.3090e-03 eta 0:09:51
epoch [22/50] batch [30/45] time 0.380 (0.459) data 0.000 (0.013) loss 0.6929 (0.4645) acc 81.2500 (88.0208) lr 1.3090e-03 eta 0:09:45
epoch [22/50] batch [35/45] time 0.379 (0.455) data 0.000 (0.011) loss 0.4844 (0.4522) acc 87.5000 (88.3036) lr 1.3090e-03 eta 0:09:38
epoch [22/50] batch [40/45] time 0.380 (0.453) data 0.000 (0.010) loss 0.3353 (0.4472) acc 87.5000 (88.3594) lr 1.3090e-03 eta 0:09:33
epoch [22/50] batch [45/45] time 0.670 (0.458) data 0.000 (0.009) loss 0.7885 (0.4611) acc 84.3750 (88.1944) lr 1.2487e-03 eta 0:09:36
Train CLIP2
Creating a 16-shot dataset
epoch [22/50] batch [5/46] time 0.380 (0.538) data 0.000 (0.098) loss 0.6780 (0.4846) acc 81.2500 (85.6250) lr 1.2487e-03 eta 0:11:54
epoch [22/50] batch [10/46] time 0.609 (0.511) data 0.000 (0.049) loss 0.6936 (0.5017) acc 87.5000 (85.6250) lr 1.2487e-03 eta 0:11:16
epoch [22/50] batch [15/46] time 0.379 (0.482) data 0.000 (0.033) loss 0.3527 (0.4754) acc 93.7500 (86.0417) lr 1.2487e-03 eta 0:10:35
epoch [22/50] batch [20/46] time 0.379 (0.479) data 0.000 (0.025) loss 0.4932 (0.4592) acc 90.6250 (87.1875) lr 1.2487e-03 eta 0:10:29
epoch [22/50] batch [25/46] time 0.607 (0.478) data 0.000 (0.020) loss 0.6454 (0.4978) acc 81.2500 (86.7500) lr 1.2487e-03 eta 0:10:25
epoch [22/50] batch [30/46] time 0.379 (0.471) data 0.000 (0.016) loss 0.5618 (0.4987) acc 84.3750 (86.3542) lr 1.2487e-03 eta 0:10:13
epoch [22/50] batch [35/46] time 0.379 (0.473) data 0.000 (0.014) loss 0.6633 (0.5059) acc 84.3750 (86.2500) lr 1.2487e-03 eta 0:10:14
epoch [22/50] batch [40/46] time 0.670 (0.476) data 0.000 (0.012) loss 0.6230 (0.5125) acc 81.2500 (85.9375) lr 1.2487e-03 eta 0:10:16
epoch [22/50] batch [45/46] time 0.379 (0.472) data 0.000 (0.011) loss 0.6156 (0.5026) acc 84.3750 (86.1806) lr 1.2487e-03 eta 0:10:08
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [23/50] batch [5/46] time 0.380 (0.505) data 0.000 (0.068) loss 0.4577 (0.5474) acc 93.7500 (85.0000) lr 1.2487e-03 eta 0:10:47
epoch [23/50] batch [10/46] time 0.666 (0.499) data 0.000 (0.034) loss 0.5309 (0.4990) acc 87.5000 (85.6250) lr 1.2487e-03 eta 0:10:37
epoch [23/50] batch [15/46] time 0.380 (0.478) data 0.000 (0.023) loss 0.7886 (0.5533) acc 75.0000 (84.5833) lr 1.2487e-03 eta 0:10:09
epoch [23/50] batch [20/46] time 0.380 (0.482) data 0.000 (0.017) loss 0.8482 (0.5370) acc 75.0000 (85.4688) lr 1.2487e-03 eta 0:10:11
epoch [23/50] batch [25/46] time 0.684 (0.486) data 0.000 (0.014) loss 0.5686 (0.5436) acc 84.3750 (85.7500) lr 1.2487e-03 eta 0:10:13
epoch [23/50] batch [30/46] time 0.380 (0.478) data 0.000 (0.012) loss 0.4616 (0.5031) acc 93.7500 (86.9792) lr 1.2487e-03 eta 0:10:00
epoch [23/50] batch [35/46] time 0.380 (0.480) data 0.000 (0.010) loss 0.6918 (0.4950) acc 87.5000 (87.5893) lr 1.2487e-03 eta 0:10:01
epoch [23/50] batch [40/46] time 0.664 (0.482) data 0.000 (0.009) loss 0.3185 (0.4783) acc 93.7500 (88.1250) lr 1.2487e-03 eta 0:10:01
epoch [23/50] batch [45/46] time 0.379 (0.477) data 0.000 (0.008) loss 0.7279 (0.4913) acc 84.3750 (87.9167) lr 1.2487e-03 eta 0:09:52
Train CLIP2
Creating a 16-shot dataset
epoch [23/50] batch [5/46] time 0.380 (0.529) data 0.000 (0.092) loss 0.5040 (0.6073) acc 87.5000 (84.3750) lr 1.1874e-03 eta 0:11:19
epoch [23/50] batch [10/46] time 0.676 (0.514) data 0.000 (0.046) loss 0.2005 (0.5831) acc 93.7500 (85.0000) lr 1.1874e-03 eta 0:10:56
epoch [23/50] batch [15/46] time 0.380 (0.488) data 0.000 (0.031) loss 0.3954 (0.5439) acc 87.5000 (85.6250) lr 1.1874e-03 eta 0:10:21
epoch [23/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.023) loss 0.4212 (0.5265) acc 87.5000 (85.9375) lr 1.1874e-03 eta 0:10:21
epoch [23/50] batch [25/46] time 0.697 (0.492) data 0.000 (0.018) loss 0.2346 (0.5028) acc 93.7500 (86.6250) lr 1.1874e-03 eta 0:10:21
epoch [23/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.5713 (0.4890) acc 81.2500 (86.4583) lr 1.1874e-03 eta 0:10:07
epoch [23/50] batch [35/46] time 0.379 (0.485) data 0.000 (0.013) loss 0.4900 (0.4941) acc 84.3750 (86.6071) lr 1.1874e-03 eta 0:10:07
epoch [23/50] batch [40/46] time 0.658 (0.486) data 0.000 (0.012) loss 0.4516 (0.4853) acc 87.5000 (86.8750) lr 1.1874e-03 eta 0:10:06
epoch [23/50] batch [45/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.3533 (0.4849) acc 90.6250 (87.0833) lr 1.1874e-03 eta 0:09:57
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [24/50] batch [5/45] time 0.605 (0.506) data 0.000 (0.082) loss 0.3220 (0.4022) acc 90.6250 (88.7500) lr 1.1874e-03 eta 0:10:12
epoch [24/50] batch [10/45] time 0.380 (0.467) data 0.000 (0.041) loss 0.4686 (0.4245) acc 87.5000 (89.0625) lr 1.1874e-03 eta 0:09:22
epoch [24/50] batch [15/45] time 0.380 (0.457) data 0.000 (0.027) loss 0.3455 (0.4138) acc 84.3750 (88.1250) lr 1.1874e-03 eta 0:09:08
epoch [24/50] batch [20/45] time 0.380 (0.453) data 0.000 (0.020) loss 0.8232 (0.4876) acc 75.0000 (86.2500) lr 1.1874e-03 eta 0:09:00
epoch [24/50] batch [25/45] time 0.662 (0.461) data 0.000 (0.016) loss 0.3088 (0.4828) acc 87.5000 (86.3750) lr 1.1874e-03 eta 0:09:08
epoch [24/50] batch [30/45] time 0.380 (0.457) data 0.000 (0.014) loss 0.5143 (0.4983) acc 78.1250 (86.3542) lr 1.1874e-03 eta 0:09:01
epoch [24/50] batch [35/45] time 0.379 (0.454) data 0.000 (0.012) loss 0.3356 (0.4895) acc 93.7500 (86.5179) lr 1.1874e-03 eta 0:08:55
epoch [24/50] batch [40/45] time 0.379 (0.452) data 0.000 (0.010) loss 0.6769 (0.4940) acc 78.1250 (86.2500) lr 1.1874e-03 eta 0:08:51
epoch [24/50] batch [45/45] time 0.658 (0.457) data 0.000 (0.009) loss 0.7800 (0.5037) acc 78.1250 (85.6944) lr 1.1253e-03 eta 0:08:54
Train CLIP2
Creating a 16-shot dataset
epoch [24/50] batch [5/46] time 0.380 (0.526) data 0.000 (0.088) loss 0.9029 (0.4415) acc 75.0000 (87.5000) lr 1.1253e-03 eta 0:10:51
epoch [24/50] batch [10/46] time 0.614 (0.505) data 0.000 (0.044) loss 0.2952 (0.5079) acc 90.6250 (86.5625) lr 1.1253e-03 eta 0:10:22
epoch [24/50] batch [15/46] time 0.380 (0.483) data 0.000 (0.029) loss 0.6457 (0.5487) acc 87.5000 (86.8750) lr 1.1253e-03 eta 0:09:52
epoch [24/50] batch [20/46] time 0.380 (0.486) data 0.000 (0.022) loss 0.6166 (0.5569) acc 84.3750 (86.4062) lr 1.1253e-03 eta 0:09:53
epoch [24/50] batch [25/46] time 0.663 (0.488) data 0.000 (0.018) loss 0.5676 (0.5197) acc 90.6250 (87.1250) lr 1.1253e-03 eta 0:09:53
epoch [24/50] batch [30/46] time 0.380 (0.479) data 0.000 (0.015) loss 0.6604 (0.5234) acc 81.2500 (86.9792) lr 1.1253e-03 eta 0:09:40
epoch [24/50] batch [35/46] time 0.380 (0.481) data 0.000 (0.013) loss 0.4714 (0.5364) acc 87.5000 (86.7857) lr 1.1253e-03 eta 0:09:40
epoch [24/50] batch [40/46] time 0.659 (0.483) data 0.000 (0.011) loss 0.4433 (0.5385) acc 90.6250 (86.7188) lr 1.1253e-03 eta 0:09:40
epoch [24/50] batch [45/46] time 0.379 (0.478) data 0.000 (0.010) loss 0.4526 (0.5222) acc 87.5000 (87.2917) lr 1.1253e-03 eta 0:09:31
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [25/50] batch [5/46] time 0.379 (0.510) data 0.000 (0.068) loss 0.7836 (0.6679) acc 78.1250 (82.5000) lr 1.1253e-03 eta 0:10:07
epoch [25/50] batch [10/46] time 0.658 (0.501) data 0.000 (0.034) loss 0.2159 (0.4903) acc 93.7500 (87.1875) lr 1.1253e-03 eta 0:09:54
epoch [25/50] batch [15/46] time 0.380 (0.480) data 0.000 (0.023) loss 0.3303 (0.4805) acc 90.6250 (86.8750) lr 1.1253e-03 eta 0:09:27
epoch [25/50] batch [20/46] time 0.380 (0.484) data 0.000 (0.017) loss 0.2141 (0.4916) acc 96.8750 (86.8750) lr 1.1253e-03 eta 0:09:28
epoch [25/50] batch [25/46] time 0.670 (0.487) data 0.000 (0.014) loss 0.7507 (0.4923) acc 78.1250 (86.3750) lr 1.1253e-03 eta 0:09:30
epoch [25/50] batch [30/46] time 0.380 (0.479) data 0.000 (0.011) loss 1.0408 (0.5234) acc 75.0000 (85.3125) lr 1.1253e-03 eta 0:09:18
epoch [25/50] batch [35/46] time 0.379 (0.481) data 0.000 (0.010) loss 0.6044 (0.5174) acc 84.3750 (85.5357) lr 1.1253e-03 eta 0:09:18
epoch [25/50] batch [40/46] time 0.659 (0.482) data 0.000 (0.009) loss 0.1997 (0.4874) acc 93.7500 (86.4844) lr 1.1253e-03 eta 0:09:17
epoch [25/50] batch [45/46] time 0.379 (0.477) data 0.000 (0.008) loss 0.2930 (0.4871) acc 90.6250 (86.7361) lr 1.1253e-03 eta 0:09:09
Train CLIP2
Creating a 16-shot dataset
epoch [25/50] batch [5/45] time 0.689 (0.532) data 0.000 (0.090) loss 0.9242 (0.6292) acc 81.2500 (83.7500) lr 1.0628e-03 eta 0:10:19
epoch [25/50] batch [10/45] time 0.380 (0.488) data 0.000 (0.045) loss 0.3353 (0.5161) acc 90.6250 (86.8750) lr 1.0628e-03 eta 0:09:25
epoch [25/50] batch [15/45] time 0.380 (0.471) data 0.000 (0.030) loss 0.5359 (0.4886) acc 87.5000 (87.5000) lr 1.0628e-03 eta 0:09:04
epoch [25/50] batch [20/45] time 0.380 (0.463) data 0.000 (0.023) loss 0.2140 (0.4700) acc 93.7500 (87.5000) lr 1.0628e-03 eta 0:08:52
epoch [25/50] batch [25/45] time 0.700 (0.471) data 0.000 (0.018) loss 0.2661 (0.4859) acc 90.6250 (86.7500) lr 1.0628e-03 eta 0:08:59
epoch [25/50] batch [30/45] time 0.380 (0.466) data 0.000 (0.015) loss 0.6486 (0.5163) acc 81.2500 (86.4583) lr 1.0628e-03 eta 0:08:50
epoch [25/50] batch [35/45] time 0.380 (0.462) data 0.000 (0.013) loss 0.8790 (0.5066) acc 81.2500 (86.6071) lr 1.0628e-03 eta 0:08:44
epoch [25/50] batch [40/45] time 0.380 (0.459) data 0.000 (0.011) loss 0.7591 (0.5123) acc 78.1250 (86.4844) lr 1.0628e-03 eta 0:08:38
epoch [25/50] batch [45/45] time 0.693 (0.463) data 0.000 (0.010) loss 0.3163 (0.5107) acc 93.7500 (86.7361) lr 1.0628e-03 eta 0:08:41
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [26/50] batch [5/46] time 0.658 (0.529) data 0.000 (0.093) loss 0.2685 (0.4728) acc 87.5000 (86.8750) lr 1.0628e-03 eta 0:10:06
epoch [26/50] batch [10/46] time 0.380 (0.484) data 0.000 (0.047) loss 0.3116 (0.4403) acc 90.6250 (88.4375) lr 1.0628e-03 eta 0:09:11
epoch [26/50] batch [15/46] time 0.380 (0.468) data 0.000 (0.031) loss 0.3934 (0.4173) acc 84.3750 (88.5417) lr 1.0628e-03 eta 0:08:51
epoch [26/50] batch [20/46] time 0.380 (0.461) data 0.000 (0.023) loss 0.5716 (0.4782) acc 84.3750 (87.0312) lr 1.0628e-03 eta 0:08:40
epoch [26/50] batch [25/46] time 0.702 (0.470) data 0.000 (0.019) loss 0.3309 (0.5172) acc 87.5000 (86.6250) lr 1.0628e-03 eta 0:08:48
epoch [26/50] batch [30/46] time 0.380 (0.465) data 0.000 (0.016) loss 0.2993 (0.4906) acc 93.7500 (87.3958) lr 1.0628e-03 eta 0:08:40
epoch [26/50] batch [35/46] time 0.380 (0.461) data 0.000 (0.013) loss 0.5721 (0.4742) acc 87.5000 (87.9464) lr 1.0628e-03 eta 0:08:33
epoch [26/50] batch [40/46] time 0.380 (0.458) data 0.000 (0.012) loss 0.6148 (0.4967) acc 87.5000 (87.5781) lr 1.0628e-03 eta 0:08:28
epoch [26/50] batch [45/46] time 0.664 (0.462) data 0.000 (0.010) loss 0.3052 (0.4889) acc 87.5000 (87.8472) lr 1.0628e-03 eta 0:08:30
Train CLIP2
Creating a 16-shot dataset
epoch [26/50] batch [5/46] time 0.379 (0.516) data 0.000 (0.090) loss 0.2391 (0.4296) acc 84.3750 (86.8750) lr 1.0000e-03 eta 0:09:50
epoch [26/50] batch [10/46] time 0.611 (0.500) data 0.000 (0.045) loss 0.4311 (0.4964) acc 87.5000 (85.9375) lr 1.0000e-03 eta 0:09:30
epoch [26/50] batch [15/46] time 0.379 (0.475) data 0.000 (0.030) loss 0.7409 (0.5204) acc 84.3750 (85.6250) lr 1.0000e-03 eta 0:08:59
epoch [26/50] batch [20/46] time 0.380 (0.477) data 0.000 (0.023) loss 0.1969 (0.4492) acc 93.7500 (87.3438) lr 1.0000e-03 eta 0:08:59
epoch [26/50] batch [25/46] time 0.659 (0.481) data 0.000 (0.018) loss 0.4089 (0.4742) acc 93.7500 (87.3750) lr 1.0000e-03 eta 0:09:01
epoch [26/50] batch [30/46] time 0.380 (0.474) data 0.000 (0.015) loss 0.3115 (0.4755) acc 90.6250 (87.1875) lr 1.0000e-03 eta 0:08:50
epoch [26/50] batch [35/46] time 0.380 (0.477) data 0.000 (0.013) loss 0.4594 (0.4918) acc 87.5000 (86.6964) lr 1.0000e-03 eta 0:08:51
epoch [26/50] batch [40/46] time 0.659 (0.479) data 0.000 (0.011) loss 0.6726 (0.4838) acc 84.3750 (86.8750) lr 1.0000e-03 eta 0:08:51
epoch [26/50] batch [45/46] time 0.380 (0.474) data 0.000 (0.010) loss 0.4008 (0.4810) acc 90.6250 (86.8056) lr 1.0000e-03 eta 0:08:43
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [27/50] batch [5/46] time 0.380 (0.531) data 0.000 (0.093) loss 0.4921 (0.3448) acc 81.2500 (90.6250) lr 1.0000e-03 eta 0:09:43
epoch [27/50] batch [10/46] time 0.689 (0.515) data 0.000 (0.047) loss 0.7996 (0.4411) acc 78.1250 (86.8750) lr 1.0000e-03 eta 0:09:23
epoch [27/50] batch [15/46] time 0.380 (0.490) data 0.000 (0.031) loss 0.3529 (0.4142) acc 93.7500 (88.1250) lr 1.0000e-03 eta 0:08:53
epoch [27/50] batch [20/46] time 0.380 (0.493) data 0.000 (0.023) loss 0.2710 (0.4488) acc 90.6250 (87.3438) lr 1.0000e-03 eta 0:08:54
epoch [27/50] batch [25/46] time 0.671 (0.494) data 0.000 (0.019) loss 1.0188 (0.4755) acc 75.0000 (86.7500) lr 1.0000e-03 eta 0:08:52
epoch [27/50] batch [30/46] time 0.380 (0.485) data 0.000 (0.016) loss 0.1881 (0.4807) acc 93.7500 (86.6667) lr 1.0000e-03 eta 0:08:41
epoch [27/50] batch [35/46] time 0.380 (0.487) data 0.000 (0.013) loss 0.2557 (0.4622) acc 90.6250 (87.1429) lr 1.0000e-03 eta 0:08:40
epoch [27/50] batch [40/46] time 0.662 (0.488) data 0.000 (0.012) loss 0.5226 (0.4531) acc 81.2500 (87.3438) lr 1.0000e-03 eta 0:08:38
epoch [27/50] batch [45/46] time 0.380 (0.482) data 0.000 (0.010) loss 0.4667 (0.4512) acc 87.5000 (87.3611) lr 1.0000e-03 eta 0:08:30
Train CLIP2
Creating a 16-shot dataset
epoch [27/50] batch [5/46] time 0.380 (0.534) data 0.000 (0.091) loss 0.7348 (0.5790) acc 78.1250 (81.2500) lr 9.3721e-04 eta 0:09:46
epoch [27/50] batch [10/46] time 0.669 (0.515) data 0.000 (0.046) loss 0.3374 (0.4240) acc 90.6250 (87.5000) lr 9.3721e-04 eta 0:09:23
epoch [27/50] batch [15/46] time 0.380 (0.490) data 0.000 (0.031) loss 0.2070 (0.3914) acc 96.8750 (89.3750) lr 9.3721e-04 eta 0:08:54
epoch [27/50] batch [20/46] time 0.380 (0.491) data 0.000 (0.023) loss 0.5154 (0.4136) acc 87.5000 (88.7500) lr 9.3721e-04 eta 0:08:52
epoch [27/50] batch [25/46] time 0.673 (0.492) data 0.000 (0.018) loss 0.6829 (0.4397) acc 84.3750 (88.0000) lr 9.3721e-04 eta 0:08:50
epoch [27/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.2623 (0.4469) acc 96.8750 (87.9167) lr 9.3721e-04 eta 0:08:38
epoch [27/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.2427 (0.4371) acc 93.7500 (88.0357) lr 9.3721e-04 eta 0:08:37
epoch [27/50] batch [40/46] time 0.676 (0.486) data 0.000 (0.012) loss 0.0956 (0.4322) acc 100.0000 (88.1250) lr 9.3721e-04 eta 0:08:36
epoch [27/50] batch [45/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.3130 (0.4349) acc 87.5000 (88.1250) lr 9.3721e-04 eta 0:08:28
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [28/50] batch [5/46] time 0.380 (0.529) data 0.000 (0.092) loss 0.1596 (0.5005) acc 96.8750 (87.5000) lr 9.3721e-04 eta 0:09:17
epoch [28/50] batch [10/46] time 0.660 (0.514) data 0.000 (0.046) loss 0.5428 (0.4467) acc 87.5000 (89.0625) lr 9.3721e-04 eta 0:08:58
epoch [28/50] batch [15/46] time 0.380 (0.490) data 0.000 (0.031) loss 0.6795 (0.4293) acc 78.1250 (88.7500) lr 9.3721e-04 eta 0:08:30
epoch [28/50] batch [20/46] time 0.380 (0.491) data 0.000 (0.023) loss 0.6182 (0.4374) acc 84.3750 (88.5938) lr 9.3721e-04 eta 0:08:30
epoch [28/50] batch [25/46] time 0.608 (0.490) data 0.000 (0.018) loss 0.5590 (0.4622) acc 84.3750 (88.0000) lr 9.3721e-04 eta 0:08:26
epoch [28/50] batch [30/46] time 0.379 (0.481) data 0.000 (0.015) loss 0.4210 (0.4431) acc 84.3750 (88.2292) lr 9.3721e-04 eta 0:08:14
epoch [28/50] batch [35/46] time 0.380 (0.480) data 0.000 (0.013) loss 0.4102 (0.4430) acc 90.6250 (88.3036) lr 9.3721e-04 eta 0:08:11
epoch [28/50] batch [40/46] time 0.661 (0.480) data 0.000 (0.012) loss 0.2355 (0.4203) acc 90.6250 (88.9062) lr 9.3721e-04 eta 0:08:09
epoch [28/50] batch [45/46] time 0.379 (0.474) data 0.000 (0.010) loss 0.5094 (0.4362) acc 87.5000 (88.5417) lr 9.3721e-04 eta 0:08:00
Train CLIP2
Creating a 16-shot dataset
epoch [28/50] batch [5/46] time 0.380 (0.507) data 0.000 (0.071) loss 0.8063 (0.3893) acc 81.2500 (92.5000) lr 8.7467e-04 eta 0:08:54
epoch [28/50] batch [10/46] time 0.671 (0.503) data 0.000 (0.036) loss 0.4624 (0.4857) acc 84.3750 (88.4375) lr 8.7467e-04 eta 0:08:46
epoch [28/50] batch [15/46] time 0.380 (0.481) data 0.000 (0.024) loss 0.5343 (0.5097) acc 81.2500 (87.2917) lr 8.7467e-04 eta 0:08:21
epoch [28/50] batch [20/46] time 0.379 (0.486) data 0.000 (0.018) loss 0.5327 (0.5041) acc 81.2500 (86.5625) lr 8.7467e-04 eta 0:08:24
epoch [28/50] batch [25/46] time 0.668 (0.488) data 0.000 (0.014) loss 0.7021 (0.5049) acc 71.8750 (86.1250) lr 8.7467e-04 eta 0:08:23
epoch [28/50] batch [30/46] time 0.380 (0.480) data 0.000 (0.012) loss 0.4007 (0.4939) acc 90.6250 (86.4583) lr 8.7467e-04 eta 0:08:13
epoch [28/50] batch [35/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.6130 (0.4887) acc 84.3750 (86.6071) lr 8.7467e-04 eta 0:08:12
epoch [28/50] batch [40/46] time 0.670 (0.483) data 0.000 (0.009) loss 0.6194 (0.4967) acc 81.2500 (86.1719) lr 8.7467e-04 eta 0:08:12
epoch [28/50] batch [45/46] time 0.379 (0.478) data 0.000 (0.008) loss 0.7262 (0.5072) acc 81.2500 (85.9722) lr 8.7467e-04 eta 0:08:04
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [29/50] batch [5/45] time 0.694 (0.538) data 0.000 (0.094) loss 0.3158 (0.4402) acc 90.6250 (88.7500) lr 8.7467e-04 eta 0:08:49
epoch [29/50] batch [10/45] time 0.380 (0.489) data 0.000 (0.047) loss 0.2479 (0.5129) acc 90.6250 (87.5000) lr 8.7467e-04 eta 0:07:59
epoch [29/50] batch [15/45] time 0.380 (0.472) data 0.000 (0.032) loss 0.2373 (0.4995) acc 93.7500 (86.8750) lr 8.7467e-04 eta 0:07:40
epoch [29/50] batch [20/45] time 0.380 (0.464) data 0.000 (0.024) loss 0.4852 (0.4837) acc 87.5000 (87.0312) lr 8.7467e-04 eta 0:07:30
epoch [29/50] batch [25/45] time 0.696 (0.472) data 0.000 (0.019) loss 0.6021 (0.4899) acc 78.1250 (86.0000) lr 8.7467e-04 eta 0:07:35
epoch [29/50] batch [30/45] time 0.380 (0.466) data 0.000 (0.016) loss 0.3920 (0.4687) acc 87.5000 (86.6667) lr 8.7467e-04 eta 0:07:27
epoch [29/50] batch [35/45] time 0.380 (0.462) data 0.000 (0.014) loss 0.2273 (0.4756) acc 96.8750 (86.6071) lr 8.7467e-04 eta 0:07:20
epoch [29/50] batch [40/45] time 0.380 (0.459) data 0.000 (0.012) loss 0.3889 (0.4700) acc 93.7500 (86.9531) lr 8.7467e-04 eta 0:07:16
epoch [29/50] batch [45/45] time 0.681 (0.464) data 0.000 (0.011) loss 0.4599 (0.4713) acc 84.3750 (87.0833) lr 8.1262e-04 eta 0:07:18
Train CLIP2
Creating a 16-shot dataset
epoch [29/50] batch [5/46] time 0.380 (0.532) data 0.000 (0.093) loss 0.3454 (0.3690) acc 87.5000 (90.6250) lr 8.1262e-04 eta 0:08:55
epoch [29/50] batch [10/46] time 0.675 (0.516) data 0.000 (0.047) loss 0.4121 (0.4010) acc 84.3750 (88.4375) lr 8.1262e-04 eta 0:08:36
epoch [29/50] batch [15/46] time 0.380 (0.491) data 0.000 (0.031) loss 0.3019 (0.3893) acc 93.7500 (88.9583) lr 8.1262e-04 eta 0:08:09
epoch [29/50] batch [20/46] time 0.380 (0.492) data 0.000 (0.023) loss 0.4393 (0.3777) acc 90.6250 (89.2188) lr 8.1262e-04 eta 0:08:08
epoch [29/50] batch [25/46] time 0.661 (0.493) data 0.000 (0.019) loss 0.2939 (0.3976) acc 93.7500 (89.1250) lr 8.1262e-04 eta 0:08:06
epoch [29/50] batch [30/46] time 0.380 (0.485) data 0.000 (0.016) loss 0.6762 (0.4240) acc 81.2500 (88.7500) lr 8.1262e-04 eta 0:07:56
epoch [29/50] batch [35/46] time 0.380 (0.486) data 0.000 (0.013) loss 0.5998 (0.4527) acc 78.1250 (88.1250) lr 8.1262e-04 eta 0:07:55
epoch [29/50] batch [40/46] time 0.670 (0.488) data 0.000 (0.012) loss 0.5125 (0.4542) acc 93.7500 (88.2031) lr 8.1262e-04 eta 0:07:54
epoch [29/50] batch [45/46] time 0.380 (0.482) data 0.000 (0.010) loss 0.3541 (0.4466) acc 90.6250 (88.3333) lr 8.1262e-04 eta 0:07:46
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [30/50] batch [5/46] time 0.662 (0.528) data 0.000 (0.091) loss 0.2916 (0.4048) acc 87.5000 (85.6250) lr 8.1262e-04 eta 0:08:27
epoch [30/50] batch [10/46] time 0.380 (0.483) data 0.000 (0.046) loss 0.5681 (0.4282) acc 90.6250 (88.1250) lr 8.1262e-04 eta 0:07:41
epoch [30/50] batch [15/46] time 0.380 (0.467) data 0.000 (0.030) loss 0.5173 (0.4269) acc 87.5000 (88.9583) lr 8.1262e-04 eta 0:07:24
epoch [30/50] batch [20/46] time 0.381 (0.460) data 0.000 (0.023) loss 0.4942 (0.4227) acc 75.0000 (88.2812) lr 8.1262e-04 eta 0:07:15
epoch [30/50] batch [25/46] time 0.669 (0.467) data 0.000 (0.018) loss 0.6046 (0.4659) acc 87.5000 (87.5000) lr 8.1262e-04 eta 0:07:19
epoch [30/50] batch [30/46] time 0.380 (0.462) data 0.000 (0.015) loss 0.2618 (0.4751) acc 93.7500 (87.0833) lr 8.1262e-04 eta 0:07:12
epoch [30/50] batch [35/46] time 0.379 (0.459) data 0.000 (0.013) loss 0.2425 (0.4667) acc 96.8750 (87.2321) lr 8.1262e-04 eta 0:07:07
epoch [30/50] batch [40/46] time 0.379 (0.458) data 0.000 (0.012) loss 0.8653 (0.4793) acc 78.1250 (87.1094) lr 8.1262e-04 eta 0:07:03
epoch [30/50] batch [45/46] time 0.702 (0.464) data 0.000 (0.010) loss 0.4961 (0.4765) acc 81.2500 (87.5000) lr 8.1262e-04 eta 0:07:07
Train CLIP2
Creating a 16-shot dataset
epoch [30/50] batch [5/46] time 0.380 (0.556) data 0.000 (0.118) loss 0.8712 (0.5626) acc 81.2500 (85.6250) lr 7.5131e-04 eta 0:08:54
epoch [30/50] batch [10/46] time 0.666 (0.525) data 0.000 (0.059) loss 0.3776 (0.5956) acc 90.6250 (84.0625) lr 7.5131e-04 eta 0:08:22
epoch [30/50] batch [15/46] time 0.380 (0.496) data 0.000 (0.039) loss 0.2826 (0.4804) acc 93.7500 (87.2917) lr 7.5131e-04 eta 0:07:51
epoch [30/50] batch [20/46] time 0.380 (0.496) data 0.000 (0.030) loss 0.2437 (0.4669) acc 93.7500 (87.1875) lr 7.5131e-04 eta 0:07:48
epoch [30/50] batch [25/46] time 0.660 (0.495) data 0.000 (0.024) loss 0.4445 (0.4695) acc 90.6250 (87.3750) lr 7.5131e-04 eta 0:07:45
epoch [30/50] batch [30/46] time 0.380 (0.487) data 0.000 (0.020) loss 0.1977 (0.4594) acc 93.7500 (87.2917) lr 7.5131e-04 eta 0:07:35
epoch [30/50] batch [35/46] time 0.380 (0.488) data 0.000 (0.017) loss 0.4880 (0.4491) acc 87.5000 (87.5000) lr 7.5131e-04 eta 0:07:34
epoch [30/50] batch [40/46] time 0.665 (0.489) data 0.000 (0.015) loss 0.1483 (0.4399) acc 96.8750 (87.8125) lr 7.5131e-04 eta 0:07:32
epoch [30/50] batch [45/46] time 0.379 (0.483) data 0.000 (0.013) loss 0.3128 (0.4520) acc 87.5000 (87.3611) lr 7.5131e-04 eta 0:07:24
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [31/50] batch [5/46] time 0.612 (0.512) data 0.000 (0.087) loss 0.1565 (0.2881) acc 96.8750 (91.8750) lr 7.5131e-04 eta 0:07:48
epoch [31/50] batch [10/46] time 0.379 (0.470) data 0.000 (0.043) loss 0.3844 (0.3327) acc 93.7500 (90.6250) lr 7.5131e-04 eta 0:07:07
epoch [31/50] batch [15/46] time 0.381 (0.459) data 0.000 (0.029) loss 0.3819 (0.3099) acc 90.6250 (92.0833) lr 7.5131e-04 eta 0:06:55
epoch [31/50] batch [20/46] time 0.380 (0.453) data 0.000 (0.022) loss 1.1140 (0.3705) acc 81.2500 (90.9375) lr 7.5131e-04 eta 0:06:48
epoch [31/50] batch [25/46] time 0.686 (0.464) data 0.000 (0.017) loss 0.3289 (0.4076) acc 90.6250 (89.6250) lr 7.5131e-04 eta 0:06:54
epoch [31/50] batch [30/46] time 0.380 (0.459) data 0.000 (0.015) loss 0.5011 (0.4122) acc 87.5000 (89.1667) lr 7.5131e-04 eta 0:06:48
epoch [31/50] batch [35/46] time 0.379 (0.457) data 0.000 (0.012) loss 0.5653 (0.4207) acc 84.3750 (88.7500) lr 7.5131e-04 eta 0:06:44
epoch [31/50] batch [40/46] time 0.380 (0.454) data 0.000 (0.011) loss 0.8877 (0.4236) acc 81.2500 (88.8281) lr 7.5131e-04 eta 0:06:39
epoch [31/50] batch [45/46] time 0.669 (0.459) data 0.000 (0.010) loss 0.3738 (0.4261) acc 93.7500 (88.9583) lr 7.5131e-04 eta 0:06:41
Train CLIP2
Creating a 16-shot dataset
epoch [31/50] batch [5/46] time 0.380 (0.532) data 0.000 (0.089) loss 0.5899 (0.5531) acc 81.2500 (87.5000) lr 6.9098e-04 eta 0:08:06
epoch [31/50] batch [10/46] time 0.659 (0.512) data 0.000 (0.044) loss 0.9263 (0.5946) acc 81.2500 (85.6250) lr 6.9098e-04 eta 0:07:46
epoch [31/50] batch [15/46] time 0.380 (0.488) data 0.000 (0.030) loss 0.2136 (0.5093) acc 90.6250 (87.2917) lr 6.9098e-04 eta 0:07:21
epoch [31/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.022) loss 0.4801 (0.5283) acc 84.3750 (86.2500) lr 6.9098e-04 eta 0:07:20
epoch [31/50] batch [25/46] time 0.677 (0.491) data 0.000 (0.018) loss 0.7438 (0.5164) acc 81.2500 (86.5000) lr 6.9098e-04 eta 0:07:19
epoch [31/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.015) loss 0.4355 (0.5214) acc 90.6250 (86.8750) lr 6.9098e-04 eta 0:07:09
epoch [31/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.1391 (0.5074) acc 100.0000 (87.5000) lr 6.9098e-04 eta 0:07:08
epoch [31/50] batch [40/46] time 0.654 (0.484) data 0.000 (0.011) loss 0.2852 (0.4965) acc 93.7500 (87.7344) lr 6.9098e-04 eta 0:07:06
epoch [31/50] batch [45/46] time 0.379 (0.479) data 0.000 (0.010) loss 0.1132 (0.4959) acc 96.8750 (87.7778) lr 6.9098e-04 eta 0:06:59
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [32/50] batch [5/46] time 0.380 (0.504) data 0.000 (0.068) loss 0.1913 (0.4270) acc 96.8750 (88.7500) lr 6.9098e-04 eta 0:07:18
epoch [32/50] batch [10/46] time 0.693 (0.503) data 0.000 (0.034) loss 0.5350 (0.5103) acc 87.5000 (86.2500) lr 6.9098e-04 eta 0:07:14
epoch [32/50] batch [15/46] time 0.380 (0.481) data 0.000 (0.023) loss 0.4331 (0.4909) acc 84.3750 (86.4583) lr 6.9098e-04 eta 0:06:53
epoch [32/50] batch [20/46] time 0.381 (0.484) data 0.000 (0.017) loss 0.4362 (0.4607) acc 93.7500 (87.1875) lr 6.9098e-04 eta 0:06:53
epoch [32/50] batch [25/46] time 0.689 (0.487) data 0.000 (0.014) loss 0.3586 (0.4498) acc 90.6250 (87.7500) lr 6.9098e-04 eta 0:06:53
epoch [32/50] batch [30/46] time 0.380 (0.479) data 0.000 (0.012) loss 0.1850 (0.4626) acc 93.7500 (87.6042) lr 6.9098e-04 eta 0:06:44
epoch [32/50] batch [35/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.6116 (0.5045) acc 87.5000 (86.7857) lr 6.9098e-04 eta 0:06:43
epoch [32/50] batch [40/46] time 0.659 (0.483) data 0.000 (0.009) loss 0.6837 (0.5071) acc 81.2500 (86.7188) lr 6.9098e-04 eta 0:06:42
epoch [32/50] batch [45/46] time 0.380 (0.478) data 0.000 (0.008) loss 0.4862 (0.5014) acc 87.5000 (86.8056) lr 6.9098e-04 eta 0:06:36
Train CLIP2
Creating a 16-shot dataset
epoch [32/50] batch [5/46] time 0.380 (0.528) data 0.000 (0.090) loss 0.3329 (0.4607) acc 90.6250 (87.5000) lr 6.3188e-04 eta 0:07:38
epoch [32/50] batch [10/46] time 0.663 (0.511) data 0.000 (0.045) loss 0.2369 (0.4565) acc 96.8750 (87.8125) lr 6.3188e-04 eta 0:07:21
epoch [32/50] batch [15/46] time 0.380 (0.487) data 0.000 (0.030) loss 0.8169 (0.4638) acc 78.1250 (87.2917) lr 6.3188e-04 eta 0:06:58
epoch [32/50] batch [20/46] time 0.381 (0.490) data 0.000 (0.023) loss 0.5347 (0.4712) acc 84.3750 (85.7812) lr 6.3188e-04 eta 0:06:58
epoch [32/50] batch [25/46] time 0.664 (0.491) data 0.000 (0.018) loss 0.6019 (0.4785) acc 87.5000 (86.0000) lr 6.3188e-04 eta 0:06:56
epoch [32/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.015) loss 0.5784 (0.4558) acc 78.1250 (86.2500) lr 6.3188e-04 eta 0:06:47
epoch [32/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.2863 (0.4732) acc 93.7500 (86.1607) lr 6.3188e-04 eta 0:06:46
epoch [32/50] batch [40/46] time 0.660 (0.485) data 0.000 (0.011) loss 0.4867 (0.4581) acc 93.7500 (86.9531) lr 6.3188e-04 eta 0:06:44
epoch [32/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.010) loss 0.2143 (0.4611) acc 96.8750 (86.8750) lr 6.3188e-04 eta 0:06:37
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [33/50] batch [5/46] time 0.380 (0.532) data 0.000 (0.095) loss 0.4814 (0.4732) acc 81.2500 (86.2500) lr 6.3188e-04 eta 0:07:18
epoch [33/50] batch [10/46] time 0.612 (0.509) data 0.000 (0.047) loss 0.5600 (0.4526) acc 84.3750 (87.5000) lr 6.3188e-04 eta 0:06:56
epoch [33/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.032) loss 0.2748 (0.4924) acc 87.5000 (86.8750) lr 6.3188e-04 eta 0:06:34
epoch [33/50] batch [20/46] time 0.381 (0.487) data 0.000 (0.024) loss 0.5619 (0.4947) acc 87.5000 (87.0312) lr 6.3188e-04 eta 0:06:33
epoch [33/50] batch [25/46] time 0.697 (0.491) data 0.000 (0.019) loss 0.4807 (0.4786) acc 87.5000 (87.0000) lr 6.3188e-04 eta 0:06:34
epoch [33/50] batch [30/46] time 0.379 (0.480) data 0.000 (0.016) loss 0.2604 (0.4556) acc 93.7500 (87.9167) lr 6.3188e-04 eta 0:06:23
epoch [33/50] batch [35/46] time 0.379 (0.479) data 0.000 (0.014) loss 0.3488 (0.4604) acc 90.6250 (87.9464) lr 6.3188e-04 eta 0:06:19
epoch [33/50] batch [40/46] time 0.657 (0.480) data 0.000 (0.012) loss 0.3243 (0.4583) acc 93.7500 (88.1250) lr 6.3188e-04 eta 0:06:18
epoch [33/50] batch [45/46] time 0.380 (0.476) data 0.000 (0.011) loss 0.3234 (0.4408) acc 90.6250 (88.2639) lr 6.3188e-04 eta 0:06:12
Train CLIP2
Creating a 16-shot dataset
epoch [33/50] batch [5/46] time 0.380 (0.538) data 0.000 (0.094) loss 0.4115 (0.4033) acc 84.3750 (88.1250) lr 5.7422e-04 eta 0:07:22
epoch [33/50] batch [10/46] time 0.700 (0.514) data 0.000 (0.047) loss 0.3355 (0.4609) acc 90.6250 (87.5000) lr 5.7422e-04 eta 0:07:00
epoch [33/50] batch [15/46] time 0.380 (0.489) data 0.000 (0.032) loss 0.4746 (0.4357) acc 84.3750 (88.3333) lr 5.7422e-04 eta 0:06:37
epoch [33/50] batch [20/46] time 0.380 (0.491) data 0.000 (0.024) loss 0.6640 (0.4709) acc 81.2500 (87.3438) lr 5.7422e-04 eta 0:06:36
epoch [33/50] batch [25/46] time 0.682 (0.493) data 0.000 (0.019) loss 0.2114 (0.4832) acc 90.6250 (86.7500) lr 5.7422e-04 eta 0:06:36
epoch [33/50] batch [30/46] time 0.380 (0.484) data 0.000 (0.016) loss 0.5904 (0.5019) acc 87.5000 (86.8750) lr 5.7422e-04 eta 0:06:26
epoch [33/50] batch [35/46] time 0.379 (0.487) data 0.000 (0.014) loss 0.5325 (0.5031) acc 81.2500 (86.6964) lr 5.7422e-04 eta 0:06:26
epoch [33/50] batch [40/46] time 0.683 (0.489) data 0.000 (0.012) loss 0.6391 (0.5137) acc 78.1250 (86.2500) lr 5.7422e-04 eta 0:06:25
epoch [33/50] batch [45/46] time 0.380 (0.483) data 0.000 (0.011) loss 0.6415 (0.5282) acc 87.5000 (85.9722) lr 5.7422e-04 eta 0:06:18
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [34/50] batch [5/46] time 0.379 (0.512) data 0.000 (0.085) loss 0.4292 (0.4977) acc 87.5000 (86.2500) lr 5.7422e-04 eta 0:06:37
epoch [34/50] batch [10/46] time 0.667 (0.498) data 0.000 (0.042) loss 0.5398 (0.5079) acc 90.6250 (86.5625) lr 5.7422e-04 eta 0:06:24
epoch [34/50] batch [15/46] time 0.380 (0.479) data 0.000 (0.028) loss 0.4313 (0.4749) acc 90.6250 (87.5000) lr 5.7422e-04 eta 0:06:07
epoch [34/50] batch [20/46] time 0.380 (0.483) data 0.000 (0.021) loss 0.4064 (0.4835) acc 84.3750 (87.9688) lr 5.7422e-04 eta 0:06:08
epoch [34/50] batch [25/46] time 0.701 (0.487) data 0.000 (0.017) loss 0.6321 (0.5027) acc 90.6250 (87.6250) lr 5.7422e-04 eta 0:06:08
epoch [34/50] batch [30/46] time 0.380 (0.479) data 0.000 (0.014) loss 0.4503 (0.4835) acc 87.5000 (87.6042) lr 5.7422e-04 eta 0:06:00
epoch [34/50] batch [35/46] time 0.380 (0.482) data 0.000 (0.012) loss 0.6469 (0.4904) acc 90.6250 (87.9464) lr 5.7422e-04 eta 0:06:00
epoch [34/50] batch [40/46] time 0.681 (0.485) data 0.000 (0.011) loss 0.6989 (0.5007) acc 78.1250 (87.5781) lr 5.7422e-04 eta 0:05:59
epoch [34/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.010) loss 0.6192 (0.4936) acc 90.6250 (87.7083) lr 5.7422e-04 eta 0:05:53
Train CLIP2
Creating a 16-shot dataset
epoch [34/50] batch [5/46] time 0.380 (0.531) data 0.000 (0.093) loss 0.1919 (0.3314) acc 100.0000 (93.1250) lr 5.1825e-04 eta 0:06:52
epoch [34/50] batch [10/46] time 0.685 (0.516) data 0.000 (0.046) loss 0.1937 (0.4214) acc 96.8750 (90.3125) lr 5.1825e-04 eta 0:06:38
epoch [34/50] batch [15/46] time 0.380 (0.492) data 0.000 (0.031) loss 0.4546 (0.4473) acc 90.6250 (89.5833) lr 5.1825e-04 eta 0:06:17
epoch [34/50] batch [20/46] time 0.380 (0.494) data 0.000 (0.023) loss 0.5905 (0.4537) acc 81.2500 (89.5312) lr 5.1825e-04 eta 0:06:16
epoch [34/50] batch [25/46] time 0.661 (0.494) data 0.000 (0.019) loss 0.5050 (0.4430) acc 87.5000 (89.6250) lr 5.1825e-04 eta 0:06:13
epoch [34/50] batch [30/46] time 0.380 (0.484) data 0.000 (0.016) loss 0.7206 (0.4665) acc 81.2500 (88.8542) lr 5.1825e-04 eta 0:06:04
epoch [34/50] batch [35/46] time 0.379 (0.486) data 0.000 (0.013) loss 0.5080 (0.4829) acc 87.5000 (88.0357) lr 5.1825e-04 eta 0:06:02
epoch [34/50] batch [40/46] time 0.661 (0.486) data 0.000 (0.012) loss 0.3909 (0.4766) acc 93.7500 (88.2812) lr 5.1825e-04 eta 0:06:00
epoch [34/50] batch [45/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.8025 (0.4871) acc 78.1250 (87.8472) lr 5.1825e-04 eta 0:05:54
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [35/50] batch [5/46] time 0.380 (0.525) data 0.000 (0.087) loss 0.5710 (0.4848) acc 90.6250 (91.2500) lr 5.1825e-04 eta 0:06:23
epoch [35/50] batch [10/46] time 0.663 (0.508) data 0.000 (0.044) loss 0.4506 (0.4642) acc 90.6250 (89.0625) lr 5.1825e-04 eta 0:06:09
epoch [35/50] batch [15/46] time 0.380 (0.484) data 0.000 (0.029) loss 0.5277 (0.4869) acc 78.1250 (87.5000) lr 5.1825e-04 eta 0:05:49
epoch [35/50] batch [20/46] time 0.380 (0.488) data 0.000 (0.022) loss 0.1439 (0.4422) acc 96.8750 (88.5938) lr 5.1825e-04 eta 0:05:49
epoch [35/50] batch [25/46] time 0.660 (0.490) data 0.000 (0.018) loss 0.8378 (0.4432) acc 81.2500 (88.7500) lr 5.1825e-04 eta 0:05:48
epoch [35/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.015) loss 0.5040 (0.4615) acc 90.6250 (88.4375) lr 5.1825e-04 eta 0:05:40
epoch [35/50] batch [35/46] time 0.379 (0.483) data 0.000 (0.013) loss 0.6673 (0.4816) acc 81.2500 (88.1250) lr 5.1825e-04 eta 0:05:38
epoch [35/50] batch [40/46] time 0.660 (0.484) data 0.000 (0.011) loss 0.5196 (0.4667) acc 84.3750 (88.3594) lr 5.1825e-04 eta 0:05:37
epoch [35/50] batch [45/46] time 0.380 (0.479) data 0.000 (0.010) loss 0.2114 (0.4441) acc 90.6250 (88.8194) lr 5.1825e-04 eta 0:05:31
Train CLIP2
Creating a 16-shot dataset
epoch [35/50] batch [5/46] time 0.380 (0.531) data 0.000 (0.091) loss 0.4433 (0.5683) acc 87.5000 (86.8750) lr 4.6417e-04 eta 0:06:28
epoch [35/50] batch [10/46] time 0.663 (0.512) data 0.000 (0.046) loss 0.4212 (0.5630) acc 90.6250 (85.6250) lr 4.6417e-04 eta 0:06:12
epoch [35/50] batch [15/46] time 0.380 (0.488) data 0.000 (0.031) loss 0.3409 (0.5155) acc 90.6250 (86.8750) lr 4.6417e-04 eta 0:05:51
epoch [35/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.023) loss 0.3201 (0.4943) acc 90.6250 (87.3438) lr 4.6417e-04 eta 0:05:50
epoch [35/50] batch [25/46] time 0.676 (0.492) data 0.000 (0.018) loss 0.5934 (0.4894) acc 78.1250 (87.3750) lr 4.6417e-04 eta 0:05:49
epoch [35/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.3055 (0.4793) acc 96.8750 (87.5000) lr 4.6417e-04 eta 0:05:40
epoch [35/50] batch [35/46] time 0.379 (0.485) data 0.000 (0.013) loss 0.4537 (0.4836) acc 81.2500 (86.9643) lr 4.6417e-04 eta 0:05:39
epoch [35/50] batch [40/46] time 0.664 (0.486) data 0.000 (0.012) loss 0.4563 (0.4690) acc 84.3750 (87.3438) lr 4.6417e-04 eta 0:05:38
epoch [35/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.010) loss 0.5103 (0.4545) acc 87.5000 (87.9167) lr 4.6417e-04 eta 0:05:31
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [36/50] batch [5/46] time 0.380 (0.526) data 0.000 (0.089) loss 0.5964 (0.3401) acc 84.3750 (91.2500) lr 4.6417e-04 eta 0:06:00
epoch [36/50] batch [10/46] time 0.605 (0.499) data 0.000 (0.044) loss 0.4561 (0.3743) acc 87.5000 (89.6875) lr 4.6417e-04 eta 0:05:39
epoch [36/50] batch [15/46] time 0.380 (0.478) data 0.000 (0.030) loss 0.2153 (0.4038) acc 93.7500 (89.5833) lr 4.6417e-04 eta 0:05:22
epoch [36/50] batch [20/46] time 0.380 (0.479) data 0.000 (0.022) loss 0.3148 (0.4138) acc 87.5000 (89.5312) lr 4.6417e-04 eta 0:05:21
epoch [36/50] batch [25/46] time 0.675 (0.483) data 0.000 (0.018) loss 0.2102 (0.4007) acc 96.8750 (90.0000) lr 4.6417e-04 eta 0:05:21
epoch [36/50] batch [30/46] time 0.380 (0.475) data 0.000 (0.015) loss 0.5031 (0.4205) acc 90.6250 (89.4792) lr 4.6417e-04 eta 0:05:13
epoch [36/50] batch [35/46] time 0.379 (0.478) data 0.000 (0.013) loss 0.2261 (0.4241) acc 90.6250 (89.2857) lr 4.6417e-04 eta 0:05:12
epoch [36/50] batch [40/46] time 0.652 (0.479) data 0.000 (0.011) loss 0.1607 (0.4282) acc 100.0000 (89.0625) lr 4.6417e-04 eta 0:05:11
epoch [36/50] batch [45/46] time 0.379 (0.474) data 0.000 (0.010) loss 0.4391 (0.4228) acc 84.3750 (89.2361) lr 4.6417e-04 eta 0:05:06
Train CLIP2
Creating a 16-shot dataset
epoch [36/50] batch [5/46] time 0.380 (0.533) data 0.000 (0.095) loss 0.6723 (0.6253) acc 84.3750 (83.1250) lr 4.1221e-04 eta 0:06:05
epoch [36/50] batch [10/46] time 0.661 (0.515) data 0.000 (0.047) loss 0.1847 (0.4669) acc 93.7500 (86.8750) lr 4.1221e-04 eta 0:05:50
epoch [36/50] batch [15/46] time 0.380 (0.490) data 0.000 (0.032) loss 0.4549 (0.4670) acc 81.2500 (86.2500) lr 4.1221e-04 eta 0:05:30
epoch [36/50] batch [20/46] time 0.380 (0.491) data 0.000 (0.024) loss 0.4116 (0.4303) acc 90.6250 (87.5000) lr 4.1221e-04 eta 0:05:28
epoch [36/50] batch [25/46] time 0.662 (0.492) data 0.000 (0.019) loss 0.4975 (0.4363) acc 90.6250 (88.2500) lr 4.1221e-04 eta 0:05:27
epoch [36/50] batch [30/46] time 0.380 (0.484) data 0.000 (0.016) loss 0.4019 (0.4440) acc 87.5000 (88.3333) lr 4.1221e-04 eta 0:05:19
epoch [36/50] batch [35/46] time 0.379 (0.486) data 0.000 (0.014) loss 0.2143 (0.4651) acc 96.8750 (88.1250) lr 4.1221e-04 eta 0:05:18
epoch [36/50] batch [40/46] time 0.656 (0.486) data 0.000 (0.012) loss 0.6755 (0.4601) acc 90.6250 (88.3594) lr 4.1221e-04 eta 0:05:16
epoch [36/50] batch [45/46] time 0.380 (0.481) data 0.000 (0.011) loss 0.3589 (0.4534) acc 90.6250 (88.4028) lr 4.1221e-04 eta 0:05:10
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [37/50] batch [5/46] time 0.379 (0.516) data 0.000 (0.090) loss 0.5734 (0.5416) acc 87.5000 (85.6250) lr 4.1221e-04 eta 0:05:29
epoch [37/50] batch [10/46] time 0.616 (0.500) data 0.000 (0.045) loss 0.7141 (0.5386) acc 84.3750 (85.9375) lr 4.1221e-04 eta 0:05:17
epoch [37/50] batch [15/46] time 0.380 (0.479) data 0.000 (0.030) loss 0.5475 (0.5107) acc 84.3750 (86.0417) lr 4.1221e-04 eta 0:05:01
epoch [37/50] batch [20/46] time 0.379 (0.480) data 0.000 (0.023) loss 0.6520 (0.5016) acc 71.8750 (85.6250) lr 4.1221e-04 eta 0:04:59
epoch [37/50] batch [25/46] time 0.692 (0.483) data 0.000 (0.018) loss 0.3887 (0.4816) acc 90.6250 (86.3750) lr 4.1221e-04 eta 0:04:59
epoch [37/50] batch [30/46] time 0.380 (0.476) data 0.000 (0.015) loss 0.2804 (0.4861) acc 93.7500 (86.6667) lr 4.1221e-04 eta 0:04:52
epoch [37/50] batch [35/46] time 0.379 (0.478) data 0.000 (0.013) loss 0.4214 (0.4759) acc 87.5000 (86.9643) lr 4.1221e-04 eta 0:04:51
epoch [37/50] batch [40/46] time 0.661 (0.480) data 0.000 (0.011) loss 0.5005 (0.4621) acc 87.5000 (87.3438) lr 4.1221e-04 eta 0:04:49
epoch [37/50] batch [45/46] time 0.379 (0.475) data 0.000 (0.010) loss 0.2961 (0.4809) acc 90.6250 (87.0833) lr 4.1221e-04 eta 0:04:44
Train CLIP2
Creating a 16-shot dataset
epoch [37/50] batch [5/46] time 0.380 (0.532) data 0.000 (0.095) loss 0.4626 (0.3970) acc 90.6250 (90.6250) lr 3.6258e-04 eta 0:05:39
epoch [37/50] batch [10/46] time 0.691 (0.516) data 0.000 (0.047) loss 0.5900 (0.4750) acc 84.3750 (87.5000) lr 3.6258e-04 eta 0:05:27
epoch [37/50] batch [15/46] time 0.380 (0.492) data 0.000 (0.032) loss 0.6816 (0.4752) acc 81.2500 (87.2917) lr 3.6258e-04 eta 0:05:09
epoch [37/50] batch [20/46] time 0.380 (0.493) data 0.000 (0.024) loss 0.4005 (0.4254) acc 87.5000 (88.2812) lr 3.6258e-04 eta 0:05:07
epoch [37/50] batch [25/46] time 0.664 (0.494) data 0.000 (0.019) loss 0.5564 (0.4521) acc 87.5000 (87.5000) lr 3.6258e-04 eta 0:05:05
epoch [37/50] batch [30/46] time 0.380 (0.486) data 0.000 (0.016) loss 0.4267 (0.4677) acc 87.5000 (87.3958) lr 3.6258e-04 eta 0:04:58
epoch [37/50] batch [35/46] time 0.379 (0.487) data 0.000 (0.014) loss 0.4230 (0.4603) acc 87.5000 (87.0536) lr 3.6258e-04 eta 0:04:56
epoch [37/50] batch [40/46] time 0.659 (0.488) data 0.000 (0.012) loss 0.5570 (0.4625) acc 87.5000 (86.9531) lr 3.6258e-04 eta 0:04:54
epoch [37/50] batch [45/46] time 0.379 (0.482) data 0.000 (0.011) loss 0.3411 (0.4660) acc 87.5000 (87.0833) lr 3.6258e-04 eta 0:04:48
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [38/50] batch [5/46] time 0.380 (0.523) data 0.000 (0.083) loss 0.3762 (0.3721) acc 90.6250 (90.0000) lr 3.6258e-04 eta 0:05:09
epoch [38/50] batch [10/46] time 0.663 (0.509) data 0.000 (0.041) loss 0.2016 (0.3716) acc 93.7500 (89.0625) lr 3.6258e-04 eta 0:04:59
epoch [38/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.028) loss 0.5589 (0.4221) acc 84.3750 (87.9167) lr 3.6258e-04 eta 0:04:42
epoch [38/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.021) loss 0.7067 (0.4242) acc 84.3750 (87.8125) lr 3.6258e-04 eta 0:04:42
epoch [38/50] batch [25/46] time 0.678 (0.492) data 0.000 (0.017) loss 0.3938 (0.4205) acc 87.5000 (88.3750) lr 3.6258e-04 eta 0:04:41
epoch [38/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.014) loss 0.3285 (0.4238) acc 93.7500 (88.4375) lr 3.6258e-04 eta 0:04:34
epoch [38/50] batch [35/46] time 0.379 (0.484) data 0.000 (0.012) loss 0.5240 (0.4182) acc 84.3750 (88.5714) lr 3.6258e-04 eta 0:04:32
epoch [38/50] batch [40/46] time 0.659 (0.486) data 0.000 (0.010) loss 0.8539 (0.4315) acc 81.2500 (88.4375) lr 3.6258e-04 eta 0:04:30
epoch [38/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.009) loss 0.3388 (0.4364) acc 87.5000 (88.2639) lr 3.6258e-04 eta 0:04:25
Train CLIP2
Creating a 16-shot dataset
epoch [38/50] batch [5/46] time 0.380 (0.536) data 0.000 (0.098) loss 0.2063 (0.4423) acc 93.7500 (88.1250) lr 3.1545e-04 eta 0:05:17
epoch [38/50] batch [10/46] time 0.679 (0.517) data 0.000 (0.049) loss 0.0961 (0.4816) acc 96.8750 (86.5625) lr 3.1545e-04 eta 0:05:04
epoch [38/50] batch [15/46] time 0.380 (0.491) data 0.000 (0.033) loss 0.2582 (0.4264) acc 93.7500 (87.9167) lr 3.1545e-04 eta 0:04:46
epoch [38/50] batch [20/46] time 0.380 (0.494) data 0.000 (0.025) loss 0.4941 (0.4069) acc 87.5000 (88.2812) lr 3.1545e-04 eta 0:04:45
epoch [38/50] batch [25/46] time 0.667 (0.494) data 0.000 (0.020) loss 0.1357 (0.4177) acc 100.0000 (88.3750) lr 3.1545e-04 eta 0:04:43
epoch [38/50] batch [30/46] time 0.380 (0.485) data 0.000 (0.016) loss 0.5218 (0.4363) acc 87.5000 (87.7083) lr 3.1545e-04 eta 0:04:35
epoch [38/50] batch [35/46] time 0.379 (0.486) data 0.000 (0.014) loss 0.3146 (0.4355) acc 90.6250 (87.5893) lr 3.1545e-04 eta 0:04:33
epoch [38/50] batch [40/46] time 0.664 (0.486) data 0.000 (0.012) loss 0.2233 (0.4571) acc 96.8750 (87.2656) lr 3.1545e-04 eta 0:04:31
epoch [38/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.011) loss 0.8780 (0.4716) acc 78.1250 (87.0139) lr 3.1545e-04 eta 0:04:25
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [39/50] batch [5/46] time 0.380 (0.535) data 0.000 (0.097) loss 0.3993 (0.3358) acc 81.2500 (88.1250) lr 3.1545e-04 eta 0:04:52
epoch [39/50] batch [10/46] time 0.665 (0.515) data 0.000 (0.049) loss 0.6882 (0.4742) acc 78.1250 (85.6250) lr 3.1545e-04 eta 0:04:39
epoch [39/50] batch [15/46] time 0.380 (0.489) data 0.000 (0.032) loss 0.6088 (0.5286) acc 84.3750 (85.0000) lr 3.1545e-04 eta 0:04:22
epoch [39/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.024) loss 0.0662 (0.4938) acc 100.0000 (86.2500) lr 3.1545e-04 eta 0:04:20
epoch [39/50] batch [25/46] time 0.673 (0.492) data 0.000 (0.020) loss 0.6644 (0.4912) acc 90.6250 (86.8750) lr 3.1545e-04 eta 0:04:19
epoch [39/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.016) loss 0.4919 (0.4757) acc 87.5000 (87.3958) lr 3.1545e-04 eta 0:04:12
epoch [39/50] batch [35/46] time 0.379 (0.483) data 0.000 (0.014) loss 0.9133 (0.4856) acc 84.3750 (87.1429) lr 3.1545e-04 eta 0:04:09
epoch [39/50] batch [40/46] time 0.607 (0.483) data 0.000 (0.012) loss 0.4389 (0.4866) acc 87.5000 (87.1875) lr 3.1545e-04 eta 0:04:07
epoch [39/50] batch [45/46] time 0.379 (0.477) data 0.000 (0.011) loss 0.3373 (0.4749) acc 93.7500 (87.4306) lr 3.1545e-04 eta 0:04:01
Train CLIP2
Creating a 16-shot dataset
epoch [39/50] batch [5/46] time 0.379 (0.509) data 0.000 (0.068) loss 0.3743 (0.4399) acc 87.5000 (88.7500) lr 2.7103e-04 eta 0:04:38
epoch [39/50] batch [10/46] time 0.656 (0.500) data 0.000 (0.034) loss 0.2578 (0.4029) acc 93.7500 (89.3750) lr 2.7103e-04 eta 0:04:31
epoch [39/50] batch [15/46] time 0.380 (0.480) data 0.000 (0.023) loss 0.7900 (0.4249) acc 84.3750 (89.7917) lr 2.7103e-04 eta 0:04:17
epoch [39/50] batch [20/46] time 0.380 (0.484) data 0.000 (0.017) loss 0.1723 (0.4299) acc 96.8750 (89.2188) lr 2.7103e-04 eta 0:04:17
epoch [39/50] batch [25/46] time 0.689 (0.487) data 0.000 (0.014) loss 0.4993 (0.4281) acc 81.2500 (88.8750) lr 2.7103e-04 eta 0:04:16
epoch [39/50] batch [30/46] time 0.380 (0.478) data 0.000 (0.011) loss 0.7202 (0.4475) acc 78.1250 (88.5417) lr 2.7103e-04 eta 0:04:09
epoch [39/50] batch [35/46] time 0.379 (0.481) data 0.000 (0.010) loss 0.4210 (0.4447) acc 87.5000 (88.5714) lr 2.7103e-04 eta 0:04:08
epoch [39/50] batch [40/46] time 0.652 (0.482) data 0.000 (0.009) loss 0.3932 (0.4411) acc 90.6250 (88.5938) lr 2.7103e-04 eta 0:04:06
epoch [39/50] batch [45/46] time 0.380 (0.477) data 0.000 (0.008) loss 0.2904 (0.4367) acc 90.6250 (88.6111) lr 2.7103e-04 eta 0:04:01
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [40/50] batch [5/46] time 0.380 (0.527) data 0.000 (0.090) loss 0.5076 (0.5113) acc 87.5000 (86.8750) lr 2.7103e-04 eta 0:04:24
epoch [40/50] batch [10/46] time 0.676 (0.513) data 0.000 (0.045) loss 0.8775 (0.4888) acc 75.0000 (87.1875) lr 2.7103e-04 eta 0:04:14
epoch [40/50] batch [15/46] time 0.380 (0.488) data 0.000 (0.030) loss 0.2462 (0.4807) acc 93.7500 (86.8750) lr 2.7103e-04 eta 0:03:59
epoch [40/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.023) loss 0.7468 (0.5069) acc 84.3750 (86.5625) lr 2.7103e-04 eta 0:03:57
epoch [40/50] batch [25/46] time 0.690 (0.492) data 0.000 (0.018) loss 0.4497 (0.4820) acc 81.2500 (86.8750) lr 2.7103e-04 eta 0:03:56
epoch [40/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.6765 (0.4879) acc 81.2500 (86.8750) lr 2.7103e-04 eta 0:03:49
epoch [40/50] batch [35/46] time 0.379 (0.484) data 0.000 (0.013) loss 0.1872 (0.4717) acc 96.8750 (87.1429) lr 2.7103e-04 eta 0:03:47
epoch [40/50] batch [40/46] time 0.664 (0.485) data 0.000 (0.011) loss 0.5069 (0.4867) acc 87.5000 (86.6406) lr 2.7103e-04 eta 0:03:46
epoch [40/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.010) loss 0.2328 (0.4742) acc 90.6250 (87.0833) lr 2.7103e-04 eta 0:03:41
Train CLIP2
Creating a 16-shot dataset
epoch [40/50] batch [5/46] time 0.379 (0.519) data 0.000 (0.093) loss 0.3940 (0.3088) acc 93.7500 (92.5000) lr 2.2949e-04 eta 0:04:19
epoch [40/50] batch [10/46] time 0.670 (0.507) data 0.000 (0.047) loss 0.1758 (0.3204) acc 93.7500 (91.5625) lr 2.2949e-04 eta 0:04:11
epoch [40/50] batch [15/46] time 0.380 (0.484) data 0.000 (0.031) loss 0.1890 (0.3053) acc 96.8750 (92.0833) lr 2.2949e-04 eta 0:03:57
epoch [40/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.023) loss 0.1809 (0.3703) acc 93.7500 (90.4688) lr 2.2949e-04 eta 0:03:57
epoch [40/50] batch [25/46] time 0.696 (0.493) data 0.000 (0.019) loss 0.5482 (0.4180) acc 87.5000 (89.6250) lr 2.2949e-04 eta 0:03:57
epoch [40/50] batch [30/46] time 0.380 (0.485) data 0.000 (0.016) loss 0.2666 (0.4168) acc 93.7500 (88.9583) lr 2.2949e-04 eta 0:03:51
epoch [40/50] batch [35/46] time 0.380 (0.488) data 0.000 (0.013) loss 0.1213 (0.4123) acc 96.8750 (89.2857) lr 2.2949e-04 eta 0:03:49
epoch [40/50] batch [40/46] time 0.661 (0.488) data 0.000 (0.012) loss 0.4864 (0.4049) acc 87.5000 (89.2969) lr 2.2949e-04 eta 0:03:47
epoch [40/50] batch [45/46] time 0.379 (0.482) data 0.000 (0.011) loss 0.6854 (0.4091) acc 84.3750 (89.2361) lr 2.2949e-04 eta 0:03:42
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [41/50] batch [5/46] time 0.380 (0.539) data 0.000 (0.096) loss 0.9954 (0.5434) acc 81.2500 (86.2500) lr 2.2949e-04 eta 0:04:05
epoch [41/50] batch [10/46] time 0.671 (0.518) data 0.000 (0.048) loss 0.2877 (0.4832) acc 93.7500 (87.1875) lr 2.2949e-04 eta 0:03:52
epoch [41/50] batch [15/46] time 0.380 (0.493) data 0.000 (0.032) loss 0.4773 (0.5106) acc 87.5000 (86.8750) lr 2.2949e-04 eta 0:03:39
epoch [41/50] batch [20/46] time 0.380 (0.494) data 0.000 (0.024) loss 0.2244 (0.4665) acc 96.8750 (88.2812) lr 2.2949e-04 eta 0:03:37
epoch [41/50] batch [25/46] time 0.669 (0.495) data 0.000 (0.019) loss 0.5349 (0.4487) acc 87.5000 (88.8750) lr 2.2949e-04 eta 0:03:35
epoch [41/50] batch [30/46] time 0.380 (0.485) data 0.000 (0.016) loss 0.6196 (0.4501) acc 87.5000 (88.5417) lr 2.2949e-04 eta 0:03:28
epoch [41/50] batch [35/46] time 0.379 (0.486) data 0.000 (0.014) loss 0.4973 (0.4418) acc 87.5000 (88.4821) lr 2.2949e-04 eta 0:03:26
epoch [41/50] batch [40/46] time 0.653 (0.487) data 0.000 (0.012) loss 0.7681 (0.4353) acc 81.2500 (88.6719) lr 2.2949e-04 eta 0:03:24
epoch [41/50] batch [45/46] time 0.379 (0.481) data 0.000 (0.011) loss 0.6161 (0.4466) acc 81.2500 (87.9861) lr 2.2949e-04 eta 0:03:19
Train CLIP2
Creating a 16-shot dataset
epoch [41/50] batch [5/46] time 0.380 (0.526) data 0.000 (0.089) loss 0.5338 (0.4800) acc 84.3750 (84.3750) lr 1.9098e-04 eta 0:03:59
epoch [41/50] batch [10/46] time 0.662 (0.510) data 0.000 (0.045) loss 0.3201 (0.4402) acc 93.7500 (86.8750) lr 1.9098e-04 eta 0:03:49
epoch [41/50] batch [15/46] time 0.380 (0.488) data 0.000 (0.030) loss 0.1931 (0.4821) acc 93.7500 (86.4583) lr 1.9098e-04 eta 0:03:37
epoch [41/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.022) loss 0.2893 (0.4514) acc 90.6250 (87.3438) lr 1.9098e-04 eta 0:03:35
epoch [41/50] batch [25/46] time 0.665 (0.490) data 0.000 (0.018) loss 0.5944 (0.4807) acc 84.3750 (86.8750) lr 1.9098e-04 eta 0:03:33
epoch [41/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.015) loss 0.3844 (0.4996) acc 90.6250 (86.5625) lr 1.9098e-04 eta 0:03:27
epoch [41/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.3164 (0.4767) acc 93.7500 (87.1429) lr 1.9098e-04 eta 0:03:25
epoch [41/50] batch [40/46] time 0.658 (0.485) data 0.000 (0.011) loss 0.5095 (0.4727) acc 87.5000 (87.6562) lr 1.9098e-04 eta 0:03:23
epoch [41/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.010) loss 0.4261 (0.4589) acc 87.5000 (87.9167) lr 1.9098e-04 eta 0:03:19
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [42/50] batch [5/46] time 0.379 (0.506) data 0.000 (0.081) loss 0.3714 (0.4662) acc 87.5000 (88.1250) lr 1.9098e-04 eta 0:03:27
epoch [42/50] batch [10/46] time 0.660 (0.494) data 0.000 (0.041) loss 0.0307 (0.3891) acc 100.0000 (90.0000) lr 1.9098e-04 eta 0:03:19
epoch [42/50] batch [15/46] time 0.380 (0.477) data 0.000 (0.027) loss 0.3368 (0.3926) acc 93.7500 (90.4167) lr 1.9098e-04 eta 0:03:10
epoch [42/50] batch [20/46] time 0.380 (0.481) data 0.000 (0.020) loss 0.2775 (0.3709) acc 93.7500 (90.7812) lr 1.9098e-04 eta 0:03:09
epoch [42/50] batch [25/46] time 0.667 (0.484) data 0.000 (0.016) loss 0.2123 (0.3551) acc 90.6250 (90.8750) lr 1.9098e-04 eta 0:03:08
epoch [42/50] batch [30/46] time 0.380 (0.476) data 0.000 (0.014) loss 0.1335 (0.3431) acc 96.8750 (91.0417) lr 1.9098e-04 eta 0:03:02
epoch [42/50] batch [35/46] time 0.379 (0.479) data 0.000 (0.012) loss 0.6973 (0.3575) acc 81.2500 (90.8036) lr 1.9098e-04 eta 0:03:01
epoch [42/50] batch [40/46] time 0.660 (0.480) data 0.000 (0.010) loss 0.1944 (0.3581) acc 96.8750 (91.0156) lr 1.9098e-04 eta 0:02:59
epoch [42/50] batch [45/46] time 0.379 (0.476) data 0.000 (0.009) loss 0.2952 (0.3805) acc 90.6250 (90.6250) lr 1.9098e-04 eta 0:02:55
Train CLIP2
Creating a 16-shot dataset
epoch [42/50] batch [5/46] time 0.380 (0.526) data 0.000 (0.090) loss 0.2640 (0.4399) acc 93.7500 (90.6250) lr 1.5567e-04 eta 0:03:35
epoch [42/50] batch [10/46] time 0.655 (0.509) data 0.000 (0.045) loss 0.2935 (0.3923) acc 90.6250 (89.6875) lr 1.5567e-04 eta 0:03:25
epoch [42/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.030) loss 0.1999 (0.3932) acc 93.7500 (89.5833) lr 1.5567e-04 eta 0:03:13
epoch [42/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.023) loss 0.2481 (0.3776) acc 93.7500 (89.3750) lr 1.5567e-04 eta 0:03:12
epoch [42/50] batch [25/46] time 0.658 (0.490) data 0.000 (0.018) loss 0.1778 (0.3874) acc 96.8750 (89.0000) lr 1.5567e-04 eta 0:03:10
epoch [42/50] batch [30/46] time 0.380 (0.481) data 0.000 (0.015) loss 0.7265 (0.3959) acc 81.2500 (88.4375) lr 1.5567e-04 eta 0:03:04
epoch [42/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.4394 (0.3985) acc 87.5000 (88.3929) lr 1.5567e-04 eta 0:03:03
epoch [42/50] batch [40/46] time 0.658 (0.485) data 0.000 (0.011) loss 0.3948 (0.4030) acc 90.6250 (88.4375) lr 1.5567e-04 eta 0:03:01
epoch [42/50] batch [45/46] time 0.379 (0.479) data 0.000 (0.010) loss 0.4785 (0.4080) acc 87.5000 (88.5417) lr 1.5567e-04 eta 0:02:56
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [43/50] batch [5/46] time 0.379 (0.526) data 0.000 (0.089) loss 0.6150 (0.6462) acc 81.2500 (81.8750) lr 1.5567e-04 eta 0:03:11
epoch [43/50] batch [10/46] time 0.660 (0.510) data 0.000 (0.044) loss 0.0558 (0.4761) acc 100.0000 (87.1875) lr 1.5567e-04 eta 0:03:02
epoch [43/50] batch [15/46] time 0.380 (0.486) data 0.000 (0.030) loss 0.3570 (0.4478) acc 93.7500 (88.9583) lr 1.5567e-04 eta 0:02:51
epoch [43/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.022) loss 0.4006 (0.4464) acc 93.7500 (89.0625) lr 1.5567e-04 eta 0:02:50
epoch [43/50] batch [25/46] time 0.674 (0.491) data 0.000 (0.018) loss 0.4484 (0.4501) acc 84.3750 (88.6250) lr 1.5567e-04 eta 0:02:48
epoch [43/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.015) loss 0.3462 (0.4714) acc 96.8750 (88.6458) lr 1.5567e-04 eta 0:02:42
epoch [43/50] batch [35/46] time 0.379 (0.484) data 0.000 (0.013) loss 0.3520 (0.4790) acc 90.6250 (88.2143) lr 1.5567e-04 eta 0:02:41
epoch [43/50] batch [40/46] time 0.653 (0.485) data 0.000 (0.011) loss 0.4086 (0.4693) acc 90.6250 (88.2812) lr 1.5567e-04 eta 0:02:39
epoch [43/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.010) loss 0.6786 (0.4776) acc 84.3750 (87.8472) lr 1.5567e-04 eta 0:02:35
Train CLIP2
Creating a 16-shot dataset
epoch [43/50] batch [5/46] time 0.379 (0.513) data 0.000 (0.086) loss 0.2845 (0.3992) acc 87.5000 (89.3750) lr 1.2369e-04 eta 0:03:06
epoch [43/50] batch [10/46] time 0.656 (0.505) data 0.000 (0.043) loss 0.4526 (0.4331) acc 84.3750 (88.1250) lr 1.2369e-04 eta 0:03:00
epoch [43/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.029) loss 0.2425 (0.4257) acc 93.7500 (88.1250) lr 1.2369e-04 eta 0:02:51
epoch [43/50] batch [20/46] time 0.380 (0.488) data 0.000 (0.022) loss 0.5083 (0.4098) acc 90.6250 (88.5938) lr 1.2369e-04 eta 0:02:49
epoch [43/50] batch [25/46] time 0.666 (0.489) data 0.000 (0.017) loss 0.4399 (0.4436) acc 93.7500 (88.2500) lr 1.2369e-04 eta 0:02:47
epoch [43/50] batch [30/46] time 0.380 (0.480) data 0.000 (0.014) loss 0.2974 (0.4670) acc 90.6250 (88.0208) lr 1.2369e-04 eta 0:02:42
epoch [43/50] batch [35/46] time 0.379 (0.482) data 0.000 (0.012) loss 0.6946 (0.4483) acc 87.5000 (88.4821) lr 1.2369e-04 eta 0:02:40
epoch [43/50] batch [40/46] time 0.672 (0.484) data 0.000 (0.011) loss 0.2600 (0.4269) acc 93.7500 (88.9062) lr 1.2369e-04 eta 0:02:38
epoch [43/50] batch [45/46] time 0.380 (0.478) data 0.000 (0.010) loss 0.6320 (0.4418) acc 87.5000 (88.5417) lr 1.2369e-04 eta 0:02:34
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [44/50] batch [5/46] time 0.380 (0.522) data 0.000 (0.084) loss 0.5101 (0.4636) acc 90.6250 (89.3750) lr 1.2369e-04 eta 0:02:45
epoch [44/50] batch [10/46] time 0.668 (0.509) data 0.000 (0.042) loss 0.6271 (0.5165) acc 84.3750 (87.1875) lr 1.2369e-04 eta 0:02:38
epoch [44/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.028) loss 0.4484 (0.4725) acc 93.7500 (87.7083) lr 1.2369e-04 eta 0:02:28
epoch [44/50] batch [20/46] time 0.380 (0.488) data 0.000 (0.021) loss 0.3873 (0.4798) acc 90.6250 (87.9688) lr 1.2369e-04 eta 0:02:27
epoch [44/50] batch [25/46] time 0.664 (0.489) data 0.000 (0.017) loss 0.3327 (0.4564) acc 90.6250 (88.2500) lr 1.2369e-04 eta 0:02:25
epoch [44/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.014) loss 0.4833 (0.4432) acc 84.3750 (88.1250) lr 1.2369e-04 eta 0:02:20
epoch [44/50] batch [35/46] time 0.380 (0.483) data 0.000 (0.012) loss 0.5253 (0.4419) acc 87.5000 (88.2143) lr 1.2369e-04 eta 0:02:18
epoch [44/50] batch [40/46] time 0.662 (0.485) data 0.000 (0.011) loss 0.4988 (0.4420) acc 84.3750 (88.0469) lr 1.2369e-04 eta 0:02:16
epoch [44/50] batch [45/46] time 0.380 (0.479) data 0.000 (0.009) loss 0.6892 (0.4663) acc 78.1250 (87.3611) lr 1.2369e-04 eta 0:02:12
Train CLIP2
Creating a 16-shot dataset
epoch [44/50] batch [5/46] time 0.380 (0.527) data 0.000 (0.091) loss 0.5553 (0.4539) acc 81.2500 (87.5000) lr 9.5173e-05 eta 0:02:47
epoch [44/50] batch [10/46] time 0.659 (0.510) data 0.000 (0.046) loss 0.1379 (0.3775) acc 90.6250 (90.0000) lr 9.5173e-05 eta 0:02:39
epoch [44/50] batch [15/46] time 0.380 (0.486) data 0.000 (0.031) loss 0.9886 (0.4734) acc 81.2500 (88.7500) lr 9.5173e-05 eta 0:02:29
epoch [44/50] batch [20/46] time 0.380 (0.488) data 0.000 (0.023) loss 0.6853 (0.4645) acc 78.1250 (88.7500) lr 9.5173e-05 eta 0:02:27
epoch [44/50] batch [25/46] time 0.663 (0.491) data 0.000 (0.018) loss 0.3743 (0.4469) acc 90.6250 (88.8750) lr 9.5173e-05 eta 0:02:25
epoch [44/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.015) loss 0.5858 (0.4314) acc 78.1250 (88.7500) lr 9.5173e-05 eta 0:02:20
epoch [44/50] batch [35/46] time 0.379 (0.484) data 0.000 (0.013) loss 0.5436 (0.4472) acc 84.3750 (88.4821) lr 9.5173e-05 eta 0:02:18
epoch [44/50] batch [40/46] time 0.659 (0.485) data 0.000 (0.012) loss 0.5071 (0.4318) acc 87.5000 (88.7500) lr 9.5173e-05 eta 0:02:16
epoch [44/50] batch [45/46] time 0.379 (0.479) data 0.000 (0.010) loss 0.4215 (0.4325) acc 90.6250 (88.7500) lr 9.5173e-05 eta 0:02:12
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [45/50] batch [5/46] time 0.380 (0.512) data 0.000 (0.069) loss 0.4477 (0.6060) acc 90.6250 (86.8750) lr 9.5173e-05 eta 0:02:18
epoch [45/50] batch [10/46] time 0.694 (0.506) data 0.000 (0.035) loss 0.1015 (0.4963) acc 96.8750 (88.1250) lr 9.5173e-05 eta 0:02:14
epoch [45/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.023) loss 0.4286 (0.4648) acc 87.5000 (88.1250) lr 9.5173e-05 eta 0:02:06
epoch [45/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.017) loss 0.4283 (0.4478) acc 87.5000 (87.9688) lr 9.5173e-05 eta 0:02:05
epoch [45/50] batch [25/46] time 0.663 (0.490) data 0.000 (0.014) loss 0.6259 (0.4415) acc 87.5000 (88.5000) lr 9.5173e-05 eta 0:02:02
epoch [45/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.012) loss 0.1115 (0.4347) acc 100.0000 (89.1667) lr 9.5173e-05 eta 0:01:58
epoch [45/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.010) loss 0.2501 (0.4381) acc 93.7500 (89.0179) lr 9.5173e-05 eta 0:01:56
epoch [45/50] batch [40/46] time 0.657 (0.485) data 0.000 (0.009) loss 0.1589 (0.4210) acc 96.8750 (89.4531) lr 9.5173e-05 eta 0:01:54
epoch [45/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.008) loss 0.6036 (0.4330) acc 87.5000 (88.9583) lr 9.5173e-05 eta 0:01:50
Train CLIP2
Creating a 16-shot dataset
epoch [45/50] batch [5/46] time 0.380 (0.530) data 0.000 (0.092) loss 0.3443 (0.3639) acc 84.3750 (88.1250) lr 7.0224e-05 eta 0:02:23
epoch [45/50] batch [10/46] time 0.665 (0.514) data 0.000 (0.046) loss 0.6078 (0.3283) acc 81.2500 (90.0000) lr 7.0224e-05 eta 0:02:16
epoch [45/50] batch [15/46] time 0.380 (0.489) data 0.000 (0.031) loss 0.9663 (0.3925) acc 78.1250 (89.1667) lr 7.0224e-05 eta 0:02:07
epoch [45/50] batch [20/46] time 0.380 (0.491) data 0.000 (0.023) loss 0.7112 (0.4472) acc 84.3750 (87.5000) lr 7.0224e-05 eta 0:02:05
epoch [45/50] batch [25/46] time 0.666 (0.492) data 0.000 (0.018) loss 0.3934 (0.4585) acc 87.5000 (87.6250) lr 7.0224e-05 eta 0:02:03
epoch [45/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.2400 (0.4452) acc 93.7500 (87.7083) lr 7.0224e-05 eta 0:01:58
epoch [45/50] batch [35/46] time 0.379 (0.485) data 0.000 (0.013) loss 0.6288 (0.4474) acc 87.5000 (87.8571) lr 7.0224e-05 eta 0:01:56
epoch [45/50] batch [40/46] time 0.666 (0.486) data 0.000 (0.012) loss 0.6881 (0.4429) acc 84.3750 (88.2031) lr 7.0224e-05 eta 0:01:54
epoch [45/50] batch [45/46] time 0.380 (0.480) data 0.000 (0.010) loss 0.2777 (0.4336) acc 90.6250 (88.2639) lr 7.0224e-05 eta 0:01:50
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [46/50] batch [5/46] time 0.380 (0.527) data 0.000 (0.090) loss 0.2675 (0.5068) acc 93.7500 (87.5000) lr 7.0224e-05 eta 0:01:58
epoch [46/50] batch [10/46] time 0.674 (0.512) data 0.000 (0.045) loss 0.3317 (0.4075) acc 87.5000 (89.3750) lr 7.0224e-05 eta 0:01:52
epoch [46/50] batch [15/46] time 0.380 (0.488) data 0.000 (0.030) loss 0.0894 (0.4049) acc 100.0000 (89.3750) lr 7.0224e-05 eta 0:01:44
epoch [46/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.023) loss 0.4551 (0.4372) acc 93.7500 (89.0625) lr 7.0224e-05 eta 0:01:42
epoch [46/50] batch [25/46] time 0.678 (0.491) data 0.000 (0.018) loss 0.3191 (0.4454) acc 87.5000 (89.1250) lr 7.0224e-05 eta 0:01:40
epoch [46/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.4330 (0.4451) acc 90.6250 (89.3750) lr 7.0224e-05 eta 0:01:36
epoch [46/50] batch [35/46] time 0.379 (0.484) data 0.000 (0.013) loss 0.3065 (0.4307) acc 93.7500 (89.4643) lr 7.0224e-05 eta 0:01:34
epoch [46/50] batch [40/46] time 0.674 (0.486) data 0.000 (0.011) loss 0.3996 (0.4151) acc 87.5000 (89.7656) lr 7.0224e-05 eta 0:01:32
epoch [46/50] batch [45/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.3011 (0.4166) acc 93.7500 (89.6528) lr 7.0224e-05 eta 0:01:28
Train CLIP2
Creating a 16-shot dataset
epoch [46/50] batch [5/46] time 0.379 (0.498) data 0.000 (0.072) loss 0.2000 (0.3565) acc 93.7500 (89.3750) lr 4.8943e-05 eta 0:01:52
epoch [46/50] batch [10/46] time 0.662 (0.491) data 0.000 (0.036) loss 0.5281 (0.4245) acc 93.7500 (88.7500) lr 4.8943e-05 eta 0:01:48
epoch [46/50] batch [15/46] time 0.380 (0.474) data 0.000 (0.024) loss 0.2592 (0.3997) acc 90.6250 (88.5417) lr 4.8943e-05 eta 0:01:41
epoch [46/50] batch [20/46] time 0.380 (0.481) data 0.000 (0.018) loss 0.5054 (0.3977) acc 87.5000 (88.9062) lr 4.8943e-05 eta 0:01:40
epoch [46/50] batch [25/46] time 0.664 (0.484) data 0.000 (0.015) loss 0.6892 (0.4225) acc 81.2500 (88.3750) lr 4.8943e-05 eta 0:01:39
epoch [46/50] batch [30/46] time 0.380 (0.476) data 0.000 (0.012) loss 0.3015 (0.4205) acc 90.6250 (88.2292) lr 4.8943e-05 eta 0:01:35
epoch [46/50] batch [35/46] time 0.379 (0.479) data 0.000 (0.010) loss 0.6335 (0.4253) acc 84.3750 (88.1250) lr 4.8943e-05 eta 0:01:33
epoch [46/50] batch [40/46] time 0.659 (0.480) data 0.000 (0.009) loss 0.2067 (0.4176) acc 96.8750 (88.5156) lr 4.8943e-05 eta 0:01:31
epoch [46/50] batch [45/46] time 0.380 (0.476) data 0.000 (0.008) loss 0.4226 (0.4367) acc 93.7500 (88.4028) lr 4.8943e-05 eta 0:01:27
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [47/50] batch [5/46] time 0.380 (0.527) data 0.000 (0.090) loss 0.4835 (0.3509) acc 84.3750 (89.3750) lr 4.8943e-05 eta 0:01:34
epoch [47/50] batch [10/46] time 0.655 (0.509) data 0.000 (0.045) loss 0.3511 (0.4124) acc 87.5000 (88.4375) lr 4.8943e-05 eta 0:01:28
epoch [47/50] batch [15/46] time 0.379 (0.487) data 0.000 (0.030) loss 0.8217 (0.4663) acc 81.2500 (87.5000) lr 4.8943e-05 eta 0:01:22
epoch [47/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.023) loss 0.2905 (0.4625) acc 90.6250 (87.8125) lr 4.8943e-05 eta 0:01:20
epoch [47/50] batch [25/46] time 0.655 (0.491) data 0.000 (0.018) loss 0.1253 (0.4437) acc 93.7500 (88.1250) lr 4.8943e-05 eta 0:01:18
epoch [47/50] batch [30/46] time 0.380 (0.482) data 0.000 (0.015) loss 0.4099 (0.4531) acc 93.7500 (88.0208) lr 4.8943e-05 eta 0:01:14
epoch [47/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.4444 (0.4606) acc 87.5000 (87.9464) lr 4.8943e-05 eta 0:01:12
epoch [47/50] batch [40/46] time 0.656 (0.485) data 0.000 (0.011) loss 0.4081 (0.4635) acc 93.7500 (87.8906) lr 4.8943e-05 eta 0:01:09
epoch [47/50] batch [45/46] time 0.379 (0.479) data 0.000 (0.010) loss 0.8021 (0.4745) acc 75.0000 (87.3611) lr 4.8943e-05 eta 0:01:06
Train CLIP2
Creating a 16-shot dataset
epoch [47/50] batch [5/46] time 0.380 (0.530) data 0.000 (0.088) loss 0.2798 (0.4971) acc 87.5000 (85.6250) lr 3.1417e-05 eta 0:01:34
epoch [47/50] batch [10/46] time 0.675 (0.514) data 0.000 (0.044) loss 0.5733 (0.5088) acc 87.5000 (85.3125) lr 3.1417e-05 eta 0:01:29
epoch [47/50] batch [15/46] time 0.380 (0.489) data 0.000 (0.030) loss 0.1785 (0.5200) acc 96.8750 (85.6250) lr 3.1417e-05 eta 0:01:22
epoch [47/50] batch [20/46] time 0.380 (0.490) data 0.000 (0.022) loss 0.3560 (0.4869) acc 93.7500 (87.0312) lr 3.1417e-05 eta 0:01:20
epoch [47/50] batch [25/46] time 0.659 (0.492) data 0.000 (0.018) loss 0.7609 (0.4647) acc 81.2500 (87.8750) lr 3.1417e-05 eta 0:01:18
epoch [47/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.9137 (0.4716) acc 84.3750 (87.8125) lr 3.1417e-05 eta 0:01:14
epoch [47/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.3446 (0.4572) acc 87.5000 (87.9464) lr 3.1417e-05 eta 0:01:12
epoch [47/50] batch [40/46] time 0.658 (0.485) data 0.000 (0.011) loss 0.5437 (0.4600) acc 81.2500 (87.9688) lr 3.1417e-05 eta 0:01:09
epoch [47/50] batch [45/46] time 0.379 (0.480) data 0.000 (0.010) loss 0.2763 (0.4679) acc 90.6250 (87.8472) lr 3.1417e-05 eta 0:01:06
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [48/50] batch [5/46] time 0.380 (0.523) data 0.000 (0.086) loss 0.5122 (0.4933) acc 90.6250 (86.8750) lr 3.1417e-05 eta 0:01:09
epoch [48/50] batch [10/46] time 0.663 (0.509) data 0.000 (0.043) loss 0.2156 (0.4715) acc 87.5000 (85.9375) lr 3.1417e-05 eta 0:01:05
epoch [48/50] batch [15/46] time 0.380 (0.485) data 0.000 (0.029) loss 0.2326 (0.4220) acc 93.7500 (87.5000) lr 3.1417e-05 eta 0:00:59
epoch [48/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.022) loss 0.4973 (0.4226) acc 87.5000 (87.3438) lr 3.1417e-05 eta 0:00:57
epoch [48/50] batch [25/46] time 0.660 (0.490) data 0.000 (0.017) loss 0.4005 (0.3969) acc 90.6250 (88.1250) lr 3.1417e-05 eta 0:00:55
epoch [48/50] batch [30/46] time 0.380 (0.481) data 0.000 (0.014) loss 0.3193 (0.4091) acc 90.6250 (87.7083) lr 3.1417e-05 eta 0:00:51
epoch [48/50] batch [35/46] time 0.379 (0.483) data 0.000 (0.012) loss 0.5044 (0.4034) acc 93.7500 (88.1250) lr 3.1417e-05 eta 0:00:49
epoch [48/50] batch [40/46] time 0.665 (0.485) data 0.000 (0.011) loss 0.2248 (0.3946) acc 93.7500 (88.7500) lr 3.1417e-05 eta 0:00:47
epoch [48/50] batch [45/46] time 0.380 (0.480) data 0.000 (0.010) loss 0.1276 (0.4155) acc 93.7500 (88.3333) lr 3.1417e-05 eta 0:00:44
Train CLIP2
Creating a 16-shot dataset
epoch [48/50] batch [5/46] time 0.380 (0.526) data 0.000 (0.089) loss 0.2789 (0.3829) acc 93.7500 (91.8750) lr 1.7713e-05 eta 0:01:09
epoch [48/50] batch [10/46] time 0.658 (0.510) data 0.000 (0.045) loss 0.1236 (0.3323) acc 96.8750 (92.8125) lr 1.7713e-05 eta 0:01:05
epoch [48/50] batch [15/46] time 0.380 (0.486) data 0.000 (0.030) loss 0.1817 (0.3259) acc 93.7500 (92.2917) lr 1.7713e-05 eta 0:00:59
epoch [48/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.022) loss 0.3431 (0.3736) acc 93.7500 (90.9375) lr 1.7713e-05 eta 0:00:57
epoch [48/50] batch [25/46] time 0.679 (0.491) data 0.000 (0.018) loss 0.6066 (0.3880) acc 87.5000 (90.5000) lr 1.7713e-05 eta 0:00:55
epoch [48/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.5564 (0.3997) acc 84.3750 (90.1042) lr 1.7713e-05 eta 0:00:52
epoch [48/50] batch [35/46] time 0.380 (0.484) data 0.000 (0.013) loss 0.4251 (0.4097) acc 90.6250 (90.0000) lr 1.7713e-05 eta 0:00:49
epoch [48/50] batch [40/46] time 0.608 (0.485) data 0.000 (0.011) loss 0.2019 (0.3907) acc 96.8750 (90.2344) lr 1.7713e-05 eta 0:00:47
epoch [48/50] batch [45/46] time 0.379 (0.479) data 0.000 (0.010) loss 0.6934 (0.4012) acc 84.3750 (89.9306) lr 1.7713e-05 eta 0:00:44
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [49/50] batch [5/46] time 0.379 (0.529) data 0.000 (0.092) loss 0.4376 (0.4355) acc 84.3750 (87.5000) lr 1.7713e-05 eta 0:00:45
epoch [49/50] batch [10/46] time 0.605 (0.500) data 0.000 (0.046) loss 0.3431 (0.4142) acc 90.6250 (89.3750) lr 1.7713e-05 eta 0:00:40
epoch [49/50] batch [15/46] time 0.382 (0.480) data 0.000 (0.031) loss 0.1710 (0.4023) acc 93.7500 (89.3750) lr 1.7713e-05 eta 0:00:36
epoch [49/50] batch [20/46] time 0.379 (0.481) data 0.000 (0.023) loss 0.3970 (0.4318) acc 87.5000 (89.2188) lr 1.7713e-05 eta 0:00:34
epoch [49/50] batch [25/46] time 0.668 (0.485) data 0.000 (0.018) loss 0.3465 (0.4236) acc 87.5000 (89.2500) lr 1.7713e-05 eta 0:00:32
epoch [49/50] batch [30/46] time 0.380 (0.477) data 0.000 (0.015) loss 0.1011 (0.4010) acc 100.0000 (89.7917) lr 1.7713e-05 eta 0:00:29
epoch [49/50] batch [35/46] time 0.381 (0.480) data 0.000 (0.013) loss 0.3322 (0.4152) acc 93.7500 (89.3750) lr 1.7713e-05 eta 0:00:27
epoch [49/50] batch [40/46] time 0.678 (0.482) data 0.000 (0.012) loss 0.6787 (0.4237) acc 84.3750 (89.1406) lr 1.7713e-05 eta 0:00:25
epoch [49/50] batch [45/46] time 0.380 (0.477) data 0.000 (0.010) loss 0.4353 (0.4300) acc 90.6250 (88.9583) lr 1.7713e-05 eta 0:00:22
Train CLIP2
Creating a 16-shot dataset
epoch [49/50] batch [5/46] time 0.380 (0.527) data 0.000 (0.089) loss 0.3327 (0.3055) acc 93.7500 (92.5000) lr 7.8853e-06 eta 0:00:45
epoch [49/50] batch [10/46] time 0.700 (0.515) data 0.000 (0.045) loss 0.2513 (0.3193) acc 93.7500 (91.5625) lr 7.8853e-06 eta 0:00:42
epoch [49/50] batch [15/46] time 0.380 (0.489) data 0.000 (0.030) loss 0.2078 (0.3493) acc 93.7500 (91.2500) lr 7.8853e-06 eta 0:00:37
epoch [49/50] batch [20/46] time 0.380 (0.491) data 0.000 (0.022) loss 0.0814 (0.3471) acc 100.0000 (90.3125) lr 7.8853e-06 eta 0:00:35
epoch [49/50] batch [25/46] time 0.667 (0.492) data 0.000 (0.018) loss 0.3562 (0.3771) acc 93.7500 (90.1250) lr 7.8853e-06 eta 0:00:32
epoch [49/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.015) loss 0.3421 (0.3824) acc 90.6250 (89.8958) lr 7.8853e-06 eta 0:00:29
epoch [49/50] batch [35/46] time 0.380 (0.485) data 0.000 (0.013) loss 0.4090 (0.3990) acc 93.7500 (89.6429) lr 7.8853e-06 eta 0:00:27
epoch [49/50] batch [40/46] time 0.671 (0.486) data 0.000 (0.011) loss 0.2594 (0.3921) acc 93.7500 (89.8438) lr 7.8853e-06 eta 0:00:25
epoch [49/50] batch [45/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.2314 (0.4019) acc 90.6250 (89.5833) lr 7.8853e-06 eta 0:00:22
Update lables on the *val* set
Do warmup evaluation on the few_shots_data set
Do warmup evaluation on the few_shots_data set
Train CLIP1
Creating a 16-shot dataset
epoch [50/50] batch [5/46] time 0.380 (0.529) data 0.000 (0.090) loss 0.3544 (0.3529) acc 90.6250 (93.1250) lr 7.8853e-06 eta 0:00:21
epoch [50/50] batch [10/46] time 0.665 (0.512) data 0.000 (0.045) loss 0.5100 (0.4389) acc 84.3750 (89.6875) lr 7.8853e-06 eta 0:00:18
epoch [50/50] batch [15/46] time 0.380 (0.487) data 0.000 (0.030) loss 0.6291 (0.5232) acc 81.2500 (87.5000) lr 7.8853e-06 eta 0:00:15
epoch [50/50] batch [20/46] time 0.380 (0.489) data 0.000 (0.023) loss 0.5951 (0.5326) acc 90.6250 (87.1875) lr 7.8853e-06 eta 0:00:12
epoch [50/50] batch [25/46] time 0.693 (0.492) data 0.000 (0.018) loss 0.2451 (0.5190) acc 93.7500 (86.8750) lr 7.8853e-06 eta 0:00:10
epoch [50/50] batch [30/46] time 0.379 (0.484) data 0.000 (0.015) loss 0.6590 (0.5405) acc 84.3750 (86.6667) lr 7.8853e-06 eta 0:00:07
epoch [50/50] batch [35/46] time 0.379 (0.485) data 0.000 (0.013) loss 0.2734 (0.5157) acc 93.7500 (87.3214) lr 7.8853e-06 eta 0:00:05
epoch [50/50] batch [40/46] time 0.659 (0.486) data 0.000 (0.011) loss 0.5644 (0.5014) acc 87.5000 (87.8125) lr 7.8853e-06 eta 0:00:02
epoch [50/50] batch [45/46] time 0.380 (0.481) data 0.000 (0.010) loss 0.4646 (0.4963) acc 87.5000 (87.9167) lr 7.8853e-06 eta 0:00:00
Train CLIP2
Creating a 16-shot dataset
epoch [50/50] batch [5/46] time 0.380 (0.538) data 0.000 (0.099) loss 0.2308 (0.3523) acc 93.7500 (90.6250) lr 1.9733e-06 eta 0:00:22
epoch [50/50] batch [10/46] time 0.670 (0.516) data 0.000 (0.050) loss 0.2773 (0.4048) acc 96.8750 (90.6250) lr 1.9733e-06 eta 0:00:18
epoch [50/50] batch [15/46] time 0.380 (0.490) data 0.000 (0.033) loss 0.6523 (0.4578) acc 81.2500 (89.7917) lr 1.9733e-06 eta 0:00:15
epoch [50/50] batch [20/46] time 0.381 (0.491) data 0.000 (0.025) loss 0.3796 (0.4260) acc 90.6250 (89.8438) lr 1.9733e-06 eta 0:00:12
epoch [50/50] batch [25/46] time 0.671 (0.492) data 0.000 (0.020) loss 0.1742 (0.4265) acc 96.8750 (90.0000) lr 1.9733e-06 eta 0:00:10
epoch [50/50] batch [30/46] time 0.380 (0.483) data 0.000 (0.017) loss 0.4813 (0.4332) acc 87.5000 (89.6875) lr 1.9733e-06 eta 0:00:07
epoch [50/50] batch [35/46] time 0.380 (0.485) data 0.000 (0.014) loss 0.5771 (0.4439) acc 87.5000 (89.2857) lr 1.9733e-06 eta 0:00:05
epoch [50/50] batch [40/46] time 0.663 (0.486) data 0.000 (0.012) loss 0.4437 (0.4596) acc 84.3750 (88.9062) lr 1.9733e-06 eta 0:00:02
epoch [50/50] batch [45/46] time 0.380 (0.480) data 0.000 (0.011) loss 0.7238 (0.4568) acc 81.2500 (88.8194) lr 1.9733e-06 eta 0:00:00
Update lables on the *val* set
Checkpoint saved to output/caltech101/RCoOp/vit_b32_ep50_16shots/nctx16_cscFalse_ctpend/GCEFalse_FactorUpLabels/16shots_0noise/seed1/prompt_learner1/model.pth.tar-50
Checkpoint saved to output/caltech101/RCoOp/vit_b32_ep50_16shots/nctx16_cscFalse_ctpend/GCEFalse_FactorUpLabels/16shots_0noise/seed1/prompt_learner2/model.pth.tar-50
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 2,465
* correct: 2,331
* accuracy: 94.6%
* error: 5.4%
* macro_f1: 91.8%
Elapsed: 0:35:45
